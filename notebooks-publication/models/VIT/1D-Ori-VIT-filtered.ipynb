{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6115123,"sourceType":"datasetVersion","datasetId":3504592}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/input/chemcancer-v2/src/\n%mkdir /kaggle/working/Deep_Learning_metrics/\n%mkdir /kaggle/working/During_train/\n%mkdir /kaggle/working/CV_VIT_models\n%mkdir /kaggle/working/CV_VIT_results","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-11T04:09:10.328547Z","iopub.execute_input":"2023-07-11T04:09:10.328964Z","iopub.status.idle":"2023-07-11T04:09:14.562569Z","shell.execute_reply.started":"2023-07-11T04:09:10.328928Z","shell.execute_reply":"2023-07-11T04:09:14.561250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom tensorflow.keras.optimizers import Adam\nfrom data import *\nfrom machine_learning_models import *\nfrom deep_learning_models import *\nfrom vision_transformer import *\nfrom utils_dl_model import *\nfrom utils_ml_model import print_ml_results\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2023-07-11T04:09:16.575954Z","iopub.execute_input":"2023-07-11T04:09:16.576351Z","iopub.status.idle":"2023-07-11T04:09:16.583566Z","shell.execute_reply.started":"2023-07-11T04:09:16.576315Z","shell.execute_reply":"2023-07-11T04:09:16.582575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the seed value.\nSEED = 7\nnp.random.seed(SEED)\n\n# Deep Learning parameters\nDL_EPOCH = 250\nDL_BATCH_SIZE = 32\nDL_CNN_VERSION = 3\nDL_TRANSFORMER_VISION_VERSION = 14\nDL_CV_FOLD = 5\n\nDO_DL = True\nCV_DL = True\nOPT_DL = False\n\nDO_CNN = False\nDO_TRANSFORMER_VISION = True\nDO_ML = False\n\n# Percentage of test set out of the dataset.\nTEST_SET = 0.2\n\n# Percentage of validation set out of the training dataset.\nVAL_SET = 0.2\n\n# Folder path associated with deep learning models\ndl_models_folder = \"../Deep_Learning_models/\"\ndl_metrics_folder = \"../Deep_Learning_metrics/\"\ndl_weights_folder = \"../Deep_Learning_weights/\"\ndl_cv_models_folder = \"../Deep_Learning_CV/\"\ndl_cv_results_folder = \"../Deep_Learning_CV_results/\"\n\n# Folder path associated with machine learning models\nml_models_folder = \"../Machine_Learning_models/\"\nml_models_results_folder = \"../Machine_Learning_models_results/\"\n\n# Model names (Saved in h5 format)\ncnn_model_name = f\"cnn_v{DL_CNN_VERSION}_{DL_BATCH_SIZE}_{DL_EPOCH}_seed_{SEED}.h5\"\ntransformer_vis_model_name = f\"transformer_vision_v{DL_TRANSFORMER_VISION_VERSION}_{DL_BATCH_SIZE}_{DL_EPOCH}_seed_{SEED}.h5\"\n\n# Metric filenames\ncnn_metrics_filename = f\"metrics_{cnn_model_name}.json\"\ntransformer_vis_metrics_filename = f\"metrics_{transformer_vis_model_name}.json\"\n\n# Weight filenames\ncnn_weights_filename = f\"weights_{cnn_model_name}.json\"\ntransformer_vis_weights_filename = f\"weights_{transformer_vis_model_name}.json\"\n\n\n# Deep Learning models path\nif DO_CNN:\n    dl_model_path = os.path.join(\n        dl_models_folder, cnn_model_name)\nelif DO_TRANSFORMER_VISION:\n    dl_model_path = os.path.join(\n        dl_models_folder, transformer_vis_model_name)\n\n\n# Deep Learning metrics path\nif DO_CNN:\n    dl_metrics_path = os.path.join(\n        dl_metrics_folder, cnn_metrics_filename)\nelif DO_TRANSFORMER_VISION:\n    dl_metrics_path = os.path.join(\n        dl_metrics_folder, transformer_vis_metrics_filename)\n\n\n# Deep Learning weights path\nif DO_CNN:\n    dl_weights_path = os.path.join(\n        dl_weights_folder, cnn_weights_filename)\n\nelif DO_TRANSFORMER_VISION:\n    dl_weights_path = os.path.join(\n        dl_weights_folder, transformer_vis_weights_filename)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T04:23:21.379674Z","iopub.execute_input":"2023-07-11T04:23:21.380062Z","iopub.status.idle":"2023-07-11T04:23:21.392062Z","shell.execute_reply.started":"2023-07-11T04:23:21.380028Z","shell.execute_reply":"2023-07-11T04:23:21.390867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\ndata_file = \"../Data/HC05_HC07.csv\"\n\nif OPT_DL:\n    X_filtered, y = preprocess_cv_raw_data(data_file)\n    optimize_hyperparameters(X_filtered, y, 50, dl_cv_models_folder, dl_cv_results_folder)\n\nelse:\n    # Train deep learning model with cross validation\n    if CV_DL:\n        X_filtered, y = preprocess_cv_raw_data(data_file)\n    else:\n        # Preprocess the raw data\n        X_train, X_test, y_train, y_test = preprocess_raw_data(\n            data_file, TEST_SET)\n\n# Do Deep Learning\nif DO_DL:\n    dl_weights_path = \"../During_train/cnn_v3-250-val_acc0.86.h5\"\n    if os.path.exists(dl_model_path):\n        if DO_TRANSFORMER_VISION:\n            model = tf.keras.models.load_model(\n                dl_model_path, custom_objects={'ClassToken': ClassToken, 'TransformerBlock': TransformerBlock})\n        elif DO_CNN:\n            model = tf.keras.models.load_model(dl_model_path)\n            print(\"Loaded trained model from\", dl_model_path)\n    elif os.path.exists(dl_weights_path):\n        if DO_TRANSFORMER_VISION:\n            print(\"hello\")\n            # model = create_vit(input_shape, patch_size, num_patches, num_classes,\n            #                         embed_dim, num_heads, mlp_dim, num_layers, dropout_rate)\n            # model.load_weights(dl_weights_path)\n        elif DO_CNN:\n            X_train = X_train.reshape(\n                X_train.shape[0], X_train.shape[1], 1)\n            X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n            input_shape = (X_train.shape[1], 1)\n            num_classes = len(np.unique(y_train))\n            learning_rate = 1.4286522423518213e-05\n            dropout_rate = 0.2\n            l2_regularizer = 0.000417822262290105\n            model = cnn_model_3_opt(\n                input_shape, num_classes, learning_rate, dropout_rate, l2_regularizer)\n            model.load_weights(dl_weights_path)\n            print(\"Loaded trained model weights from\", dl_weights_path)\n            # Evaluating the model\n            print(\"Evaluating the CNN model... \")\n            # Calculate model loss and accuracy\n            test_loss, test_accuracy = model.evaluate(X_test, y_test)\n            print(\"Test loss:\", test_loss)\n            print(\"Test accuracy:\", test_accuracy)\n    else:\n        if CV_DL:\n            # learning_rate = 3.408170980489466e-05\n            # dropout_rate = 0.3\n            # l2_regularizer = 0.00010124894257897855\n            if DO_CNN:\n                learning_rate = 1.4286522423518213e-05\n                dropout_rate = 0.2\n                l2_regularizer = 0.000417822262290105\n                # Start the timer\n                start_time = time.time()\n                perform_cross_validation(X_filtered, y, learning_rate, dropout_rate, l2_regularizer,\n                                        n_splits=DL_CV_FOLD, epochs=DL_EPOCH, batch_size=DL_BATCH_SIZE, cnn_version=DL_CNN_VERSION,\n                                        do_opt=True, models_folder=dl_cv_models_folder, results_folder=dl_cv_results_folder)\n                # End the timer\n                end_time = time.time()\n                # Calculate the elapsed time\n                elapsed_time = end_time - start_time\n                # Print the elapsed time\n                print(\"Training time: {:.2f} seconds\".format(elapsed_time))\n            elif DO_TRANSFORMER_VISION:\n                # Train and evaluate deep learning models\n                print(\"Building Transformer model...\")\n                patch_size = 30\n                embed_dim = 64\n                num_heads = 4\n                mlp_dim = 128  # patch_size * patch_size * input_shape[1]\n                num_layers = 4\n                dropout_rate = 0.3\n\n                # Create the model\n                perform_vit_cross_validation(X_filtered, y, patch_size, embed_dim, num_heads, mlp_dim, num_layers, dropout_rate,\n                                            n_splits=DL_CV_FOLD, epochs=DL_EPOCH, batch_size=DL_BATCH_SIZE, \n                                            vit_version = DL_TRANSFORMER_VISION_VERSION, val_set = 0.2,\n                                            do_opt = True, models_folder = \"/kaggle/working/CV_VIT_models\", results_folder = \"/kaggle/working/CV_VIT_results\")\n\n        else:\n            # Reshape the input data for deep learning models\n            print(\"Reshaping the data for CNN model...\")\n            X_train = X_train.reshape(\n                X_train.shape[0], X_train.shape[1], 1)\n            X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n            input_shape = (X_train.shape[1], 1)\n            num_classes = len(np.unique(y_train))\n\n            # Splitting the training data to create a validation set\n            print(\"Splitting the training data to create a validation set...\")\n            X_train, X_val, y_train, y_val = train_test_split(\n                X_train, y_train, test_size=VAL_SET, random_state=SEED, stratify=y_train)\n\n            filepath = \"\"\n\n            if DO_CNN:\n                # Train and evaluate deep learning models\n                print(\"Building CNN model...\")\n                # model = cnn_model_3_3(input_shape, num_classes)\n                # learning_rate = 3.408170980489466e-05\n                # dropout_rate = 0.3\n                # l2_regularizer = 0.00010124894257897855\n                learning_rate = 1.4286522423518213e-05\n                dropout_rate = 0.2\n                l2_regularizer = 0.000417822262290105\n                model = cnn_model_3_opt(\n                    input_shape, num_classes, learning_rate, dropout_rate, l2_regularizer)\n\n                filepath = '../During_train/cnn_v3-{epoch:02d}-val_acc{val_accuracy:.2f}.h5'\n\n            elif DO_TRANSFORMER_VISION:\n                # Train and evaluate deep learning models\n                print(\"Building Transformer model...\")\n                # Define model parameters\n                print(f\"X_train shape = {X_train.shape}\")\n                input_shape = (X_train.shape[1], 1)  # (270,1)\n                # cancer cell lines, monocytes, and T-cells\n                num_classes = len(np.unique(y_train))\n                patch_size = 3\n                num_patches = input_shape[0] // patch_size\n                embed_dim = 64\n                num_heads = 4\n                mlp_dim = 128  # patch_size * patch_size * input_shape[1]\n                num_layers = 4\n                dropout_rate = 0.3\n\n                # Create the model\n                model = create_vit(input_shape, patch_size, num_patches, num_classes,\n                                   embed_dim, num_heads, mlp_dim, num_layers, dropout_rate)\n                model.summary()\n                # Compile the model\n                model.compile(\n                    optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n                filepath = '../During_train/vit_v11-{epoch:02d}-val_acc{val_accuracy:.2f}.h5'\n\n            # Train the model\n            print(\"Training and evaluating the model...\")\n            # Start the timer\n            start_time = time.time()\n            model_history = model.fit(X_train, y_train, batch_size=DL_BATCH_SIZE,\n                                      epochs=DL_EPOCH, validation_data=(X_val, y_val), shuffle=True, callbacks=callbacks)\n            # End the timer\n            end_time = time.time()\n            # Calculate the elapsed time\n            elapsed_time = end_time - start_time\n            # Print the elapsed time\n            print(\"Training time: {:.2f} seconds\".format(elapsed_time))\n            # Compile the model\n\n            # Save the deep learning model\n            print(\"Saving model to \", dl_model_path)\n            model.save(dl_model_path)\n\n            # Save the deep learning model's weights\n            print(\"Saving model weights to \", dl_weights_path)\n            model.save_weights(dl_weights_path)\n\n            # Evaluating the model\n            print(\"Evaluating the CNN model... \")\n            # Calculate model loss and accuracy\n            test_loss, test_accuracy = model.evaluate(X_test, y_test)\n            print(\"Test loss:\", test_loss)\n            print(\"Test accuracy:\", test_accuracy)\n\n            # Save the model's metrics\n            print(\"Saving the model metrics to \", dl_metrics_path)\n            save_dl_metrics(model_history, test_loss,\n                            test_accuracy, dl_metrics_path)\n\n            # Plot the model history\n            plot_dl_history(model_history)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T04:23:34.324670Z","iopub.execute_input":"2023-07-11T04:23:34.325041Z","iopub.status.idle":"2023-07-11T04:44:48.604075Z","shell.execute_reply.started":"2023-07-11T04:23:34.325008Z","shell.execute_reply":"2023-07-11T04:44:48.603079Z"},"trusted":true},"execution_count":null,"outputs":[]}]}