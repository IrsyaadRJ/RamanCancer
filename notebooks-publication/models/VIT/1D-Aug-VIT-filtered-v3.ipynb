{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7243680,"sourceType":"datasetVersion","datasetId":4195789},{"sourceId":7243692,"sourceType":"datasetVersion","datasetId":4195798},{"sourceId":7243705,"sourceType":"datasetVersion","datasetId":4195809}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/input/chemcancer-v2/src/\n%mkdir /kaggle/working/Deep_Learning_metrics/\n%mkdir /kaggle/working/During_train/\n%mkdir /kaggle/working/CV_VIT_models\n%mkdir /kaggle/working/CV_VIT_results\n%mkdir /kaggle/working/CV_fold_data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-21T04:26:52.476327Z","iopub.execute_input":"2023-12-21T04:26:52.477215Z","iopub.status.idle":"2023-12-21T04:26:57.896534Z","shell.execute_reply.started":"2023-12-21T04:26:52.477177Z","shell.execute_reply":"2023-12-21T04:26:57.895037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom tensorflow.keras.optimizers import Adam\nfrom data import *\nfrom machine_learning_models import *\nfrom deep_learning_models import *\nfrom vision_transformer import *\nfrom utils_dl_model import *\nfrom utils_ml_model import print_ml_results\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2023-12-21T04:26:57.899140Z","iopub.execute_input":"2023-12-21T04:26:57.899487Z","iopub.status.idle":"2023-12-21T04:26:57.906339Z","shell.execute_reply.started":"2023-12-21T04:26:57.899458Z","shell.execute_reply":"2023-12-21T04:26:57.905279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the seed value.\nSEED = 7\nnp.random.seed(SEED)\n\n# Deep Learning parameters\nDL_EPOCH = 100\nDL_BATCH_SIZE = 32\nDL_CNN_VERSION = 3\nDL_TRANSFORMER_VISION_VERSION = 14\nDL_CV_FOLD = 5\n\nDO_DL = True\nCV_DL = True\nOPT_DL = False\n\nDO_CNN = False\nDO_TRANSFORMER_VISION = True\nDO_ML = False\n\n# Percentage of test set out of the dataset.\nTEST_SET = 0.2\n\n# Percentage of validation set out of the training dataset.\nVAL_SET = 0.2\n\n# Folder path associated with deep learning models\ndl_models_folder = \"../Deep_Learning_models/\"\ndl_metrics_folder = \"../Deep_Learning_metrics/\"\ndl_weights_folder = \"../Deep_Learning_weights/\"\ndl_cv_models_folder = \"../Deep_Learning_CV/\"\ndl_cv_results_folder = \"../Deep_Learning_CV_results/\"\n\n# Folder path associated with machine learning models\nml_models_folder = \"../Machine_Learning_models/\"\nml_models_results_folder = \"../Machine_Learning_models_results/\"\n\n# Model names (Saved in h5 format)\ncnn_model_name = f\"cnn_v{DL_CNN_VERSION}_{DL_BATCH_SIZE}_{DL_EPOCH}_seed_{SEED}.h5\"\ntransformer_vis_model_name = f\"transformer_vision_v{DL_TRANSFORMER_VISION_VERSION}_{DL_BATCH_SIZE}_{DL_EPOCH}_seed_{SEED}.h5\"\n\n# Metric filenames\ncnn_metrics_filename = f\"metrics_{cnn_model_name}.json\"\ntransformer_vis_metrics_filename = f\"metrics_{transformer_vis_model_name}.json\"\n\n# Weight filenames\ncnn_weights_filename = f\"weights_{cnn_model_name}.json\"\ntransformer_vis_weights_filename = f\"weights_{transformer_vis_model_name}.json\"\n\n\n# Deep Learning models path\nif DO_CNN:\n    dl_model_path = os.path.join(\n        dl_models_folder, cnn_model_name)\nelif DO_TRANSFORMER_VISION:\n    dl_model_path = os.path.join(\n        dl_models_folder, transformer_vis_model_name)\n\n\n# Deep Learning metrics path\nif DO_CNN:\n    dl_metrics_path = os.path.join(\n        dl_metrics_folder, cnn_metrics_filename)\nelif DO_TRANSFORMER_VISION:\n    dl_metrics_path = os.path.join(\n        dl_metrics_folder, transformer_vis_metrics_filename)\n\n\n# Deep Learning weights path\nif DO_CNN:\n    dl_weights_path = os.path.join(\n        dl_weights_folder, cnn_weights_filename)\n\nelif DO_TRANSFORMER_VISION:\n    dl_weights_path = os.path.join(\n        dl_weights_folder, transformer_vis_weights_filename)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T04:30:20.943974Z","iopub.execute_input":"2023-12-21T04:30:20.944332Z","iopub.status.idle":"2023-12-21T04:30:20.955607Z","shell.execute_reply.started":"2023-12-21T04:30:20.944303Z","shell.execute_reply":"2023-12-21T04:30:20.954677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\ndef perform_vit_cross_validation(X_original, y_original, X_augmented, y_augmented, patch_size, embed_dim, num_heads, mlp_dim, num_layers, dropout_rate,\n                                 n_splits=5, epochs=100, batch_size=32, vit_version = 1, val_set = 0.2,\n                                 do_opt = False,models_folder = \"models\", results_folder = \"results\"):\n    \n    if not os.path.exists(models_folder):\n        os.makedirs(models_folder)\n\n    if not os.path.exists(results_folder):\n        os.makedirs(results_folder)\n        \n    # Initialize variables for tracking the best model\n    best_val_accuracy = 0\n    best_model_filepath = \"\"\n    \n    accuracies = []\n    test_losses = []\n    test_accuracies = []\n    \n    # Initialize lists to store precision, recall, and F1 scores\n    precisions = []\n    recalls = []\n    f1_scores = []\n    \n    # Initialize lists to store losses and accuracies for each epoch\n    mean_training_losses = []\n    mean_training_accuracies = []\n    mean_val_losses = []   \n    mean_val_accuracies = []\n    \n    fold = 1\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_value)\n    skf_augmented = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_value)\n    \n    for train_index, _ in skf_augmented.split(X_augmented, y_augmented):\n        # We are only interested in the train index for augmented data\n        # Select the augmented data for training\n        print(\"=\" * 40)\n        print(f\"Fold: {fold}\")\n        print(\"Selecting the augmented data\")\n        \n        X_train = X_augmented[train_index]\n        y_train = y_augmented[train_index]\n        X_ori = X_original\n        \n        print(\"Apply Filters\")\n        X_train =  apply_filters_and_background_subtraction(X_train)\n        X_ori =  apply_filters_and_background_subtraction(X_ori)\n            \n        # Standardize the data\n        print(\"Standardizing the data\")\n        X_train, X_ori = standardize_data(X_train, X_ori)\n        \n        # Reshape the data\n        print(\"Reshaping the data for deep learning models\")\n        X_train, X_ori = reshape_data(X_train, X_ori)\n        \n        # Input shape and number of classes for the model\n        input_shape = (X_train.shape[1], 1)\n        num_classes = len(np.unique(y_original))\n        \n        # Split a portion of the original data for validation and testing (stratified based on y_original)\n        X_val, X_test, y_val, y_test = train_test_split(X_ori, y_original, test_size = 0.7, random_state = seed_value, stratify = y_original)\n        \n        print(f\"X_train shape: {X_train.shape}\")\n        print(f\"X_test shape: {X_test.shape}\")\n        print(f\"X_val shape: {X_val.shape}\")\n        \n        num_patches = input_shape[0] // patch_size\n        try:\n            if do_opt:\n                # Create the model\n                model = create_vit(input_shape, patch_size, num_patches, num_classes,\n                                embed_dim, num_heads, mlp_dim, num_layers, dropout_rate)\n                model.summary()\n                # Compile the model\n                model.compile(\n#                     optimizer=Adam(learning_rate=0.0001), loss=weighted_sparse_categorical_crossentropy(class_weights), metrics=['accuracy'])\n                    optimizer=Adam(learning_rate = 1e-4),loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n            else:\n                # Create the model\n                print(\"Building the vit model with the following hyperparameters:\")\n                print(f\"Patch size: {learning_rate}\")\n                print(f\"num_patches: {num_patches}\") \n                print(f\"embed_dim: {embed_dim}\")\n                print(f\"num_heads: {num_heads}\")\n                print(f\"mlp_dim: {mlp_dim}\")\n                print(f\"num_layers: {num_layers}\")\n                print(f\"dropout_rate: {dropout_rate}\")\n                model = create_vit(input_shape, patch_size, num_patches, num_classes,\n                                embed_dim, num_heads, mlp_dim, num_layers, dropout_rate)\n                model.summary()\n                # Compile the model\n                model.compile(\n#                     optimizer=Adam(learning_rate=0.0001), loss=weighted_sparse_categorical_crossentropy(class_weights), metrics=['accuracy'])\n                    optimizer=Adam(learning_rate = 1e-4),loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n            if model is not None:\n                \"Build VIT\"\n                # model.summary()\n            else:\n                print(\"Failed to build the VIT model.\")\n        except Exception as e:\n            print(f\"Error while building the VIT model: {e}\")\n        \n        print(\"Saving the data\")\n        fold_data = {\n\n            'X_train': X_train,\n            'X_val': X_val,\n            'X_test': X_test,\n            'y_train': y_train,\n            'y_val': y_val,\n            'y_test': y_test\n        }\n\n        with open(f\"/kaggle/working/CV_fold_data/fold_{fold}_data.pkl\", 'wb') as f:\n            pickle.dump(fold_data, f)\n            \n        filepath = f'/kaggle/working/CV_VIT_models/temp_best_fold_{fold}.h5'\n        # the ModelCheckpoint callback to save the best model of the current fold\n        model_checkpoint_callback = ModelCheckpoint(\n            filepath=os.path.join(filepath),\n            save_best_only=True,\n            monitor='val_accuracy',\n            mode='max'\n        )\n        \n        print(\"Training the model\")\n        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val),\n                           callbacks=[model_checkpoint_callback])\n         \n        # Check if this model is the best so far\n        max_val_accuracy_this_fold = max(history.history['val_accuracy'])\n        if max_val_accuracy_this_fold > best_val_accuracy:\n            best_val_accuracy = max_val_accuracy_this_fold\n            best_model_filepath = filepath\n            \n        if best_model_filepath:\n            best_model = tf.keras.models.load_model(\n                best_model_filepath,\n                custom_objects={'ClassToken': ClassToken, 'TransformerBlock': TransformerBlock})\n#                     'loss': weighted_sparse_categorical_crossentropy(class_weights)}}\n            print(f\"The best model was loaded and ready to be evaluated\")\n        \n        \n        \n        y_pred = np.argmax(model.predict(X_test), axis=-1)\n        accuracy = accuracy_score(y_test, y_pred)\n        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n        \n            # Calculate precision, recall, and F1 score\n        precision = precision_score(y_test, y_pred, average='macro')\n        recall = recall_score(y_test, y_pred, average='macro')\n        f1 = f1_score(y_test, y_pred, average='macro')\n\n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n\n        # Append the scores to the lists\n        precisions.append(precision)\n        recalls.append(recall)\n        f1_scores.append(f1)\n        \n        # Append the losses and accuracies for each epoch to the respective lists\n        for epoch in range(epochs):\n            if fold == 1:\n                # For the first fold, initialize the lists with the first fold's values\n                mean_training_losses.append(history.history['loss'][epoch])\n                mean_training_accuracies.append(history.history['accuracy'][epoch])\n                mean_val_losses.append(history.history['val_loss'][epoch])\n                mean_val_accuracies.append(history.history['val_accuracy'][epoch])\n            else:\n                # For subsequent folds, add the fold's values to the running sum\n                mean_training_losses[epoch] += history.history['loss'][epoch]\n                mean_training_accuracies[epoch] += history.history['accuracy'][epoch]\n                mean_val_losses[epoch] += history.history['val_loss'][epoch]\n                mean_val_accuracies[epoch] += history.history['val_accuracy'][epoch]\n\n        # Save the model\n        if do_opt:\n            model_filename = f\"VIT_v{vit_version}_opt_{batch_size}_{epochs}_seed{seed_value}.h5\"\n        else:\n            model_filename = f\"VIT_v{vit_version}_{batch_size}_{epochs}_seed{seed_value}.h5\"\n        model_filepath = os.path.join(models_folder, f\"fold_{fold}_split_{n_splits}_{model_filename}\")\n        model.save(model_filepath)\n\n        # Save the results as a JSON file\n        if do_opt:\n            results_filename = f\"VIT_v{vit_version}_opt_{batch_size}_{epochs}_seed{seed_value}.json\"\n        else:\n            results_filename = f\"VIT_v{vit_version}_{batch_size}_{epochs}_seed{seed_value}.json\"\n        results_filepath = os.path.join(results_folder, f\"fold_{fold}_split_{n_splits}_{results_filename}\")\n\n        results = {\n            \"fold\": fold,\n            \"accuracy\": accuracy,\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1_scores\": f1_scores,\n            \"test_loss\": test_loss,\n            \"test_accuracy\": test_accuracy,\n            \"training_loss\": history.history['loss'],\n            \"training_accuracy\": history.history['accuracy'],\n            \"validation_loss\": history.history['val_loss'],\n            \"validation_accuracy\": history.history['val_accuracy'],\n        }\n\n        with open(results_filepath, \"w\") as results_file:\n            json.dump(results, results_file, indent=4)\n        \n        # Append the results to the lists\n        accuracies.append(accuracy)\n        test_losses.append(test_loss)\n        test_accuracies.append(test_accuracy)\n        \n        print(f\"Fold {fold}, Accuracy: {accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n        print(\"=\" * 40)\n        fold += 1\n\n    # At the end, divide the sums by the number of folds to get the mean\n    mean_training_losses = [loss / n_splits for loss in mean_training_losses]\n    mean_training_accuracies = [acc / n_splits for acc in mean_training_accuracies]\n    mean_val_losses = [loss / n_splits for loss in mean_val_losses]\n    mean_val_accuracies = [acc / n_splits for acc in mean_val_accuracies]\n    # Convert lists to numpy arrays for easier calculation of mean and standard deviation\n    mean_accuracy = np.mean(accuracies)\n    mean_test_loss = np.mean(test_losses)\n    mean_test_accuracy = np.mean(test_accuracies)\n\n    # Calculate standard deviations\n    std_accuracy = np.std(accuracies)\n    std_test_loss = np.std(test_losses)\n    std_test_accuracy = np.std(test_accuracies)\n\n    std_training_loss = np.std(mean_training_losses)\n    std_training_accuracy = np.std(mean_training_accuracies)\n    std_val_loss = np.std(mean_val_losses)\n    std_val_accuracy = np.std(mean_val_accuracies)\n\n    precisions = np.array(precisions)\n    recalls = np.array(recalls)\n    f1_scores = np.array(f1_scores)\n\n      \n    print(f\"test losses: {test_losses}\")\n    print(f\"test accuracy: {test_accuracies}\")\n    \n    print(\"*\" * 40)\n    print(f\"Mean training loss over stratified {n_splits}-fold cross-validation: {np.mean(mean_training_losses):.4f}\")\n    print(f\"Mean training accuracy over stratified {n_splits}-fold cross-validation: {np.mean(mean_training_accuracies):.4f}\")\n    print(f\"Mean validation loss over stratified {n_splits}-fold cross-validation: {np.mean(mean_val_losses):.4f}\")\n    print(f\"Mean validation accuracy over stratified {n_splits}-fold cross-validation: {np.mean(mean_val_accuracies):.4f}\")\n    print(\"*\" * 40)\n    print(f\"Mean accuracy over stratified {n_splits}-fold cross-validation: {mean_accuracy:.4f}\")\n    print(f\"Mean test loss over stratified {n_splits}-fold cross-validation: {mean_test_loss:.4f}\")\n    print(f\"Mean test accuracy over stratified {n_splits}-fold cross-validation: {mean_test_accuracy:.4f}\")\n    print(\"*\" * 40)\n\n    print(f\"Standard deviation of training loss over stratified {n_splits}-fold cross-validation: {np.std(mean_training_losses):.4f}\")\n    print(f\"Standard deviation of training accuracy over stratified {n_splits}-fold cross-validation: {np.std(mean_training_accuracies):.4f}\")\n    print(f\"Standard deviation of validation loss over stratified {n_splits}-fold cross-validation: {np.std(mean_val_losses):.4f}\")\n    print(f\"Standard deviation of validation accuracy over stratified {n_splits}-fold cross-validation: {np.std(mean_val_accuracies):.4f}\")\n    print(\"*\" * 40)\n    print(f\"Standard deviation of accuracy over stratified {n_splits}-fold cross-validation: {std_accuracy:.4f}\")\n    print(f\"Standard deviation of test loss over stratified {n_splits}-fold cross-validation: {std_test_loss:.4f}\")\n    print(f\"Standard deviation of test accuracy over stratified {n_splits}-fold cross-validation: {std_test_accuracy:.4f}\")\n    print(\"*\" * 40)\n    \n    # Calculate and print the mean and standard deviation of precision, recall, and F1 score\n    print(f\"Mean precision over stratified {n_splits}-fold cross-validation: {np.mean(precisions):.4f}\")\n    print(f\"Standard deviation of precision over stratified {n_splits}-fold cross-validation: {np.std(precisions):.4f}\")\n    print(f\"Mean recall over stratified {n_splits}-fold cross-validation: {np.mean(recalls):.4f}\")\n    print(f\"Standard deviation of recall over stratified {n_splits}-fold cross-validation: {np.std(recalls):.4f}\")\n    print(f\"Mean F1 score over stratified {n_splits}-fold cross-validation: {np.mean(f1_scores):.4f}\")\n    print(f\"Standard deviation of F1 score over stratified {n_splits}-fold cross-validation: {np.std(f1_scores):.4f}\")\n\n    \n# Define the directory where the JSON files are stored\n\n    fig, axes = plt.subplots(2, n_splits, figsize=(20, 10))\n\n    for fold in range(1, n_splits+1):\n        # Load the JSON file for this fold\n        if do_opt:\n            cnn_filename = f\"VIT_v{vit_version}_opt_{batch_size}_{epochs}_seed{seed_value}.json\"\n        else:\n            cnn_filename = f\"VIT_v{vit_version}_{batch_size}_{epochs}_seed{seed_value}.json\"\n        results_filename = f\"fold_{fold}_split_{n_splits}_{cnn_filename}\"\n        \n        results_filepath = os.path.join(results_folder, results_filename)\n        \n        with open(results_filepath, \"r\") as results_file:\n            results = json.load(results_file)\n        \n        # Plot training and validation loss\n        axes[0, fold-1].plot(results[\"training_loss\"], label='Train')\n        axes[0, fold-1].plot(results[\"validation_loss\"], label='Validation')\n        axes[0, fold-1].set_title(f'Fold {fold} Loss')\n        axes[0, fold-1].set_xlabel('Epochs')\n        axes[0, fold-1].set_ylabel('Loss')\n        axes[0, fold-1].legend()\n\n        # Plot training and validation accuracy\n        axes[1, fold-1].plot(results[\"training_accuracy\"], label='Train')\n        axes[1, fold-1].plot(results[\"validation_accuracy\"], label='Validation')\n        axes[1, fold-1].set_title(f'Fold {fold} Accuracy')\n        axes[1, fold-1].set_xlabel('Epochs')\n        axes[1, fold-1].set_ylabel('Accuracy')\n        axes[1, fold-1].legend()\n\n    plt.tight_layout()\n    plt.show()\n    \n    return mean_val_accuracies  ","metadata":{"execution":{"iopub.status.busy":"2023-12-21T04:26:57.964244Z","iopub.execute_input":"2023-12-21T04:26:57.964595Z","iopub.status.idle":"2023-12-21T04:26:58.016453Z","shell.execute_reply.started":"2023-12-21T04:26:57.964570Z","shell.execute_reply":"2023-12-21T04:26:58.015484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_data_from_csv(filename=\"generated_data.csv\"):\n    # Read the CSV file into a DataFrame\n    df_extracted = pd.read_csv(filename)\n    \n    # Split the DataFrame into features and labels\n    X_extracted = df_extracted.drop(columns=[\"labels\"]).values\n    y_extracted = df_extracted[\"labels\"].values\n    \n    return X_extracted, y_extracted","metadata":{"execution":{"iopub.status.busy":"2023-12-21T04:26:58.017690Z","iopub.execute_input":"2023-12-21T04:26:58.018001Z","iopub.status.idle":"2023-12-21T04:26:58.034192Z","shell.execute_reply.started":"2023-12-21T04:26:58.017976Z","shell.execute_reply":"2023-12-21T04:26:58.033318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# With bksb, slope and roll set to true\ntest_data= \"/kaggle/input/test-gen-cc-10x-v4/test-gen-cc-10x-v4.csv\"\n\n# No bksb, slope and roll set to false\ntrain_data = \"/kaggle/input/gen-cc-10x-v4/gen-cc-10x-v4.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-12-21T04:26:58.035241Z","iopub.execute_input":"2023-12-21T04:26:58.035531Z","iopub.status.idle":"2023-12-21T04:26:58.046372Z","shell.execute_reply.started":"2023-12-21T04:26:58.035507Z","shell.execute_reply":"2023-12-21T04:26:58.045380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_augmented, y_augmented = extract_data_from_csv(train_data)\nprint(f\"X_augmented shaped: {X_augmented.shape}\")\nprint(f\"y_augmented shaped: {y_augmented.shape}\")\n\nX_original, y_original = extract_data_from_csv(test_data)\nprint(f\"X_original shaped: {X_original.shape}\")\nprint(f\"y_original shaped: {y_original.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T04:26:58.047645Z","iopub.execute_input":"2023-12-21T04:26:58.047956Z","iopub.status.idle":"2023-12-21T04:26:59.274918Z","shell.execute_reply.started":"2023-12-21T04:26:58.047930Z","shell.execute_reply":"2023-12-21T04:26:59.273911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nif CV_DL:\n    if DO_TRANSFORMER_VISION:\n        # Train and evaluate deep learning models\n        print(\"Building Transformer model...\")\n        patch_size = 30\n        embed_dim = 32\n        num_heads = 8\n        mlp_dim = 32  # patch_size * patch_size * input_shape[1]\n        num_layers = 1\n        dropout_rate = 0.4\n\n        # Create the model\n        perform_vit_cross_validation(X_original, y_original, X_augmented, y_augmented, patch_size, embed_dim, num_heads, mlp_dim, num_layers, dropout_rate,\n                                    n_splits=DL_CV_FOLD, epochs=DL_EPOCH, batch_size=DL_BATCH_SIZE, \n                                    vit_version = DL_TRANSFORMER_VISION_VERSION, val_set = 0.2,\n                                    do_opt = True, models_folder = \"/kaggle/working/CV_VIT_models\", results_folder = \"/kaggle/working/CV_VIT_results\")\n\n    # Train the model\n    print(\"Training and evaluating the model...\")\n    # Start the timer\n    start_time = time.time()\n    model_history = model.fit(X_train, y_train, batch_size=DL_BATCH_SIZE,\n                              epochs=DL_EPOCH, validation_data=(X_val, y_val), shuffle=True, callbacks=callbacks)\n    # End the timer\n    end_time = time.time()\n    # Calculate the elapsed time\n    elapsed_time = end_time - start_time\n    # Print the elapsed time\n    print(\"Training time: {:.2f} seconds\".format(elapsed_time))\n    # Compile the model\n\n    # Save the deep learning model\n    print(\"Saving model to \", dl_model_path)\n    model.save(dl_model_path)\n\n    # Save the deep learning model's weights\n    print(\"Saving model weights to \", dl_weights_path)\n    model.save_weights(dl_weights_path)\n\n    # Evaluating the model\n    print(\"Evaluating the CNN model... \")\n    # Calculate model loss and accuracy\n    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n    print(\"Test loss:\", test_loss)\n    print(\"Test accuracy:\", test_accuracy)\n\n    # Save the model's metrics\n    print(\"Saving the model metrics to \", dl_metrics_path)\n    save_dl_metrics(model_history, test_loss,\n                    test_accuracy, dl_metrics_path)\n\n    # Plot the model history\n    plot_dl_history(model_history)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T04:30:29.774866Z","iopub.execute_input":"2023-12-21T04:30:29.775240Z","iopub.status.idle":"2023-12-21T04:57:17.376177Z","shell.execute_reply.started":"2023-12-21T04:30:29.775211Z","shell.execute_reply":"2023-12-21T04:57:17.374885Z"},"trusted":true},"execution_count":null,"outputs":[]}]}