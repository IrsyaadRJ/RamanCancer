{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6115123,"sourceType":"datasetVersion","datasetId":3504592},{"sourceId":7169667,"sourceType":"datasetVersion","datasetId":4142249},{"sourceId":7169671,"sourceType":"datasetVersion","datasetId":4142252}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/input/chemcancer-v2/src/\n%mkdir /kaggle/working/Machine_Learning_models/\n%mkdir /kaggle/working/Machine_Learning_models_results/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-23T07:19:54.157023Z","iopub.execute_input":"2023-12-23T07:19:54.157390Z","iopub.status.idle":"2023-12-23T07:19:56.134288Z","shell.execute_reply.started":"2023-12-23T07:19:54.157358Z","shell.execute_reply":"2023-12-23T07:19:56.132925Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/chemcancer-v2/src\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom tensorflow.keras.optimizers import Adam\nfrom data import *\nfrom machine_learning_models import *\nfrom deep_learning_models import *\nfrom vision_transformer import *\nfrom utils_dl_model import *\nfrom utils_ml_model import print_ml_results\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:19:56.136080Z","iopub.execute_input":"2023-12-23T07:19:56.136498Z","iopub.status.idle":"2023-12-23T07:20:05.270745Z","shell.execute_reply.started":"2023-12-23T07:19:56.136457Z","shell.execute_reply":"2023-12-23T07:20:05.269749Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the seed value.\nSEED = 7\nnp.random.seed(SEED)\n\n# Deep Learning parameters\nDL_EPOCH = 500\nDL_BATCH_SIZE = 32\nDL_CNN_VERSION = 3\nDL_TRANSFORMER_VISION_VERSION = 11\nDL_BLS_VERSION = 1\n\nDO_DL = False\nCV_DL = True\nOPT_DL = False\n\nDO_CNN = False\nDO_TRANSFORMER_VISION = False\nDO_BLS = False\nDO_ML = True\n\n# Percentage of test set out of the dataset.\nTEST_SET = 0.2\n\n# Percentage of validation set out of the training dataset.\nVAL_SET = 0.2\n\n# Folder path associated with machine learning models\nml_models_folder = \"/kaggle/working/Machine_Learning_models/\"\nml_models_results_folder = \"/kaggle/working/Machine_Learning_models_results/\"","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:20:05.271941Z","iopub.execute_input":"2023-12-23T07:20:05.272513Z","iopub.status.idle":"2023-12-23T07:20:05.278596Z","shell.execute_reply.started":"2023-12-23T07:20:05.272485Z","shell.execute_reply":"2023-12-23T07:20:05.277673Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_confusion_matrices(results):\n    \"\"\"\n    Function to plot confusion matrices one by one.\n    \n    Parameters:\n    results (dict): Dictionary containing the results of the machine learning models\n    \"\"\"\n    for name, result in results.items():\n        # Create a new figure for each model\n        plt.figure(figsize=(5, 5))\n        \n        # Generate a confusion matrix heatmap\n        confusion_matrix = np.array(result['Confusion Matrix'])\n        sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap=\"Blues\")\n        \n        # Set the plot labels\n        plt.title(f'{name}')\n        plt.xlabel('Predicted Label')\n        plt.ylabel('True Label')\n        \n        # Display the plot\n        plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:20:05.279983Z","iopub.execute_input":"2023-12-23T07:20:05.280556Z","iopub.status.idle":"2023-12-23T07:20:05.488240Z","shell.execute_reply.started":"2023-12-23T07:20:05.280522Z","shell.execute_reply":"2023-12-23T07:20:05.487272Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def preprocess_with_pca(X, variance_threshold=0.95):\n    \"\"\"\n    Preprocesses the data using PCA, selecting the number of components\n    such that the specified variance threshold is retained.\n\n    :param X: The already standardized input data.\n    :param variance_threshold: The threshold for explained variance.\n    :return: Data transformed by PCA and the PCA model.\n    \"\"\"\n    pca_temp = PCA()\n    pca_temp.fit(X)\n    cumulative_variance_ratio = np.cumsum(pca_temp.explained_variance_ratio_)\n    n_components = np.argmax(cumulative_variance_ratio >= variance_threshold) + 1\n#\n    pca = PCA(n_components)\n    X_pca = pca.fit_transform(X)\n\n    print(f\"PCA with {n_components} components retaining {variance_threshold * 100}% of variance\")\n    \n    return X_pca, pca\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:20:05.489455Z","iopub.execute_input":"2023-12-23T07:20:05.489740Z","iopub.status.idle":"2023-12-23T07:20:05.495818Z","shell.execute_reply.started":"2023-12-23T07:20:05.489716Z","shell.execute_reply":"2023-12-23T07:20:05.494814Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\ndef load_extract_data(data_file):\n    # Load the data\n    print(\"Load the data\")\n    data = load_data(data_file)\n    print(f\"Data shape : {data.shape}\")\n\n    # Extract the feature and target data\n    print(\"Extract the feature and target data\")\n    X, y = extract_data(data)\n    print(f\"X shaped: {X.shape}\")\n    print(f\"y shaped: {y.shape}\")\n\n    return X, y\n\ndef extract_data_from_csv(filename=\"generated_data.csv\"):\n    # Read the CSV file into a DataFrame\n    df_extracted = pd.read_csv(filename)\n    \n    # Split the DataFrame into features and labels\n    X_extracted = df_extracted.drop(columns=[\"labels\"]).values\n    y_extracted = df_extracted[\"labels\"].values\n    \n    return X_extracted, y_extracted","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:20:05.498230Z","iopub.execute_input":"2023-12-23T07:20:05.498495Z","iopub.status.idle":"2023-12-23T07:20:05.509998Z","shell.execute_reply.started":"2023-12-23T07:20:05.498472Z","shell.execute_reply":"2023-12-23T07:20:05.509148Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n\ndef compute_tp_tn_fp_fn_percentage(y_test, y_pred, class_label):\n    \"\"\"\n    Function to compute the True Positives (TP), True Negatives (TN),\n    False Positives (FP), and False Negatives (FN) for a specific class as percentages.\n    \"\"\"\n    cm = confusion_matrix(y_test, y_pred)\n    total_samples = np.sum(cm)\n\n    tp = cm[class_label, class_label] / total_samples\n    fp = (sum(cm[:, class_label]) - cm[class_label, class_label]) / total_samples\n    fn = (sum(cm[class_label, :]) - cm[class_label, class_label]) / total_samples\n    tn = (total_samples - (tp + fp + fn)) / total_samples\n\n    return tp, tn, fp, fn\n\n# Replace compute_tp_tn_fp_fn with compute_tp_tn_fp_fn_percentage in the function train_and_evaluate_ml_models\ndef train_and_evaluate_ml_models(models, X, y, apply_pca=False, pca_variance_threshold=0.95, apply_filters_bg_subtraction=False, cv=5, standardize_data_func=None):\n    results = {}\n\n    # Create a StratifiedKFold object\n    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n    \n    for name, model in models.items():\n        fold_metrics = {\n            'accuracy': [],\n            'precision': [],\n            'recall': [],\n            'f1_score': [],\n            'confusion_matrix': [],\n            'tp_tn_fp_fn': [],\n            'tp': [],\n            'tn': [],\n            'fp': [],\n            'fn': []\n        }\n\n        # Perform stratified cross-validation\n        for train_index, test_index in skf.split(X, y):\n            X_train, X_test = X[train_index], X[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n            \n            # Apply filters and background subtraction if enabled\n            if apply_filters_bg_subtraction:\n                print(\"Apply filters and background subtraction\")\n                X_train = apply_filters_and_background_subtraction(X_train)\n                X_test = apply_filters_and_background_subtraction(X_test)\n            \n           # Standardize data if a standardization function is provided\n            if standardize_data_func is not None:\n                print(\"Standardize the data\")\n                X_train, X_test = standardize_data_func(X_train, X_test)\n\n            # Apply PCA if enabled\n            if apply_pca:\n                print(\"Apply PCA\")\n                pca = PCA(n_components=pca_variance_threshold)\n                X_train = pca.fit_transform(X_train)\n                X_test = pca.transform(X_test)\n            \n            # Train the model\n            print(f\"Training {name} model...\")\n            model.fit(X_train, y_train)\n\n            # Evaluate the model\n            print(f\"Evaluating {name} model...\")\n            y_pred = model.predict(X_test)\n            accuracy = accuracy_score(y_test, y_pred)\n            precision = precision_score(y_test, y_pred, average='macro')\n            recall = recall_score(y_test, y_pred, average='macro')\n            f1 = f1_score(y_test, y_pred, average='macro')\n            confusion = confusion_matrix(y_test, y_pred)\n\n            # Compute TP, TN, FP, FN for each class\n            tp_tn_fp_fn = {class_label: compute_tp_tn_fp_fn_percentage(y_test, y_pred, class_label) for class_label in range(len(np.unique(y)))}\n\n            # Append the tp, tn, fp, fn values to the corresponding lists\n            for class_label, (tp, tn, fp, fn) in tp_tn_fp_fn.items():\n                fold_metrics['tp'].append(tp)\n                fold_metrics['tn'].append(tn)\n                fold_metrics['fp'].append(fp)\n                fold_metrics['fn'].append(fn)\n\n            fold_metrics['accuracy'].append(accuracy)\n            fold_metrics['precision'].append(precision)\n            fold_metrics['recall'].append(recall)\n            fold_metrics['f1_score'].append(f1)\n            fold_metrics['confusion_matrix'].append(confusion)\n            fold_metrics['tp_tn_fp_fn'].append(tp_tn_fp_fn)\n\n        # Calculate the mean and standard deviation of the metrics from the CV folds\n        results[name] = {\n            'CV': cv,\n            'Accuracy': np.mean(fold_metrics['accuracy']),\n            'Precision': np.mean(fold_metrics['precision']),\n            'Recall': np.mean(fold_metrics['recall']),\n            'F1 Score': np.mean(fold_metrics['f1_score']),\n            'Confusion Matrix': np.mean(fold_metrics['confusion_matrix'], axis=0).tolist(),  # average confusion matrix across folds\n            'TP_TN_FP_FN': fold_metrics['tp_tn_fp_fn'],  # TP, TN, FP, FN for each fold\n            'Avg TP': np.mean(fold_metrics['tp']),\n            'Avg TN': np.mean(fold_metrics['tn']),\n            'Avg FP': np.mean(fold_metrics['fp']),\n            'Avg FN': np.mean(fold_metrics['fn']),\n            'Std Accuracy': np.std(fold_metrics['accuracy']),\n            'Std Precision': np.std(fold_metrics['precision']),\n            'Std Recall': np.std(fold_metrics['recall']),\n            'Std F1 Score': np.std(fold_metrics['f1_score'])\n        }\n\n        # Print the results for the current model\n        print(f\"\\n{name} Model Results:\")\n        print(f\"CV: {results[name]['CV']}\")\n        print(f\"Accuracy: {results[name]['Accuracy']}\")\n        print(f\"Precision: {results[name]['Precision']}\")\n        print(f\"Recall: {results[name]['Recall']}\")\n        print(f\"F1 Score: {results[name]['F1 Score']}\")\n        print(f\"STD Accuracy: {results[name]['Std Accuracy']}\")\n        print(f\"STD Precision: {results[name]['Std Precision']}\")\n        print(f\"STD Recall: {results[name]['Std Recall']}\")\n        print(f\"STD F1 Score: {results[name]['Std F1 Score']}\")\n        print(f\"Confusion Matrix: \\n{np.array(results[name]['Confusion Matrix'])}\\n\")\n        print(f\"TP_TN_FP_FN: \\n{results[name]['TP_TN_FP_FN']}\\n\")\n        print(f\"Avg TP: {results[name]['Avg TP']}\")\n        print(f\"Avg TN: {results[name]['Avg TN']}\")\n        print(f\"Avg FP: {results[name]['Avg FP']}\")\n        print(f\"Avg FN: {results[name]['Avg FN']}\\n\")\n\n    return results","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:20:05.511301Z","iopub.execute_input":"2023-12-23T07:20:05.511839Z","iopub.status.idle":"2023-12-23T07:20:05.535295Z","shell.execute_reply.started":"2023-12-23T07:20:05.511808Z","shell.execute_reply":"2023-12-23T07:20:05.534387Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# With bksb, slope and roll set to true\ndata_file= \"/kaggle/input/chemcancer-v2/Data/HC05_HC07.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:20:05.536278Z","iopub.execute_input":"2023-12-23T07:20:05.536505Z","iopub.status.idle":"2023-12-23T07:20:05.547899Z","shell.execute_reply.started":"2023-12-23T07:20:05.536485Z","shell.execute_reply":"2023-12-23T07:20:05.547014Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Apply median filter and background subtraction to the data\ndef apply_filters_and_background_subtraction(X):\n    # Reshape the input data to a 2D array if necessary\n    if len(X.shape) == 1:\n        X = X.reshape((1, -1))\n    \n    # Apply median filter\n    datamedfilt = scipy.ndimage.median_filter(X, size=(1, 5))\n    \n    # Apply airPLS for background subtraction\n    baseline = np.zeros_like(datamedfilt)\n    cols = baseline.shape[1]\n    for col in range(cols):\n        baseline[:, col] = airPLS(datamedfilt[:, col], lambda_=150)\n    \n    data_bksb = datamedfilt - baseline\n    return datamedfilt","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:37:48.988725Z","iopub.execute_input":"2023-12-23T07:37:48.989621Z","iopub.status.idle":"2023-12-23T07:37:48.996120Z","shell.execute_reply.started":"2023-12-23T07:37:48.989585Z","shell.execute_reply":"2023-12-23T07:37:48.995041Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Load the data\nprint(\"Load the data\")\ndata = load_data(data_file)\nprint(f\"Data shape : {data.shape}\")\n\n# Extract the feature and target data\nprint(\"Extract the feature and target data\")\nX, y = extract_data(data)\nprint(f\"X shaped: {X.shape}\")\nprint(f\"y shaped: {y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:37:50.497178Z","iopub.execute_input":"2023-12-23T07:37:50.497611Z","iopub.status.idle":"2023-12-23T07:37:50.634854Z","shell.execute_reply.started":"2023-12-23T07:37:50.497577Z","shell.execute_reply":"2023-12-23T07:37:50.633957Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Load the data\nData shape : (2373, 274)\nExtract the feature and target data\nX shaped: (2373, 270)\ny shaped: (2373,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## (PCA) Not Filtered - Original was used","metadata":{}},{"cell_type":"code","source":"if DO_ML:\n    print(\"Building machine learning models...\")\n    ml_models = build_ml_models()\n    results = train_and_evaluate_ml_models(\n        models=ml_models,\n        X=X, \n        y=y, \n        apply_pca=True, \n        pca_variance_threshold=0.95, \n        apply_filters_bg_subtraction=False,\n        cv=5, \n        standardize_data_func=standardize_data\n    )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (No PCA) Not filtered - Original data was used","metadata":{}},{"cell_type":"code","source":"if DO_ML:\n    print(\"Building machine learning models...\")\n    ml_models = build_ml_models()\n    results = train_and_evaluate_ml_models(\n    models=ml_models,\n    X=X, \n    y=y, \n    apply_pca=False, \n    pca_variance_threshold=0.95, \n    apply_filters_bg_subtraction=False,\n    cv=5, \n    standardize_data_func=standardize_data\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (PCA) Filtered - Original Dataset was used","metadata":{}},{"cell_type":"code","source":"  if DO_ML:\n    print(\"Building machine learning models...\")\n    ml_models = build_ml_models()\n    results = train_and_evaluate_ml_models(\n    models=ml_models,\n    X=X, \n    y=y, \n    apply_pca=True, \n    pca_variance_threshold=0.95, \n    apply_filters_bg_subtraction=True,\n    cv=5, \n    standardize_data_func=standardize_data\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ## (No PCA) Filtered - Original Dataset was used","metadata":{}},{"cell_type":"code","source":"  if DO_ML:\n    print(\"Building machine learning models...\")\n    ml_models = build_ml_models()\n    results = train_and_evaluate_ml_models(\n    models=ml_models,\n    X=X, \n    y=y, \n    apply_pca=False, \n    pca_variance_threshold=0.95, \n    apply_filters_bg_subtraction=True,\n    cv=5, \n    standardize_data_func=standardize_data\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:39:26.401746Z","iopub.execute_input":"2023-12-23T07:39:26.402130Z","iopub.status.idle":"2023-12-23T07:46:43.431950Z","shell.execute_reply.started":"2023-12-23T07:39:26.402097Z","shell.execute_reply":"2023-12-23T07:46:43.431022Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Building machine learning models...\nApply filters and background subtraction\nStandardize the data\nTraining SVM model...\nEvaluating SVM model...\nApply filters and background subtraction\nStandardize the data\nTraining SVM model...\nEvaluating SVM model...\nApply filters and background subtraction\nStandardize the data\nTraining SVM model...\nEvaluating SVM model...\nApply filters and background subtraction\nStandardize the data\nTraining SVM model...\nEvaluating SVM model...\nApply filters and background subtraction\nStandardize the data\nTraining SVM model...\nEvaluating SVM model...\n\nSVM Model Results:\nCV: 5\nAccuracy: 0.5697392849211637\nPrecision: 0.5845534317170837\nRecall: 0.5544415176093183\nF1 Score: 0.5325799566014701\nSTD Accuracy: 0.004998797108884473\nSTD Precision: 0.007861299951589996\nSTD Recall: 0.004794989355675116\nSTD F1 Score: 0.007421322962028428\nConfusion Matrix: \n[[145.2  30.    7.8]\n [ 39.6  89.   13. ]\n [ 70.2  43.6  36.2]]\n\nTP_TN_FP_FN: \n[{0: (0.3178947368421053, 0.9987102493074793, 0.22736842105263158, 0.06736842105263158), 1: (0.17684210526315788, 0.9990692520775624, 0.1431578947368421, 0.12210526315789473), 2: (0.08, 0.999219944598338, 0.05473684210526316, 0.23578947368421052)}, {0: (0.30526315789473685, 0.9987191135734073, 0.2231578947368421, 0.08), 1: (0.18736842105263157, 0.9990249307479224, 0.16421052631578947, 0.11157894736842106), 2: (0.07578947368421053, 0.9992421052631578, 0.04421052631578947, 0.24)}, {0: (0.3031578947368421, 0.9986925207756233, 0.23578947368421052, 0.08210526315789474), 1: (0.1957894736842105, 0.9990603878116344, 0.14736842105263157, 0.1031578947368421), 2: (0.07578947368421053, 0.9992465373961218, 0.042105263157894736, 0.24)}, {0: (0.29957805907172996, 0.9986647438978796, 0.2468354430379747, 0.08649789029535865), 1: (0.1877637130801688, 0.9990697715821895, 0.14345991561181434, 0.10970464135021098), 2: (0.08227848101265822, 0.9992478057291388, 0.04008438818565401, 0.23417721518987342)}, {0: (0.3037974683544304, 0.9987137032882907, 0.22362869198312235, 0.08227848101265822), 1: (0.189873417721519, 0.9989985579234097, 0.17721518987341772, 0.10759493670886076), 2: (0.06751054852320675, 0.9992522565828126, 0.0379746835443038, 0.2489451476793249)}]\n\nAvg TP: 0.18991309497372122\nAvg TN: 0.9989954587036644\nAvg FP: 0.1434202383596121\nAvg FN: 0.1434202383596121\n\nApply filters and background subtraction\nStandardize the data\nTraining AdaBoost model...\nEvaluating AdaBoost model...\nApply filters and background subtraction\nStandardize the data\nTraining AdaBoost model...\nEvaluating AdaBoost model...\nApply filters and background subtraction\nStandardize the data\nTraining AdaBoost model...\nEvaluating AdaBoost model...\nApply filters and background subtraction\nStandardize the data\nTraining AdaBoost model...\nEvaluating AdaBoost model...\nApply filters and background subtraction\nStandardize the data\nTraining AdaBoost model...\nEvaluating AdaBoost model...\n\nAdaBoost Model Results:\nCV: 5\nAccuracy: 0.5908238951809904\nPrecision: 0.5859092866895932\nRecall: 0.5896770055671002\nF1 Score: 0.5832277297050862\nSTD Accuracy: 0.022946349726768508\nSTD Precision: 0.024742844908247068\nSTD Recall: 0.02223104731144741\nSTD F1 Score: 0.024211217706946158\nConfusion Matrix: \n[[115.8  29.4  37.8]\n [ 24.4  98.6  18.6]\n [ 37.   47.   66. ]]\n\nTP_TN_FP_FN: \n[{0: (0.23157894736842105, 0.9989362880886427, 0.12, 0.15368421052631578), 1: (0.2063157894736842, 0.9990027700831026, 0.17473684210526316, 0.09263157894736843), 2: (0.12631578947368421, 0.9990382271468145, 0.14105263157894737, 0.18947368421052632)}, {0: (0.22105263157894736, 0.9989362880886427, 0.12, 0.16421052631578947), 1: (0.22105263157894736, 0.9989894736842105, 0.18105263157894738, 0.07789473684210527), 2: (0.13052631578947368, 0.9990692520775624, 0.12631578947368421, 0.18526315789473685)}, {0: (0.2463157894736842, 0.9989141274238227, 0.13052631578947368, 0.13894736842105262), 1: (0.21473684210526317, 0.9990249307479224, 0.16421052631578947, 0.08421052631578947), 2: (0.14947368421052631, 0.9991357340720222, 0.09473684210526316, 0.16631578947368422)}, {0: (0.25949367088607594, 0.9988650323131977, 0.1518987341772152, 0.12658227848101267), 1: (0.1962025316455696, 0.9990653207285157, 0.14556962025316456, 0.10126582278481013), 2: (0.12658227848101267, 0.9990786732895369, 0.12025316455696203, 0.189873417721519)}, {0: (0.2616033755274262, 0.9989228934109562, 0.12447257383966245, 0.12447257383966245), 1: (0.20042194092827004, 0.9990786732895369, 0.13924050632911392, 0.0970464135021097), 2: (0.16244725738396623, 0.999096476704232, 0.11181434599156118, 0.1540084388185654)}]\n\nAvg TP: 0.1969412983936635\nAvg TN: 0.9990102774099144\nAvg FP: 0.13639203493966984\nAvg FN: 0.13639203493966984\n\nApply filters and background subtraction\nStandardize the data\nTraining XGBoost model...\nEvaluating XGBoost model...\nApply filters and background subtraction\nStandardize the data\nTraining XGBoost model...\nEvaluating XGBoost model...\nApply filters and background subtraction\nStandardize the data\nTraining XGBoost model...\nEvaluating XGBoost model...\nApply filters and background subtraction\nStandardize the data\nTraining XGBoost model...\nEvaluating XGBoost model...\nApply filters and background subtraction\nStandardize the data\nTraining XGBoost model...\nEvaluating XGBoost model...\n\nXGBoost Model Results:\nCV: 5\nAccuracy: 0.7324174994448145\nPrecision: 0.7297123613963074\nRecall: 0.7284991230957423\nF1 Score: 0.728232978511006\nSTD Accuracy: 0.0255360509219884\nSTD Precision: 0.02743543478433704\nSTD Recall: 0.02588663281985819\nSTD F1 Score: 0.026317656980320143\nConfusion Matrix: \n[[144.4  18.8  19.8]\n [ 15.8 105.6  20.2]\n [ 28.6  23.8  97.6]]\n\nTP_TN_FP_FN: \n[{0: (0.30105263157894735, 0.9989717451523547, 0.1031578947368421, 0.08421052631578947), 1: (0.21052631578947367, 0.999184487534626, 0.08842105263157894, 0.08842105263157894), 2: (0.19157894736842104, 0.9991135734072022, 0.10526315789473684, 0.12421052631578948)}, {0: (0.2863157894736842, 0.9990072022160665, 0.0863157894736842, 0.09894736842105263), 1: (0.21894736842105264, 0.9991313019390582, 0.11368421052631579, 0.08), 2: (0.19789473684210526, 0.9991313019390582, 0.0968421052631579, 0.11789473684210526)}, {0: (0.3178947368421053, 0.9989894736842105, 0.09473684210526316, 0.06736842105263158), 1: (0.24, 0.999219944598338, 0.07157894736842105, 0.05894736842105263), 2: (0.2063157894736842, 0.99918891966759, 0.06947368421052631, 0.10947368421052632)}, {0: (0.310126582278481, 0.9990074596307572, 0.08438818565400844, 0.0759493670886076), 1: (0.21518987341772153, 0.9991899446313803, 0.08649789029535865, 0.08227848101265822), 2: (0.2109704641350211, 0.9991365343872954, 0.09282700421940929, 0.10548523206751055)}, {0: (0.3059071729957806, 0.9989763036550411, 0.09915611814345991, 0.08016877637130802), 1: (0.22784810126582278, 0.9991854937777066, 0.08860759493670886, 0.06962025316455696), 2: (0.22151898734177214, 0.999212198899749, 0.056962025316455694, 0.0949367088607595)}]\n\nAvg TP: 0.2441391664816048\nAvg TN: 0.9991097256746957\nAvg FP: 0.08919416685172848\nAvg FN: 0.08919416685172846\n\nApply filters and background subtraction\nStandardize the data\nTraining Gradient Boost model...\nEvaluating Gradient Boost model...\nApply filters and background subtraction\nStandardize the data\nTraining Gradient Boost model...\nEvaluating Gradient Boost model...\nApply filters and background subtraction\nStandardize the data\nTraining Gradient Boost model...\nEvaluating Gradient Boost model...\nApply filters and background subtraction\nStandardize the data\nTraining Gradient Boost model...\nEvaluating Gradient Boost model...\nApply filters and background subtraction\nStandardize the data\nTraining Gradient Boost model...\nEvaluating Gradient Boost model...\n\nGradient Boost Model Results:\nCV: 5\nAccuracy: 0.6915434155007771\nPrecision: 0.6899389313523018\nRecall: 0.6871031089844887\nF1 Score: 0.6868671198557943\nSTD Accuracy: 0.029787806993616155\nSTD Precision: 0.0324083968765708\nSTD Recall: 0.029103018822180016\nSTD F1 Score: 0.03027525240978809\nConfusion Matrix: \n[[138.2  21.4  23.4]\n [ 21.8  99.8  20. ]\n [ 32.4  27.4  90.2]]\n\nTP_TN_FP_FN: \n[{0: (0.27789473684210525, 0.9989540166204985, 0.11157894736842106, 0.10736842105263159), 1: (0.20210526315789473, 0.9991490304709141, 0.10526315789473684, 0.0968421052631579), 2: (0.17894736842105263, 0.9990736842105263, 0.12421052631578948, 0.1368421052631579)}, {0: (0.26105263157894737, 0.9989850415512466, 0.0968421052631579, 0.12421052631578948), 1: (0.21052631578947367, 0.9991002770083103, 0.12842105263157894, 0.08842105263157894), 2: (0.18947368421052632, 0.9990958448753463, 0.11368421052631579, 0.12631578947368421)}, {0: (0.3031578947368421, 0.9989274238227146, 0.12421052631578948, 0.08210526315789474), 1: (0.2231578947368421, 0.999202216066482, 0.08, 0.07578947368421053), 2: (0.1957894736842105, 0.999180055401662, 0.07368421052631578, 0.12)}, {0: (0.3080168776371308, 0.9989184425572826, 0.12658227848101267, 0.07805907172995781), 1: (0.20253164556962025, 0.9991543378019905, 0.10337552742616034, 0.0949367088607595), 2: (0.1751054852320675, 0.9991543378019905, 0.08438818565400844, 0.14135021097046413)}, {0: (0.3059071729957806, 0.9989495985329986, 0.11181434599156118, 0.08016877637130802), 1: (0.21308016877637131, 0.9991676903630117, 0.0970464135021097, 0.08438818565400844), 2: (0.2109704641350211, 0.9992032971924014, 0.06118143459915612, 0.10548523206751055)}]\n\nAvg TP: 0.23051447183359247\nAvg TN: 0.9990810196184917\nAvg FP: 0.10281886149974093\nAvg FN: 0.10281886149974091\n\nApply filters and background subtraction\nStandardize the data\nTraining Random Forest model...\nEvaluating Random Forest model...\nApply filters and background subtraction\nStandardize the data\nTraining Random Forest model...\nEvaluating Random Forest model...\nApply filters and background subtraction\nStandardize the data\nTraining Random Forest model...\nEvaluating Random Forest model...\nApply filters and background subtraction\nStandardize the data\nTraining Random Forest model...\nEvaluating Random Forest model...\nApply filters and background subtraction\nStandardize the data\nTraining Random Forest model...\nEvaluating Random Forest model...\n\nRandom Forest Model Results:\nCV: 5\nAccuracy: 0.7185121030424162\nPrecision: 0.7165646379708034\nRecall: 0.7139695427925458\nF1 Score: 0.7141520499861117\nSTD Accuracy: 0.022668674722829213\nSTD Precision: 0.022968634612772106\nSTD Recall: 0.021547765949639353\nSTD F1 Score: 0.022733502673667656\nConfusion Matrix: \n[[143.   18.6  21.4]\n [ 18.  102.4  21.2]\n [ 30.2  24.2  95.6]]\n\nTP_TN_FP_FN: \n[{0: (0.3094736842105263, 0.9989628808864265, 0.10736842105263159, 0.07578947368421053), 1: (0.21052631578947367, 0.9992421052631578, 0.061052631578947365, 0.08842105263157894), 2: (0.20842105263157895, 0.9991180055401662, 0.1031578947368421, 0.10736842105263159)}, {0: (0.27578947368421053, 0.9989983379501386, 0.09052631578947369, 0.10947368421052632), 1: (0.21263157894736842, 0.9990825484764543, 0.1368421052631579, 0.0863157894736842), 2: (0.18526315789473685, 0.9991268698060942, 0.09894736842105263, 0.13052631578947368)}, {0: (0.30105263157894735, 0.9989628808864265, 0.10736842105263159, 0.08421052631578947), 1: (0.22736842105263158, 0.999193351800554, 0.08421052631578947, 0.07157894736842105), 2: (0.1957894736842105, 0.9991578947368421, 0.08421052631578947, 0.12)}, {0: (0.310126582278481, 0.9989629510940199, 0.10548523206751055, 0.0759493670886076), 1: (0.21518987341772153, 0.9992032971924014, 0.08016877637130802, 0.08227848101265822), 2: (0.20675105485232068, 0.9991587886556641, 0.08227848101265822, 0.10970464135021098)}, {0: (0.310126582278481, 0.9989807545087147, 0.0970464135021097, 0.0759493670886076), 1: (0.21308016877637131, 0.9991854937777066, 0.08860759493670886, 0.08438818565400844), 2: (0.2109704641350211, 0.9991632395093379, 0.08016877637130802, 0.10548523206751055)}]\n\nAvg TP: 0.23950403434747203\nAvg TN: 0.9990999600056071\nAvg FP: 0.09382929898586127\nAvg FN: 0.09382929898586129\n\nApply filters and background subtraction\nStandardize the data\nTraining Decision Tree model...\nEvaluating Decision Tree model...\nApply filters and background subtraction\nStandardize the data\nTraining Decision Tree model...\nEvaluating Decision Tree model...\nApply filters and background subtraction\nStandardize the data\nTraining Decision Tree model...\nEvaluating Decision Tree model...\nApply filters and background subtraction\nStandardize the data\nTraining Decision Tree model...\nEvaluating Decision Tree model...\nApply filters and background subtraction\nStandardize the data\nTraining Decision Tree model...\nEvaluating Decision Tree model...\n\nDecision Tree Model Results:\nCV: 5\nAccuracy: 0.5984099489229402\nPrecision: 0.5953127875967128\nRecall: 0.5942197309735248\nF1 Score: 0.5941928270257902\nSTD Accuracy: 0.02780469915619234\nSTD Precision: 0.028615863329906312\nSTD Recall: 0.02903940331154842\nSTD F1 Score: 0.028736378890789522\nConfusion Matrix: \n[[119.8  26.8  36.4]\n [ 25.8  84.4  31.4]\n [ 40.8  29.4  79.8]]\n\nTP_TN_FP_FN: \n[{0: (0.24421052631578946, 0.9988653739612188, 0.15368421052631578, 0.14105263157894737), 1: (0.18526315789473685, 0.999175623268698, 0.09263157894736843, 0.11368421052631579), 2: (0.1831578947368421, 0.9990382271468145, 0.14105263157894737, 0.13263157894736843)}, {0: (0.23789473684210527, 0.9988875346260387, 0.1431578947368421, 0.14736842105263157), 1: (0.16, 0.9990825484764543, 0.1368421052631579, 0.13894736842105262), 2: (0.15368421052631578, 0.9989806094182826, 0.16842105263157894, 0.16210526315789472)}, {0: (0.25263157894736843, 0.9989229916897506, 0.12631578947368421, 0.13263157894736843), 1: (0.1957894736842105, 0.9990914127423823, 0.13263157894736843, 0.1031578947368421), 2: (0.15578947368421053, 0.9990470914127424, 0.1368421052631579, 0.16)}, {0: (0.26371308016877637, 0.9989362459719774, 0.11814345991561181, 0.12236286919831224), 1: (0.19198312236286919, 0.9991053784115793, 0.12658227848101267, 0.10548523206751055), 2: (0.17932489451476794, 0.9990786732895369, 0.12025316455696203, 0.1371308016877637)}, {0: (0.26371308016877637, 0.9988472288985027, 0.16033755274261605, 0.12236286919831224), 1: (0.15611814345991562, 0.9991543378019905, 0.10337552742616034, 0.14135021097046413), 2: (0.16877637130801687, 0.9990208121917784, 0.14767932489451477, 0.14767932489451477)}]\n\nAvg TP: 0.19946998297431343\nAvg TN: 0.99901560595385\nAvg FP: 0.13386335035901992\nAvg FN: 0.13386335035901992\n\nApply filters and background subtraction\nStandardize the data\nTraining Logistic Regression model...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model...\nApply filters and background subtraction\nStandardize the data\nTraining Logistic Regression model...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model...\nApply filters and background subtraction\nStandardize the data\nTraining Logistic Regression model...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model...\nApply filters and background subtraction\nStandardize the data\nTraining Logistic Regression model...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model...\nApply filters and background subtraction\nStandardize the data\nTraining Logistic Regression model...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model...\n\nLogistic Regression Model Results:\nCV: 5\nAccuracy: 0.6818307794803464\nPrecision: 0.6716952185836872\nRecall: 0.6686716065879444\nF1 Score: 0.667241770187357\nSTD Accuracy: 0.027150256208366096\nSTD Precision: 0.02741469771764335\nSTD Recall: 0.026747825567832114\nSTD F1 Score: 0.026505670346666253\nConfusion Matrix: \n[[154.2  12.8  16. ]\n [ 24.8  86.   30.8]\n [ 26.2  40.4  83.4]]\n\nTP_TN_FP_FN: \n[{0: (0.32842105263157895, 0.9989229916897506, 0.12631578947368421, 0.056842105263157895), 1: (0.15789473684210525, 0.9992066481994459, 0.07789473684210527, 0.14105263157894737), 2: (0.18526315789473685, 0.9990736842105263, 0.12421052631578948, 0.13052631578947368)}, {0: (0.33473684210526317, 0.9989983379501386, 0.09052631578947369, 0.05052631578947368), 1: (0.19157894736842104, 0.9991180055401662, 0.12, 0.10736842105263159), 2: (0.17473684210526316, 0.9991490304709141, 0.08842105263157894, 0.14105263157894737)}, {0: (0.3389473684210526, 0.9989540166204985, 0.11157894736842106, 0.04631578947368421), 1: (0.18526315789473685, 0.9991313019390582, 0.11368421052631579, 0.11368421052631579), 2: (0.16421052631578947, 0.999153462603878, 0.0863157894736842, 0.15157894736842106)}, {0: (0.3291139240506329, 0.9989763036550411, 0.09915611814345991, 0.056962025316455694), 1: (0.19831223628691982, 0.9991365343872954, 0.11181434599156118, 0.09915611814345991), 2: (0.18565400843881857, 0.9991721412166853, 0.0759493670886076, 0.1308016877637131)}, {0: (0.29324894514767935, 0.9989540493866724, 0.10970464135021098, 0.09282700421940929), 1: (0.1729957805907173, 0.9990831241432107, 0.1371308016877637, 0.12447257383966245), 2: (0.16877637130801687, 0.9990831241432107, 0.11814345991561181, 0.14767932489451477)}]\n\nAvg TP: 0.22727692649344883\nAvg TN: 0.999074183743766\nAvg FP: 0.10605640683988452\nAvg FN: 0.1060564068398845\n\nApply filters and background subtraction\nStandardize the data\nTraining k-Nearest Neighbors model...\nEvaluating k-Nearest Neighbors model...\nApply filters and background subtraction\nStandardize the data\nTraining k-Nearest Neighbors model...\nEvaluating k-Nearest Neighbors model...\nApply filters and background subtraction\nStandardize the data\nTraining k-Nearest Neighbors model...\nEvaluating k-Nearest Neighbors model...\nApply filters and background subtraction\nStandardize the data\nTraining k-Nearest Neighbors model...\nEvaluating k-Nearest Neighbors model...\nApply filters and background subtraction\nStandardize the data\nTraining k-Nearest Neighbors model...\nEvaluating k-Nearest Neighbors model...\n\nk-Nearest Neighbors Model Results:\nCV: 5\nAccuracy: 0.6974390406395736\nPrecision: 0.695959086437277\nRecall: 0.6919813691278391\nF1 Score: 0.6924238047259126\nSTD Accuracy: 0.011328923323474096\nSTD Precision: 0.012692537192058423\nSTD Recall: 0.010082364218859295\nSTD F1 Score: 0.010677856991761544\nConfusion Matrix: \n[[140.8  22.2  20. ]\n [ 23.6  97.6  20.4]\n [ 32.8  24.6  92.6]]\n\nTP_TN_FP_FN: \n[{0: (0.28842105263157897, 0.9989407202216066, 0.11789473684210526, 0.0968421052631579), 1: (0.20210526315789473, 0.9991490304709141, 0.10526315789473684, 0.0968421052631579), 2: (0.1957894736842105, 0.9991445983379501, 0.09052631578947369, 0.12)}, {0: (0.28210526315789475, 0.9989717451523547, 0.1031578947368421, 0.1031578947368421), 1: (0.20210526315789473, 0.9991224376731301, 0.11789473684210526, 0.0968421052631579), 2: (0.19789473684210526, 0.9991313019390582, 0.0968421052631579, 0.11789473684210526)}, {0: (0.2926315789473684, 0.9989185595567867, 0.12842105263157894, 0.09263157894736843), 1: (0.22526315789473683, 0.9991667590027701, 0.0968421052631579, 0.07368421052631578), 2: (0.1831578947368421, 0.999180055401662, 0.07368421052631578, 0.13263157894736843)}, {0: (0.310126582278481, 0.9989139917036087, 0.12869198312236288, 0.0759493670886076), 1: (0.20253164556962025, 0.9991988463387278, 0.08227848101265822, 0.0949367088607595), 2: (0.19831223628691982, 0.9991676903630117, 0.07805907172995781, 0.11814345991561181)}, {0: (0.310126582278481, 0.9989406968256512, 0.1160337552742616, 0.0759493670886076), 1: (0.1962025316455696, 0.9991810429240328, 0.09071729957805907, 0.10126582278481013), 2: (0.20042194092827004, 0.9991498869483166, 0.08649789029535865, 0.1160337552742616)}]\n\nAvg TP: 0.2324796802131912\nAvg TN: 0.9990851575239719\nAvg FP: 0.10085365312014213\nAvg FN: 0.10085365312014212\n\n","output_type":"stream"}]}]}