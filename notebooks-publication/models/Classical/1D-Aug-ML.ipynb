{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6115123,"sourceType":"datasetVersion","datasetId":3504592},{"sourceId":7169667,"sourceType":"datasetVersion","datasetId":4142249},{"sourceId":7169671,"sourceType":"datasetVersion","datasetId":4142252}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/input/chemcancer-v2/src/\n%mkdir /kaggle/working/Machine_Learning_models/\n%mkdir /kaggle/working/Machine_Learning_models_results/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-23T07:58:21.030339Z","iopub.execute_input":"2023-12-23T07:58:21.030716Z","iopub.status.idle":"2023-12-23T07:58:22.906964Z","shell.execute_reply.started":"2023-12-23T07:58:21.030687Z","shell.execute_reply":"2023-12-23T07:58:22.904693Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/chemcancer-v2/src\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom tensorflow.keras.optimizers import Adam\nfrom data import *\nfrom machine_learning_models import *\nfrom deep_learning_models import *\nfrom vision_transformer import *\nfrom utils_dl_model import *\nfrom utils_ml_model import print_ml_results\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:58:25.714222Z","iopub.execute_input":"2023-12-23T07:58:25.714604Z","iopub.status.idle":"2023-12-23T07:58:35.060920Z","shell.execute_reply.started":"2023-12-23T07:58:25.714572Z","shell.execute_reply":"2023-12-23T07:58:35.059922Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the seed value.\nSEED = 7\nnp.random.seed(SEED)\n\n# Deep Learning parameters\nDL_EPOCH = 500\nDL_BATCH_SIZE = 32\nDL_CNN_VERSION = 3\nDL_TRANSFORMER_VISION_VERSION = 11\nDL_BLS_VERSION = 1\n\nDO_DL = False\nCV_DL = True\nOPT_DL = False\n\nDO_CNN = False\nDO_TRANSFORMER_VISION = False\nDO_BLS = False\nDO_ML = True\n\n# Percentage of test set out of the dataset.\nTEST_SET = 0.2\n\n# Percentage of validation set out of the training dataset.\nVAL_SET = 0.2\n\n# Folder path associated with machine learning models\nml_models_folder = \"/kaggle/working/Machine_Learning_models/\"\nml_models_results_folder = \"/kaggle/working/Machine_Learning_models_results/\"","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:58:42.888472Z","iopub.execute_input":"2023-12-23T07:58:42.889137Z","iopub.status.idle":"2023-12-23T07:58:42.895461Z","shell.execute_reply.started":"2023-12-23T07:58:42.889090Z","shell.execute_reply":"2023-12-23T07:58:42.894508Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n\ndef compute_tp_tn_fp_fn_percentage(y_test, y_pred, class_label):\n    \"\"\"\n    Function to compute the True Positives (TP), True Negatives (TN),\n    False Positives (FP), and False Negatives (FN) for a specific class as percentages.\n    \"\"\"\n    cm = confusion_matrix(y_test, y_pred)\n    total_samples = np.sum(cm)\n\n    tp = cm[class_label, class_label] / total_samples\n    fp = (sum(cm[:, class_label]) - cm[class_label, class_label]) / total_samples\n    fn = (sum(cm[class_label, :]) - cm[class_label, class_label]) / total_samples\n    tn = (total_samples - (tp + fp + fn)) / total_samples\n\n    return tp, tn, fp, fn\n\n# Replace compute_tp_tn_fp_fn with compute_tp_tn_fp_fn_percentage in the function train_and_evaluate_ml_models\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\ndef train_and_evaluate_ml_models(models, X_augmented, y_augmented, X_test, y_test, apply_pca=False, pca_variance_threshold=0.95, apply_filters_bg_subtraction=False, cv=5, standardize_data_func=None):\n    results = {}\n\n    # Create a StratifiedKFold object for cross-validation on the augmented data\n    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n\n    for name, model in models.items():\n        fold_metrics = {\n            'accuracy': [],\n            'precision': [],\n            'recall': [],\n            'f1_score': [],\n            'confusion_matrix': [],\n            'tp_tn_fp_fn': []\n        }\n\n        # Perform stratified cross-validation on the augmented data\n        for train_index, _ in skf.split(X_augmented, y_augmented):\n            X_train_fold, y_train_fold = X_augmented[train_index], y_augmented[train_index]\n            X_test_fold = X_test\n            \n            # Apply filters and background subtraction if enabled\n            if apply_filters_bg_subtraction:\n                X_train_fold = apply_filters_and_background_subtraction(X_train_fold)\n                X_test_fold = apply_filters_and_background_subtraction(X_test)\n                \n            # Standardize data if a standardization function is provided\n            if standardize_data_func is not None:\n                X_train_fold, X_test_fold = standardize_data_func(X_train_fold, X_test_fold)\n\n            # Apply PCA if enabled\n            if apply_pca:\n                pca = PCA(n_components=pca_variance_threshold)\n                X_train_fold = pca.fit_transform(X_train_fold)\n                X_test_fold = pca.transform(X_test_fold)\n\n            # Train the model on the current fold\n            print(f\"Training {name} model on fold...\")\n            model.fit(X_train_fold, y_train_fold)\n\n            # Evaluate the model on the original data\n            print(f\"Evaluating {name} model on original data...\")\n            y_pred = model.predict(X_test_fold)\n\n            accuracy = accuracy_score(y_test, y_pred)\n            precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n            recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n            f1 = f1_score(y_test, y_pred, average='macro', zero_division=1)\n            confusion = confusion_matrix(y_test, y_pred)\n\n            tp_tn_fp_fn = {class_label: compute_tp_tn_fp_fn_percentage(y_test, y_pred, class_label) \n                           for class_label in range(len(np.unique(y_test)))}\n\n            fold_metrics['accuracy'].append(accuracy)\n            fold_metrics['precision'].append(precision)\n            fold_metrics['recall'].append(recall)\n            fold_metrics['f1_score'].append(f1)\n            fold_metrics['confusion_matrix'].append(confusion)\n            fold_metrics['tp_tn_fp_fn'].append(tp_tn_fp_fn)\n\n        # Calculate the mean and standard deviation of the metrics from the CV folds\n        results[name] = {\n            'CV': cv,\n            'Accuracy': np.mean(fold_metrics['accuracy']),\n            'Precision': np.mean(fold_metrics['precision']),\n            'Recall': np.mean(fold_metrics['recall']),\n            'F1 Score': np.mean(fold_metrics['f1_score']),\n            'Confusion Matrix': np.mean(fold_metrics['confusion_matrix'], axis=0).tolist(),\n            'TP_TN_FP_FN': fold_metrics['tp_tn_fp_fn'],\n        }\n\n        # Print the results for the current model\n        print(f\"\\n{name} Model Results:\")\n        print(f\"CV: {results[name]['CV']}\")\n        print(f\"Accuracy: {results[name]['Accuracy']}\")\n        print(f\"Precision: {results[name]['Precision']}\")\n        print(f\"Recall: {results[name]['Recall']}\")\n        print(f\"F1 Score: {results[name]['F1 Score']}\")\n        print(f\"Confusion Matrix: \\n{np.array(results[name]['Confusion Matrix'])}\\n\")\n        print(f\"TP_TN_FP_FN: \\n{results[name]['TP_TN_FP_FN']}\\n\")\n\n    return results\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T08:04:29.465120Z","iopub.execute_input":"2023-12-23T08:04:29.465454Z","iopub.status.idle":"2023-12-23T08:04:29.484172Z","shell.execute_reply.started":"2023-12-23T08:04:29.465427Z","shell.execute_reply":"2023-12-23T08:04:29.483166Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_confusion_matrices(results):\n    \"\"\"\n    Function to plot confusion matrices one by one.\n    \n    Parameters:\n    results (dict): Dictionary containing the results of the machine learning models\n    \"\"\"\n    for name, result in results.items():\n        # Create a new figure for each model\n        plt.figure(figsize=(5, 5))\n        \n        # Generate a confusion matrix heatmap\n        confusion_matrix = np.array(result['Confusion Matrix'])\n        sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap=\"Blues\")\n        \n        # Set the plot labels\n        plt.title(f'{name}')\n        plt.xlabel('Predicted Label')\n        plt.ylabel('True Label')\n        \n        # Display the plot\n        plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:58:48.431509Z","iopub.execute_input":"2023-12-23T07:58:48.432254Z","iopub.status.idle":"2023-12-23T07:58:48.634062Z","shell.execute_reply.started":"2023-12-23T07:58:48.432223Z","shell.execute_reply":"2023-12-23T07:58:48.633309Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def preprocess_with_pca(X, variance_threshold=0.95):\n    \"\"\"\n    Preprocesses the data using PCA, selecting the number of components\n    such that the specified variance threshold is retained.\n\n    :param X: The already standardized input data.\n    :param variance_threshold: The threshold for explained variance.\n    :return: Data transformed by PCA and the PCA model.\n    \"\"\"\n    pca_temp = PCA()\n    pca_temp.fit(X)\n    cumulative_variance_ratio = np.cumsum(pca_temp.explained_variance_ratio_)\n    n_components = np.argmax(cumulative_variance_ratio >= variance_threshold) + 1\n\n    pca = PCA(n_components=n_components)\n    X_pca = pca.fit_transform(X)\n\n    print(f\"PCA with {n_components} components retaining {variance_threshold * 100}% of variance\")\n    \n    return X_pca, pca\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:58:50.547713Z","iopub.execute_input":"2023-12-23T07:58:50.548433Z","iopub.status.idle":"2023-12-23T07:58:50.554671Z","shell.execute_reply.started":"2023-12-23T07:58:50.548398Z","shell.execute_reply":"2023-12-23T07:58:50.553450Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\ndef load_extract_data(data_file):\n    # Load the data\n    print(\"Load the data\")\n    data = load_data(data_file)\n    print(f\"Data shape : {data.shape}\")\n\n    # Extract the feature and target data\n    print(\"Extract the feature and target data\")\n    X, y = extract_data(data)\n    print(f\"X shaped: {X.shape}\")\n    print(f\"y shaped: {y.shape}\")\n\n    return X, y\n\ndef extract_data_from_csv(filename=\"generated_data.csv\"):\n    # Read the CSV file into a DataFrame\n    df_extracted = pd.read_csv(filename)\n    \n    # Split the DataFrame into features and labels\n    X_extracted = df_extracted.drop(columns=[\"labels\"]).values\n    y_extracted = df_extracted[\"labels\"].values\n    \n    return X_extracted, y_extracted","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:58:52.047891Z","iopub.execute_input":"2023-12-23T07:58:52.048756Z","iopub.status.idle":"2023-12-23T07:58:52.055096Z","shell.execute_reply.started":"2023-12-23T07:58:52.048726Z","shell.execute_reply":"2023-12-23T07:58:52.054046Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Apply median filter and background subtraction to the data\ndef apply_filters_and_background_subtraction(X):\n    # Reshape the input data to a 2D array if necessary\n    if len(X.shape) == 1:\n        X = X.reshape((1, -1))\n    \n    # Apply median filter\n    datamedfilt = scipy.ndimage.median_filter(X, size=(1, 5))\n    \n    # Apply airPLS for background subtraction\n    baseline = np.zeros_like(datamedfilt)\n    cols = baseline.shape[1]\n    for col in range(cols):\n        baseline[:, col] = airPLS(datamedfilt[:, col], lambda_=150)\n    \n    data_bksb = datamedfilt - baseline\n    return datamedfilt","metadata":{"execution":{"iopub.status.busy":"2023-12-23T08:04:17.959900Z","iopub.execute_input":"2023-12-23T08:04:17.960293Z","iopub.status.idle":"2023-12-23T08:04:17.966977Z","shell.execute_reply.started":"2023-12-23T08:04:17.960264Z","shell.execute_reply":"2023-12-23T08:04:17.965979Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# With bksb, slope and roll set to true\ntest_data= \"/kaggle/input/test-gen-cc-10x-v4/test-gen-cc-10x-v4.csv\"\n\n# No bksb, slope and roll set to false\ntrain_data = \"/kaggle/input/gen-cc-10x-v4/gen-cc-10x-v4.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:58:57.611813Z","iopub.execute_input":"2023-12-23T07:58:57.612561Z","iopub.status.idle":"2023-12-23T07:58:57.616688Z","shell.execute_reply.started":"2023-12-23T07:58:57.612527Z","shell.execute_reply":"2023-12-23T07:58:57.615652Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_aug, y_aug = extract_data_from_csv(train_data)\nprint(f\"X_augmented shaped: {X_aug.shape}\")\nprint(f\"y_augmented shaped: {y_aug.shape}\")\n\n# test_df = load_data(test_data)\nX_test, y_test = extract_data_from_csv(test_data)\nprint(f\"X_original shaped: {X_test.shape}\")\nprint(f\"y_original shaped: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:58:59.755382Z","iopub.execute_input":"2023-12-23T07:58:59.756071Z","iopub.status.idle":"2023-12-23T07:59:02.237340Z","shell.execute_reply.started":"2023-12-23T07:58:59.756041Z","shell.execute_reply":"2023-12-23T07:59:02.236415Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"X_augmented shaped: (18980, 270)\ny_augmented shaped: (18980,)\nX_original shaped: (475, 270)\ny_original shaped: (475,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Assuming y_augmented and y_test are numpy arrays or lists\nclasses_augmented, counts_augmented = np.unique(y_aug, return_counts=True)\nclasses_test, counts_test = np.unique(y_test, return_counts=True)\n\n# Create a bar chart for the augmented data\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.bar(classes_augmented, counts_augmented, color='blue', alpha=0.7)\nplt.title('Class Distribution in Augmented Dataset')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.xticks(classes_augmented)\n\n# Create a bar chart for the test data\nplt.subplot(1, 2, 2)\nplt.bar(classes_test, counts_test, color='green', alpha=0.7)\nplt.title('Class Distribution in Test Dataset')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.xticks(classes_test)\n\n# Show the plots\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T07:59:04.419665Z","iopub.execute_input":"2023-12-23T07:59:04.420034Z","iopub.status.idle":"2023-12-23T07:59:04.961531Z","shell.execute_reply.started":"2023-12-23T07:59:04.420002Z","shell.execute_reply":"2023-12-23T07:59:04.960577Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABuCUlEQVR4nO3de1gWdf7/8dcdh1skuBMQbvmGSoZmomZaiB3UPJLopm1atqjlqTxF6lrmltjPoGxXLd3ssCbmIdtt1c0OpGbatkqeUtNcMzMPBVKGoEaA+Pn90cVst+AJcUDv5+O65rqamfc985672/z0uj/3jMMYYwQAAAAAAADY6IqqbgAAAAAAAADeh1AKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAK1dK2bdv0wAMPKDo6WjVq1NCVV16pG2+8UVOmTNFPP/1k1bVr107t2rWrukZPw+FwWIuPj49q1aql5s2ba+jQocrMzCxT/+2338rhcCg9Pf28zrNw4UJNnz79vF5T3rlSUlLkcDj0448/ntexzuTLL79USkqKvv322zL7BgwYoPr161fauc6Hw+FQSkrKRTn26NGj5XA4lJiYeFGOf6n4/vvvlZKSoi1btlT6sdPT0+VwOMr9XP1W6We6dKlZs6auvvpqdenSRTNmzNDRo0cr3MPatWuVkpKiI0eOVPgYlen999+/aJ9pADgTxmvnhvHa+aus8Vrp+3guy9nGFufifMdAq1ev9ujB399ftWvX1i233KIJEyZo3759tvVysZ3pswbvRiiFaue1115Ty5YttWHDBv3xj39URkaGlixZonvuuUcvv/yyBg4cWNUtnpPf//73WrdunT799FMtWrRI/fr1U2ZmpuLj4/XII4941NapU0fr1q1Tt27dzuscFRnkVPRc5+vLL7/UpEmTyv2L58knn9SSJUsu6vlPZ926dRo0aFClH7e4uFjz58+XJGVkZOi7776r9HNcKr7//ntNmjSpWgyCMjIytG7dOmVkZOjPf/6z6tatq3HjxqlJkybaunVrhY65du1aTZo0qVqFUpMmTarqNgB4GcZr547x2vmrrPFa6fv426VFixa65pprymyvU6fOBZ+vomOg1NRUrVu3Th9//LFmz56tdu3a6fXXX1fjxo21YMECW3u5WM70WYN3863qBoDfWrdunR5++GF16tRJS5culdPptPZ16tRJY8aMUUZGRhV2eO4iIiLUunVra71Lly5KTk7WkCFD9OKLL+q6667Tww8/LElyOp0etRdDSUmJTpw4Ycu5zqZBgwZVdu6Lde3/+te/9MMPP6hbt2567733NHfuXD3xxBMX5Vw4dy1btlRYWJi1fu+992rEiBFq27atevTooa+++srjvzMAgLNjvHbxMF77VWVde3nvY3BwsIqKiqr8/f2tmJgYj3569OihMWPGqGPHjhowYICaNWumpk2bVmGHwEVkgGokMTHR+Pr6mv37959Tfdu2bU3btm09tqWkpJibb77Z1KpVywQFBZkWLVqYv/3tb+bkyZMedR999JFp27atCQkJMTVq1DBRUVGmV69e5vjx41bNSy+9ZJo1a2YCAwPNlVdeaRo1amTGjx9/1r4kmeHDh5e77+effzZhYWEmOjra2rZ3714jycyZM8falpOTYwYPHmyuvvpq4+/vb8LCwkybNm3MihUrrGuXVGb57fGee+458//+3/8z9evXNz4+PuaDDz4o91wTJ040kszmzZtNz549TVBQkAkODjb333+/ycnJKXNtEydOLHNd9erVM/379zfGGDNnzpxyeys9Z//+/U29evU8Xl9QUGAef/xxU79+fePn52ciIyPNsGHDTG5ubpnzdOvWzXzwwQemRYsWpkaNGqZRo0Zm9uzZp/m34enU/kt7XbVqlXnooYdMaGioCQkJMT179jTffffdOR3TGGO6du1q/P39TU5OjomKijLXXnttmc9c6bn27t3rsf3jjz82kszHH39sbTt58qR55plnTN26dY3T6TQtW7Y0y5cvL/OZL33tggULzLhx44zb7TaBgYEmMTHRZGdnm/z8fDN48GATGhpqQkNDzYABA8zRo0c9zn/y5Enz17/+1TRv3tzUqFHDXHXVVebuu+82e/bs8ahr27atadKkiVm/fr259dZbTUBAgImOjjZpaWmmpKTEo59Tl9++5xs2bDDdu3c3tWrVMk6n09xwww3mrbfeKvOerlu3zrRp08Y4nU5Tp04d8/jjj5tXX3213PfwVKWf6R9++KHc/VOmTDGSzNy5c61ty5cvNz169DD/93//Z5xOp2nQoIEZMmSIxzFKj3vqUvrvbtGiRaZTp07G7XabGjVqmOuuu8489thj5tixYx7n37Nnj+nTp4+pU6eO8ff3N+Hh4eaOO+4wn3/+uUfdokWLTOvWrU3NmjVNYGCg6dy5s9m8ebO1v3///uX2c7b3BwAuBOO1OdY2xmuX1njNmP+NZ34rLy/PjBkzxuO6HnnkkTJ/f//97383N998swkODrbGQQ888IAx5tzGQKcqfc0//vGPcvevX7/eSLLOYYwxu3fvNgMGDDDXXnutCQgIMJGRkSYxMdFs27atzHFP18uGDRtMnz59TL169UyNGjVMvXr1zL333mu+/fZbj/MfP37cel+cTqepVauWadmypVm4cKFH3dnGdmf7rMG7MVMK1UZJSYlWrVqlli1bKioqqsLH+fbbbzV06FDVrVtXkpSZmamRI0fqu+++01NPPWXVdOvWTbfddptef/11XXXVVfruu++UkZGhoqIi1axZU4sWLdKwYcM0cuRI/fnPf9YVV1yhr7/+Wl9++eUFXWdAQIA6duyoRYsW6eDBg7r66qvLrUtKStLmzZv1zDPPqGHDhjpy5Ig2b96sw4cPS5JeeuklDRkyRHv27Dnt1OoXX3xRDRs21J///GcFBwcrJibmjL317NlTvXv31kMPPaQdO3boySef1JdffqnPPvtMfn5+53yN3bp1U2pqqp544gn99a9/1Y033ijp9N+4GWN011136aOPPtL48eN12223adu2bZo4caI1pfq338Ju3bpVY8aM0eOPP66IiAj97W9/08CBA3Xttdfq9ttvP+c+f2vQoEHq1q2bFi5cqAMHDuiPf/yj/vCHP2jVqlVnfe3Bgwe1fPly3X333apdu7b69++vyZMn65NPPlHbtm0r1M+ECROUlpamIUOGqFevXjpw4IAGDRqk4uJiNWzYsEz9E088ofbt2ys9PV3ffvutxo4dq/vuu0++vr5q3ry53nzzTX3++ed64oknFBQUpBdffNF67dChQ5Wenq5Ro0bpueee008//aSnn35abdq00datWxUREWHVZmdn6/7779eYMWM0ceJELVmyROPHj1dkZKT69eunG2+8UXPmzNEDDzygP/3pT9bPDko/5x9//LG6du2quLg4vfzyy3K5XFq0aJH69Omjn3/+WQMGDJD06xTvDh06qH79+kpPT1fNmjX10ksvaeHChRV6P0/Vo0cPjRs3Tp988on69esnSdqzZ4/i4+M1aNAguVwuffvtt5o6dapuvfVWffHFF/Lz89OgQYP0008/acaMGVq8eLE11f/666+XJO3evVt33nmnkpOTFRgYqP/+97967rnntH79eo/P0p133qmSkhJNmTJFdevW1Y8//qi1a9d6/CQwNTVVf/rTn6z3sqioSM8//7xuu+02rV+/Xtdff72efPJJHT9+XG+//bbWrVtnvbYyfoIAAOVhvOaJ8dqlM147nZ9//llt27bVwYMH9cQTT6hZs2basWOHnnrqKX3xxRdauXKlHA6H1q1bpz59+qhPnz5KSUlRjRo1tG/fPuvcZxsDVcRNN92kOnXq6JNPPrG2ff/99woNDdWzzz6r2rVr66efftLcuXMVFxenzz//XI0aNTprL99++60aNWqke++9VyEhIcrKytKsWbN000036csvv7RmmY8ePVrz5s3T5MmT1aJFCx0/flzbt2+3Pt/SuY3tzvezBi9T1akYUCo7O9tIMvfee+85v6a8b95+q6SkxBQXF5unn37ahIaGWt++vf3220aS2bJly2lfO2LECHPVVVedcy+/pTN882aMMY899piRZD777DNjTPnfvF155ZUmOTn5jOfp1q1bmW+wfnu8Bg0amKKionL3lffN26OPPupRu2DBAiPJzJ8/3+PazvbNmzHG/OMf/ygz+6fUqd+8ZWRkGElmypQpHnVvvfWWkWReffVVj/PUqFHD7Nu3z9pWUFBgQkJCzNChQ8uc61Sn9l/6zc2wYcM86kpn0mRlZZ31mE8//bSRZDIyMowxxnzzzTfG4XCYpKQkj7pznSn1008/GafTafr06eNRt27dOiOp3JlS3bt396hNTk42ksyoUaM8tt91110mJCSkzDH/8pe/eNQdOHDABAQEmHHjxlnbSr/tLf3clrr++utNly5drPUNGzac9tuv6667zrRo0cIUFxd7bE9MTDR16tSxZlz16dPHBAQEmOzsbKvmxIkT5rrrrquUmVIFBQVGkklISCh3/8mTJ01xcbHZt2+fkWT+9a9/Wfuef/75c+qh9Bhr1qwxkszWrVuNMcb8+OOPRpKZPn36aV+7f/9+4+vra0aOHOmx/ejRo8btdpvevXtb24YPH2596w4AFxvjNcZrl+p4rdSpM6XS0tLMFVdcYTZs2OBRV/r5e//9940xxvz5z382ksyRI0dOe+wzjYHKc7aZUsYYExcXZwICAk67/8SJE6aoqMjExMR4fDbOp5cTJ06YY8eOmcDAQPPCCy9Y22NjY81dd911xtee69juTJ81eDdudI7LzqpVq9SxY0e5XC75+PjIz89PTz31lA4fPqycnBxJ0g033CB/f38NGTJEc+fO1TfffFPmODfffLOOHDmi++67T//6178q9Uknxpiz1tx8881KT0/X5MmTlZmZqeLi4vM+T48ePc7rG7P777/fY713797y9fXVxx9/fN7nPh+l3zCVzpIpdc899ygwMFAfffSRx/YbbrjB+mZVkmrUqKGGDRte0BNKevTo4bHerFkzSTrrMY0xmjNnjqKiotSpUydJUnR0tNq1a6d//vOfys/PP+9eMjMzVVhYqN69e3tsb9269WmfgnPqE/8aN24sSWVukNq4cWP99NNPOnbsmCTp3XfflcPh0B/+8AedOHHCWtxut5o3b67Vq1d7vN7tduvmm2/22NasWbNzeu+//vpr/fe//7U+Z78935133qmsrCzt2rVL0q/funXo0MFjlpaPj4/69Olz1vOci/L+DObk5Oihhx5SVFSUfH195efnp3r16kmSdu7ceU7H/eabb9S3b1+53W7rvz+ls+VKjxESEqIGDRro+eef19SpU/X555/r5MmTHsf58MMPdeLECfXr18/jfapRo4batm1b5t8LAFxqGK/9D+O1c1fR8dqZvPvuu4qNjdUNN9zg8Xduly5d5HA4rL9zb7rpJkm/vt9///vfbXuozamfwxMnTig1NVXXX3+9/P395evrK39/f+3evfucxyvHjh3TY489pmuvvVa+vr7y9fXVlVdeqePHj3sc4+abb9YHH3ygxx9/XKtXr1ZBQYHHcc5nbAecDqEUqo2wsDDVrFlTe/furfAx1q9fr86dO0v69akw//nPf7RhwwZNmDBBkqz/kDZo0EArV65UeHi4hg8frgYNGqhBgwZ64YUXrGMlJSXp9ddf1759+3T33XcrPDxccXFxWrFixQVc5a9K/+KMjIw8bc1bb72l/v37629/+5vi4+MVEhKifv36KTs7+5zPc74/4XG73R7rvr6+Cg0N9ZiiezEcPnxYvr6+ql27tsd2h8Mht9td5vyhoaFljuF0Osv8RXk+Tj1m6fTzsx1z1apV2rt3r+655x7l5+fryJEjOnLkiHr37q2ff/5Zb7755nn3Unq9vw1kSpW3Tfo16Pgtf3//M27/5ZdfJEmHDh2SMUYRERHy8/PzWDIzM8sM7i/kvT906JAkaezYsWXONWzYMEmyznf48OEyn0ep7Ge0ok79M3jy5El17txZixcv1rhx4/TRRx9p/fr11iPBz+X6jh07pttuu02fffaZJk+erNWrV2vDhg1avHixxzEcDoc++ugjdenSRVOmTNGNN96o2rVra9SoUTp69Kik/71XN910U5n36q233qrU/+kCgPPBeM0T47VLY7x2JocOHdK2bdvK/H0bFBQkY4z1d+7tt9+upUuXWl8aXX311YqNja3QWO987N+/3+MzOHr0aD355JO66667tGzZMn322WfasGGDmjdvfs7vQ9++fTVz5kwNGjRIH374odavX68NGzaodu3aHsd48cUX9dhjj2np0qVq3769QkJCdNddd2n37t2Szm9sB5wO95RCteHj46MOHTrogw8+OONv989k0aJF8vPz07vvvqsaNWpY25cuXVqm9rbbbtNtt92mkpISbdy4UTNmzFBycrIiIiJ07733SpIeeOABPfDAAzp+/Lg++eQTTZw4UYmJifrqq6+sGRTnq6CgQCtXrlSDBg3OeI1hYWGaPn26pk+frv379+udd97R448/rpycnHN+oo3D4Tiv3rKzs/V///d/1vqJEyd0+PBhjwGA0+lUYWFhmddeyEAoNDRUJ06c0A8//OAx0DHGKDs72/pmqjqaPXu2JGnq1KmaOnVqufuHDh0qSdZn8tT373TBT+lf9L+VnZ192tlSFREWFiaHw6F///vf5T6FrjKfTFd6f4Lx48erV69e5dY0atRI0q/vQXkD+vMZ5J/JO++8I0lq166dJGn79u3aunWr0tPT1b9/f6vu66+/Pudjrlq1St9//71Wr17tcS+x394nqlS9evWsz85XX32lv//970pJSVFRUZFefvll6716++23K/zfGgC4GBiveWK8dmmM184kLCxMAQEBev3110+7v9Tvfvc7/e53v1NhYaEyMzOVlpamvn37qn79+oqPj6/03tavX6/s7GwNHDjQ2jZ//nz169dPqampHrU//vijrrrqqrMeMy8vT++++64mTpyoxx9/3NpeWFion376yaM2MDBQkyZN0qRJk3To0CFr1lT37t313//+97zGdsDpMFMK1cr48eNljNHgwYNVVFRUZn9xcbGWLVt22tc7HA75+vrKx8fH2lZQUKB58+ad9jU+Pj6Ki4vTX//6V0nS5s2by9QEBgYqISFBEyZMUFFRkXbs2HE+l2UpKSnRiBEjdPjwYT322GPn/Lq6detqxIgR6tSpk0d/F/pt06kWLFjgsf73v/9dJ06csP7HXZLq16+vbdu2edStWrXK+jnYb3uTzu2bqw4dOkj69S/Z3/rnP/+p48ePW/urm9zcXC1ZskS33HKLPv744zLL/fffrw0bNmj79u2SZIVJp75/pQFJqbi4ODmdTr311lse2zMzMy9oenp5EhMTZYzRd999p1atWpVZKvL44dP9u2/UqJFiYmK0devWcs/VqlUrBQUFSZLat2+vjz76yCOYKykpKfOeVMTWrVuVmpqq+vXrWz+RLP0fglNDuFdeeeWcr+98jvFbDRs21J/+9Cc1bdrU+vPdpUsX+fr6as+ePad9r87WDwBcLIzXysd4rXqO184mMTFRe/bsUWhoaLl/35b3ZaDT6VTbtm313HPPSZI+//xza7tUOX8n//TTT3rooYfk5+enRx991NrucDjKjDXee++9Mj8nPNN4xRhT5hh/+9vfVFJSctp+IiIiNGDAAN13333atWuXfv755/Ma2zFewekwUwrVSnx8vGbNmqVhw4apZcuWevjhh9WkSRMVFxfr888/16uvvqrY2Fh179693Nd369ZNU6dOVd++fTVkyBAdPnxYf/7zn8v8R/fll1/WqlWr1K1bN9WtW1e//PKL9e1Ix44dJUmDBw9WQECAbrnlFtWpU0fZ2dlKS0uTy+U6p2+CDh06pMzMTBljdPToUW3fvl1vvPGGtm7dqkcffVSDBw8+7Wvz8vLUvn179e3bV9ddd52CgoK0YcMGZWRkeHwL0bRpUy1evFizZs1Sy5YtdcUVV3j8z+r5Wrx4sXx9fdWpUyfraS7Nmzf3uLdRUlKSnnzyST311FNq27atvvzyS82cOVMul8vjWLGxsZKkV199VUFBQapRo4aio6PLncrdqVMndenSRY899pjy8/N1yy23WE9zadGihZKSkip8TRfTggUL9Msvv2jUqFEeA8FSoaGhWrBggWbPnq1p06bppptuUqNGjTR27FidOHFCtWrV0pIlS/Tpp596vC4kJESjR49WWlqaatWqpZ49e+rgwYOaNGmS6tSpoyuuqLzvE2655RYNGTJEDzzwgDZu3Kjbb79dgYGBysrK0qeffqqmTZvq4YcfPq9jNmjQQAEBAVqwYIEaN26sK6+8UpGRkYqMjNQrr7yihIQEdenSRQMGDND//d//6aefftLOnTu1efNm/eMf/5Ak/elPf9I777yjO+64Q0899ZRq1qypv/71rzp+/Ph59bJp0ya5XC4VFxfr+++/10cffaR58+YpPDxcy5Yts37OeN1116lBgwZ6/PHHZYxRSEiIli1bVu7PP0qDuhdeeEH9+/eXn5+fGjVqpDZt2qhWrVp66KGHNHHiRPn5+WnBggXaunWrx+u3bdumESNG6J577lFMTIz8/f21atUqbdu2zfrGsn79+nr66ac1YcIEffPNN+ratatq1aqlQ4cOaf369dY3l7/t57nnnlNCQoJ8fHzUrFkz69oAoLIxXvsV47VLY7x2NsnJyfrnP/+p22+/XY8++qiaNWumkydPav/+/Vq+fLnGjBmjuLg4PfXUUzp48KA6dOigq6++WkeOHNELL7zgcf/IM42BzmT37t3KzMzUyZMndfjwYX322WeaPXu28vPz9cYbb6hJkyZWbWJiotLT03XdddepWbNm2rRpk55//vkyM/rO1Mvtt9+u559/XmFhYapfv77WrFmj2bNnl5lpFRcXp8TERDVr1ky1atXSzp07NW/ePMXHx6tmzZqSdM5ju/P5rMHL2H9vdeDstmzZYvr372/q1q1r/P39TWBgoGnRooV56qmnTE5OjlVX3tNcXn/9ddOoUSPjdDrNNddcY9LS0szs2bM9npa1bt0607NnT1OvXj3jdDpNaGioadu2rXnnnXes48ydO9e0b9/eREREGH9/fxMZGWl69+5ttm3bdtb+JVnLFVdcYYKDg03Tpk3NkCFDzLp168rUn/qElV9++cU89NBDplmzZiY4ONgEBASYRo0amYkTJ5rjx49br/vpp5/M73//e3PVVVcZh8NhPYGr9HjPP//8Wc9lzP+e5rJp0ybTvXt3c+WVV5qgoCBz3333mUOHDnm8vrCw0IwbN85ERUWZgIAA07ZtW7Nly5YyT3Mxxpjp06eb6Oho4+Pj43HOU5/mYsyvT2R57LHHTL169Yyfn5+pU6eOefjhh01ubq5HXb169Uy3bt3KXNfZnuxTSqd5msupT1w59Yl45bnhhhtMeHi4KSwsPG1N69atTVhYmFXz1Vdfmc6dO5vg4GBTu3ZtM3LkSPPee++VOdfJkyfN5MmTzdVXX238/f1Ns2bNzLvvvmuaN29uevbsWabPU5/acrrrOt1T6V5//XUTFxdnAgMDTUBAgGnQoIHp16+f2bhxo1Vz6tNqSpX37/PNN9801113nfHz8yvznm/dutX07t3bhIeHGz8/P+N2u80dd9xhXn75ZY9j/Oc//zGtW7c2TqfTuN1u88c//tG8+uqr5/X0vdLF6XSaOnXqmM6dO5sXXnjB5Ofnl3nNl19+aTp16mSCgoJMrVq1zD333GP2799f7hOMxo8fbyIjI80VV1zh8e9u7dq1Jj4+3tSsWdPUrl3bDBo0yGzevNnj83/o0CEzYMAAc91115nAwEBz5ZVXmmbNmplp06aZEydOeJxn6dKlpn379iY4ONg4nU5Tr1498/vf/96sXLnSqiksLDSDBg0ytWvXtv47cLb3BwAqA+M1xmuXwnitvB5OHc8cO3bM/OlPfzKNGjUy/v7+xuVymaZNm5pHH33UehLwu+++axISEsz//d//GX9/fxMeHm7uvPNO8+9//9vjWGcaA52qtP/SxdfX14SGhpr4+HjzxBNPmG+//bbMa3Jzc83AgQNNeHi4qVmzprn11lvNv//973Lf29P1cvDgQXP33XebWrVqmaCgINO1a1ezffv2Mp+Pxx9/3LRq1crUqlXL+rP66KOPmh9//NHjPOc6tjvdZw3ezWHMOTxWAgBQ5fbu3avrrrtOEydO1BNPPFHV7QAAAADABSGUAoBqaOvWrXrzzTfVpk0bBQcHa9euXZoyZYry8/O1ffv20z6FDwAAAAAuFdxTCgCqocDAQG3cuFGzZ8/WkSNH5HK51K5dOz3zzDMEUgAAAAAuC8yUAgAAAAAAgO0q7xFOAAAAAAAAwDkilAIAAAAAAIDtCKUAAAAAAABgO250fo5Onjyp77//XkFBQXI4HFXdDgAAqCLGGB09elSRkZG64gq+3/stxksAAEA69/ESodQ5+v777xUVFVXVbQAAgGriwIEDuvrqq6u6jWqF8RIAAPits42XCKXOUVBQkKRf39Dg4OAq7gYAAFSV/Px8RUVFWWMD/A/jJQAAIJ37eIlQ6hyVTkEPDg5mkAUAAKrNz9PS0tK0ePFi/fe//1VAQIDatGmj5557To0aNbJqjDGaNGmSXn31VeXm5iouLk5//etf1aRJE6umsLBQY8eO1ZtvvqmCggJ16NBBL7300nnNBmO8BAAAfuts4yVuhAAAAHAJW7NmjYYPH67MzEytWLFCJ06cUOfOnXX8+HGrZsqUKZo6dapmzpypDRs2yO12q1OnTjp69KhVk5ycrCVLlmjRokX69NNPdezYMSUmJqqkpKQqLgsAAHgBhzHGVHUTl4L8/Hy5XC7l5eXxzR8AAF6suo8JfvjhB4WHh2vNmjW6/fbbZYxRZGSkkpOT9dhjj0n6dVZURESEnnvuOQ0dOlR5eXmqXbu25s2bpz59+kj63/2h3n//fXXp0uWczl3d3xsAAGCPcx0TMFMKAADgMpKXlydJCgkJkSTt3btX2dnZ6ty5s1XjdDrVtm1brV27VpK0adMmFRcXe9RERkYqNjbWqgEAAKhs3FMKAADgMmGM0ejRo3XrrbcqNjZWkpSdnS1JioiI8KiNiIjQvn37rBp/f3/VqlWrTE3p68tTWFiowsJCaz0/P79SrgMAAHgHZkoBAABcJkaMGKFt27bpzTffLLPv1BuNGmPOevPRs9WkpaXJ5XJZS1RUVMUaBwAAXolQCgAA4DIwcuRIvfPOO/r44489npjndrslqcyMp5ycHGv2lNvtVlFRkXJzc09bU57x48crLy/PWg4cOFBZlwMAALwAoRQAAMAlzBijESNGaPHixVq1apWio6M99kdHR8vtdmvFihXWtqKiIq1Zs0Zt2rSRJLVs2VJ+fn4eNVlZWdq+fbtVUx6n06ng4GCPBQAA4FxxTykAAIBL2PDhw7Vw4UL961//UlBQkDUjyuVyKSAgQA6HQ8nJyUpNTVVMTIxiYmKUmpqqmjVrqm/fvlbtwIEDNWbMGIWGhiokJERjx45V06ZN1bFjx6q8PAAAcBkjlAIAALiEzZo1S5LUrl07j+1z5szRgAEDJEnjxo1TQUGBhg0bptzcXMXFxWn58uUKCgqy6qdNmyZfX1/17t1bBQUF6tChg9LT0+Xj42PXpQAAAC/jMMaYqm7iUpCfny+Xy6W8vDympgMA4MUYE5we7w0AAJDOfUzAPaUAAAAAAABgO0IpAAAAAAAA2I5QCgAAAAAAALYjlAIAAAAAAIDtCKUAAAAAAABgO0IpAAAAAAAA2I5QCgAAAAAAALYjlAIAAAAAAIDtCKUAAAAAAABgO0IpAAAAAAAA2I5QCgAAAAAAALbzreoG8Kvu3au6A1RXy5ZVdQcAAFQP3d9kwITyLbuPARMAXIqYKQUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdlUaStWvX18Oh6PMMnz4cEmSMUYpKSmKjIxUQECA2rVrpx07dngco7CwUCNHjlRYWJgCAwPVo0cPHTx40KMmNzdXSUlJcrlccrlcSkpK0pEjR+y6TAAAAAAAAJyiSkOpDRs2KCsry1pWrFghSbrnnnskSVOmTNHUqVM1c+ZMbdiwQW63W506ddLRo0etYyQnJ2vJkiVatGiRPv30Ux07dkyJiYkqKSmxavr27astW7YoIyNDGRkZ2rJli5KSkuy9WAAAAAAAAFh8q/LktWvX9lh/9tln1aBBA7Vt21bGGE2fPl0TJkxQr169JElz585VRESEFi5cqKFDhyovL0+zZ8/WvHnz1LFjR0nS/PnzFRUVpZUrV6pLly7auXOnMjIylJmZqbi4OEnSa6+9pvj4eO3atUuNGjWy96IBAAAAAABQfe4pVVRUpPnz5+vBBx+Uw+HQ3r17lZ2drc6dO1s1TqdTbdu21dq1ayVJmzZtUnFxsUdNZGSkYmNjrZp169bJ5XJZgZQktW7dWi6Xy6opT2FhofLz8z0WAAAAAAAAVI5qE0otXbpUR44c0YABAyRJ2dnZkqSIiAiPuoiICGtfdna2/P39VatWrTPWhIeHlzlfeHi4VVOetLQ06x5ULpdLUVFRFb42AAAAAAAAeKo2odTs2bOVkJCgyMhIj+0Oh8Nj3RhTZtupTq0pr/5sxxk/frzy8vKs5cCBA+dyGQAAAAAAADgH1SKU2rdvn1auXKlBgwZZ29xutySVmc2Uk5NjzZ5yu90qKipSbm7uGWsOHTpU5pw//PBDmVlYv+V0OhUcHOyxAAAAAAAAoHJUi1Bqzpw5Cg8PV7du3axt0dHRcrvd1hP5pF/vO7VmzRq1adNGktSyZUv5+fl51GRlZWn79u1WTXx8vPLy8rR+/Xqr5rPPPlNeXp5VAwAAAAAAAHtV6dP3JOnkyZOaM2eO+vfvL1/f/7XjcDiUnJys1NRUxcTEKCYmRqmpqapZs6b69u0rSXK5XBo4cKDGjBmj0NBQhYSEaOzYsWratKn1NL7GjRura9euGjx4sF555RVJ0pAhQ5SYmMiT9wAAAAAAAKpIlYdSK1eu1P79+/Xggw+W2Tdu3DgVFBRo2LBhys3NVVxcnJYvX66goCCrZtq0afL19VXv3r1VUFCgDh06KD09XT4+PlbNggULNGrUKOspfT169NDMmTMv/sUBAAAAAACgXA5jjKnqJi4F+fn5crlcysvLuyj3l+revdIPicvEsmVV3QEA4Lcu9pjgUnbRx0tvMmBC+Zbdx4AJAKqTcx0TVIt7SgEAAAAAAMC7EEoBAAAAAADAdoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsB2hFAAAwCXuk08+Uffu3RUZGSmHw6GlS5d67Hc4HOUuzz//vFXTrl27Mvvvvfdem68EAAB4E0IpAACAS9zx48fVvHlzzZw5s9z9WVlZHsvrr78uh8Ohu+++26Nu8ODBHnWvvPKKHe0DAAAv5VvVDQAAAODCJCQkKCEh4bT73W63x/q//vUvtW/fXtdcc43H9po1a5apBQAAuFiYKQUAAOBFDh06pPfee08DBw4ss2/BggUKCwtTkyZNNHbsWB09evSMxyosLFR+fr7HAgAAcK6YKQUAAOBF5s6dq6CgIPXq1ctj+/3336/o6Gi53W5t375d48eP19atW7VixYrTHistLU2TJk262C0DAIDLFKEUAACAF3n99dd1//33q0aNGh7bBw8ebP1zbGysYmJi1KpVK23evFk33nhjuccaP368Ro8eba3n5+crKirq4jQOAAAuO4RSAAAAXuLf//63du3apbfeeuustTfeeKP8/Py0e/fu04ZSTqdTTqezstsEAABegntKAQAAeInZs2erZcuWat68+Vlrd+zYoeLiYtWpU8eGzgAAgDdiphQAAMAl7tixY/r666+t9b1792rLli0KCQlR3bp1Jf3607p//OMf+stf/lLm9Xv27NGCBQt05513KiwsTF9++aXGjBmjFi1a6JZbbrHtOgAAgHchlAIAALjEbdy4Ue3bt7fWS+/z1L9/f6Wnp0uSFi1aJGOM7rvvvjKv9/f310cffaQXXnhBx44dU1RUlLp166aJEyfKx8fHlmsAAADeh1AKAADgEteuXTsZY85YM2TIEA0ZMqTcfVFRUVqzZs3FaA0AAOC0uKcUAAAAAAAAbEcoBQAAAAAAANsRSgEAAAAAAMB2hFIAAAAAAACwHaEUAAAAAAAAbEcoBQAAAAAAANsRSgEAAAAAAMB2hFIAAAAAAACwHaEUAAAAAAAAbEcoBQAAAAAAANsRSgEAAAAAAMB2hFIAAAAAAACwHaEUAAAAAAAAbEcoBQAAAAAAANsRSgEAAAAAAMB2hFIAAAAAAACwHaEUAAAAAAAAbEcoBQAAAAAAANsRSgEAAAAAAMB2hFIAAAAAAACwHaEUAAAAAAAAbEcoBQAAAAAAANsRSgEAAAAAAMB2hFIAAAAAAACwHaEUAAAAAAAAbFflodR3332nP/zhDwoNDVXNmjV1ww03aNOmTdZ+Y4xSUlIUGRmpgIAAtWvXTjt27PA4RmFhoUaOHKmwsDAFBgaqR48eOnjwoEdNbm6ukpKS5HK55HK5lJSUpCNHjthxiQAAAAAAADiFb1WePDc3V7fccovat2+vDz74QOHh4dqzZ4+uuuoqq2bKlCmaOnWq0tPT1bBhQ02ePFmdOnXSrl27FBQUJElKTk7WsmXLtGjRIoWGhmrMmDFKTEzUpk2b5OPjI0nq27evDh48qIyMDEnSkCFDlJSUpGXLltl+3QCAytO9e1V3gOqIv94BAACqvyoNpZ577jlFRUVpzpw51rb69etb/2yM0fTp0zVhwgT16tVLkjR37lxFRERo4cKFGjp0qPLy8jR79mzNmzdPHTt2lCTNnz9fUVFRWrlypbp06aKdO3cqIyNDmZmZiouLkyS99tprio+P165du9SoUSP7LhoAAAAAAABV+/O9d955R61atdI999yj8PBwtWjRQq+99pq1f+/evcrOzlbnzp2tbU6nU23bttXatWslSZs2bVJxcbFHTWRkpGJjY62adevWyeVyWYGUJLVu3Voul8uqAQAAAAAAgH2qNJT65ptvNGvWLMXExOjDDz/UQw89pFGjRumNN96QJGVnZ0uSIiIiPF4XERFh7cvOzpa/v79q1ap1xprw8PAy5w8PD7dqTlVYWKj8/HyPBQAAAAAAAJWjSn++d/LkSbVq1UqpqamSpBYtWmjHjh2aNWuW+vXrZ9U5HA6P1xljymw71ak15dWf6ThpaWmaNGnSOV8LAAAAAAAAzl2VzpSqU6eOrr/+eo9tjRs31v79+yVJbrdbksrMZsrJybFmT7ndbhUVFSk3N/eMNYcOHSpz/h9++KHMLKxS48ePV15enrUcOHCgAlcIAAAAAACA8lRpKHXLLbdo165dHtu++uor1atXT5IUHR0tt9utFStWWPuLioq0Zs0atWnTRpLUsmVL+fn5edRkZWVp+/btVk18fLzy8vK0fv16q+azzz5TXl6eVXMqp9Op4OBgjwUAAAAAAACVo0p/vvfoo4+qTZs2Sk1NVe/evbV+/Xq9+uqrevXVVyX9+pO75ORkpaamKiYmRjExMUpNTVXNmjXVt29fSZLL5dLAgQM1ZswYhYaGKiQkRGPHjlXTpk2tp/E1btxYXbt21eDBg/XKK69IkoYMGaLExESevAcAAAAAAFAFqjSUuummm7RkyRKNHz9eTz/9tKKjozV9+nTdf//9Vs24ceNUUFCgYcOGKTc3V3FxcVq+fLmCgoKsmmnTpsnX11e9e/dWQUGBOnTooPT0dPn4+Fg1CxYs0KhRo6yn9PXo0UMzZ86072IBAAAAAABgcRhjTFU3cSnIz8+Xy+VSXl7eRfkpX/fulX5IXCaWLavqDoDqjf9+ojwX87+dF3tMcCm76OOlN/kDj/Itu48BEwBUJ+c6JqjSe0oBAAAAAADAOxFKAQAAAAAAwHaEUgAAAAAAALAdoRQAAAAAAABsRygFAAAAAAAA2xFKAQAAAAAAwHaEUgAAAAAAALAdoRQAAAAAAABsRygFAAAAAAAA2xFKAQAAAAAAwHaEUgAAAAAAALAdoRQAAAAAAABsRygFAAAAAAAA2xFKAQAAAAAAwHa+Vd0AgOqve/eq7gDV1bJlVd0BAAAAgEsVM6UAAAAucZ988om6d++uyMhIORwOLV261GP/gAED5HA4PJbWrVt71BQWFmrkyJEKCwtTYGCgevTooYMHD9p4FQAAwNsQSgEAAFzijh8/rubNm2vmzJmnrenatauysrKs5f333/fYn5ycrCVLlmjRokX69NNPdezYMSUmJqqkpORitw8AALwUP98DAAC4xCUkJCghIeGMNU6nU263u9x9eXl5mj17tubNm6eOHTtKkubPn6+oqCitXLlSXbp0qfSeAQAAmCkFAADgBVavXq3w8HA1bNhQgwcPVk5OjrVv06ZNKi4uVufOna1tkZGRio2N1dq1a6uiXQAA4AWYKQUAAHCZS0hI0D333KN69epp7969evLJJ3XHHXdo06ZNcjqdys7Olr+/v2rVquXxuoiICGVnZ5/2uIWFhSosLLTW8/PzL9o1AACAyw+hFAAAwGWuT58+1j/HxsaqVatWqlevnt577z316tXrtK8zxsjhcJx2f1pamiZNmlSpvQIAAO/Bz/cAAAC8TJ06dVSvXj3t3r1bkuR2u1VUVKTc3FyPupycHEVERJz2OOPHj1deXp61HDhw4KL2DQAALi+EUgAAAF7m8OHDOnDggOrUqSNJatmypfz8/LRixQqrJisrS9u3b1ebNm1Oexyn06ng4GCPBQAA4Fzx8z0AAIBL3LFjx/T1119b63v37tWWLVsUEhKikJAQpaSk6O6771adOnX07bff6oknnlBYWJh69uwpSXK5XBo4cKDGjBmj0NBQhYSEaOzYsWratKn1ND4AAIDKRigFAABwidu4caPat29vrY8ePVqS1L9/f82aNUtffPGF3njjDR05ckR16tRR+/bt9dZbbykoKMh6zbRp0+Tr66vevXuroKBAHTp0UHp6unx8fGy/HgAA4B0IpQAAAC5x7dq1kzHmtPs//PDDsx6jRo0amjFjhmbMmFGZrQEAAJwW95QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7XyrugEAAAAAAHDxdH+ze1W3gGpo2X3LqroFZkoBAAAAAADAfoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsJ1vVTcAAAAAAJe67m92r+oWUE0tu29ZVbcAVFvMlAIAAAAAAIDtCKUAAAAAAABgO0IpAAAAAAAA2I5QCgAAAAAAALYjlAIAAAAAAIDtqjSUSklJkcPh8Fjcbre13xijlJQURUZGKiAgQO3atdOOHTs8jlFYWKiRI0cqLCxMgYGB6tGjhw4ePOhRk5ubq6SkJLlcLrlcLiUlJenIkSN2XCIAAAAAAADKUeUzpZo0aaKsrCxr+eKLL6x9U6ZM0dSpUzVz5kxt2LBBbrdbnTp10tGjR62a5ORkLVmyRIsWLdKnn36qY8eOKTExUSUlJVZN3759tWXLFmVkZCgjI0NbtmxRUlKSrdcJAAAAAACA//Gt8gZ8fT1mR5Uyxmj69OmaMGGCevXqJUmaO3euIiIitHDhQg0dOlR5eXmaPXu25s2bp44dO0qS5s+fr6ioKK1cuVJdunTRzp07lZGRoczMTMXFxUmSXnvtNcXHx2vXrl1q1KiRfRcLAAAAAAAASdVgptTu3bsVGRmp6Oho3Xvvvfrmm28kSXv37lV2drY6d+5s1TqdTrVt21Zr166VJG3atEnFxcUeNZGRkYqNjbVq1q1bJ5fLZQVSktS6dWu5XC6rBgAAAAAAAPaq0plScXFxeuONN9SwYUMdOnRIkydPVps2bbRjxw5lZ2dLkiIiIjxeExERoX379kmSsrOz5e/vr1q1apWpKX19dna2wsPDy5w7PDzcqilPYWGhCgsLrfX8/PyKXSQAAAAAAADKqNJQKiEhwfrnpk2bKj4+Xg0aNNDcuXPVunVrSZLD4fB4jTGmzLZTnVpTXv3ZjpOWlqZJkyad03UAAAAAAADg/FT5z/d+KzAwUE2bNtXu3but+0ydOpspJyfHmj3ldrtVVFSk3NzcM9YcOnSozLl++OGHMrOwfmv8+PHKy8uzlgMHDlzQtQEAAAAAAOB/qlUoVVhYqJ07d6pOnTqKjo6W2+3WihUrrP1FRUVas2aN2rRpI0lq2bKl/Pz8PGqysrK0fft2qyY+Pl55eXlav369VfPZZ58pLy/PqimP0+lUcHCwxwIAAAAAAIDKUaU/3xs7dqy6d++uunXrKicnR5MnT1Z+fr769+8vh8Oh5ORkpaamKiYmRjExMUpNTVXNmjXVt29fSZLL5dLAgQM1ZswYhYaGKiQkRGPHjlXTpk2tp/E1btxYXbt21eDBg/XKK69IkoYMGaLExESevAcAAAAAAFBFqjSUOnjwoO677z79+OOPql27tlq3bq3MzEzVq1dPkjRu3DgVFBRo2LBhys3NVVxcnJYvX66goCDrGNOmTZOvr6969+6tgoICdejQQenp6fLx8bFqFixYoFGjRllP6evRo4dmzpxp78UCAAAAAADAUqWh1KJFi8643+FwKCUlRSkpKaetqVGjhmbMmKEZM2actiYkJETz58+vaJsAAAAAAACoZNXqnlIAAAAAAADwDoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAAAAAADbEUoBAAAAAADAdoRSAAAAAAAAsB2hFAAAAAAAAGxHKAUAAHCJ++STT9S9e3dFRkbK4XBo6dKl1r7i4mI99thjatq0qQIDAxUZGal+/frp+++/9zhGu3bt5HA4PJZ7773X5isBAADehFAKAADgEnf8+HE1b95cM2fOLLPv559/1ubNm/Xkk09q8+bNWrx4sb766iv16NGjTO3gwYOVlZVlLa+88ood7QMAAC/lW9UNAAAA4MIkJCQoISGh3H0ul0srVqzw2DZjxgzdfPPN2r9/v+rWrWttr1mzptxu90XtFQAAoBQzpQAAALxMXl6eHA6HrrrqKo/tCxYsUFhYmJo0aaKxY8fq6NGjZzxOYWGh8vPzPRYAAIBzxUwpAAAAL/LLL7/o8ccfV9++fRUcHGxtv//++xUdHS23263t27dr/Pjx2rp1a5lZVr+VlpamSZMm2dE2AAC4DBFKAQAAeIni4mLde++9OnnypF566SWPfYMHD7b+OTY2VjExMWrVqpU2b96sG2+8sdzjjR8/XqNHj7bW8/PzFRUVdXGaBwAAlx1CKQAAAC9QXFys3r17a+/evVq1apXHLKny3HjjjfLz89Pu3btPG0o5nU45nc6L0S4AAPAChFIAAACXudJAavfu3fr4448VGhp61tfs2LFDxcXFqlOnjg0dAgAAb0QoBQAAcIk7duyYvv76a2t979692rJli0JCQhQZGanf//732rx5s959912VlJQoOztbkhQSEiJ/f3/t2bNHCxYs0J133qmwsDB9+eWXGjNmjFq0aKFbbrmlqi4LAABc5gilAAAALnEbN25U+/btrfXS+zz1799fKSkpeueddyRJN9xwg8frPv74Y7Vr107+/v766KOP9MILL+jYsWOKiopSt27dNHHiRPn4+Nh2HQAAwLsQSgEAAFzi2rVrJ2PMafefaZ8kRUVFac2aNZXdFgAAwBldUdUNAAAAAAAAwPsQSgEAAAAAAMB2hFIAAAAAAACwHaEUAAAAAAAAbEcoBQAAAAAAANsRSgEAAAAAAMB2hFIAAAAAAACwHaEUAAAAAAAAbEcoBQAAAAAAANsRSgEAAAAAAMB2hFIAAAAAAACwHaEUAAAAAAAAbEcoBQAAAAAAANsRSgEAAAAAAMB2hFIAAAAAAACwHaEUAAAAAAAAbEcoBQAAAAAAANsRSgEAAAAAAMB2hFIAAAAAAACwXYVCqb1791Z2HwAAAF6HMRUAAPBmFQqlrr32WrVv317z58/XL7/8Utk9AQAAeAXGVAAAwJtVKJTaunWrWrRooTFjxsjtdmvo0KFav359ZfcGAABwWWNMBQAAvFmFQqnY2FhNnTpV3333nebMmaPs7GzdeuutatKkiaZOnaoffvihsvsEAAC47DCmAgAA3uyCbnTu6+urnj176u9//7uee+457dmzR2PHjtXVV1+tfv36KSsrq7L6BAAAuGwxpgIAAN7ogkKpjRs3atiwYapTp46mTp2qsWPHas+ePVq1apW+++47/e53v6usPgEAAC5bjKkAAIA38q3Ii6ZOnao5c+Zo165duvPOO/XGG2/ozjvv1BVX/JpxRUdH65VXXtF1111Xqc0CAABcThhTAQAAb1ahUGrWrFl68MEH9cADD8jtdpdbU7duXc2ePfuCmgMAALicMaYCAADerEKh1O7du89a4+/vr/79+1fk8AAAAF6BMRUAAPBmFbqn1Jw5c/SPf/yjzPZ//OMfmjt37gU3BQAA4A0YUwEAAG9WoVDq2WefVVhYWJnt4eHhSk1NveCmAAAAvAFjKgAA4M0qFErt27dP0dHRZbbXq1dP+/fvv+CmAAAAvAFjKgAA4M0qFEqFh4dr27ZtZbZv3bpVoaGhF9wUAACAN2BMBQAAvFmFQql7771Xo0aN0scff6ySkhKVlJRo1apVeuSRR3TvvfdWdo8AAACXJcZUAADAm1Xo6XuTJ0/Wvn371KFDB/n6/nqIkydPql+/ftz/AAAA4BwxpgIAAN6sQjOl/P399dZbb+m///2vFixYoMWLF2vPnj16/fXX5e/vX6FG0tLS5HA4lJycbG0zxiglJUWRkZEKCAhQu3bttGPHDo/XFRYWauTIkQoLC1NgYKB69OihgwcPetTk5uYqKSlJLpdLLpdLSUlJOnLkSIX6BAAAqCwXY0wFAABwqajQTKlSDRs2VMOGDS+4iQ0bNujVV19Vs2bNPLZPmTJFU6dOVXp6uho2bKjJkyerU6dO2rVrl4KCgiRJycnJWrZsmRYtWqTQ0FCNGTNGiYmJ2rRpk3x8fCRJffv21cGDB5WRkSFJGjJkiJKSkrRs2bIL7h0AAOBCVdaYCgAA4FJSoVCqpKRE6enp+uijj5STk6OTJ0967F+1atU5H+vYsWO6//779dprr2ny5MnWdmOMpk+frgkTJqhXr16SpLlz5yoiIkILFy7U0KFDlZeXp9mzZ2vevHnq2LGjJGn+/PmKiorSypUr1aVLF+3cuVMZGRnKzMxUXFycJOm1115TfHy8du3apUaNGlXkLQAAALhglTmmAgAAuNRU6Od7jzzyiB555BGVlJQoNjZWzZs391jOx/Dhw9WtWzcrVCq1d+9eZWdnq3PnztY2p9Optm3bau3atZKkTZs2qbi42KMmMjJSsbGxVs26devkcrmsQEqSWrduLZfLZdUAAABUhcocUwEAAFxqKjRTatGiRfr73/+uO++884JOvmjRIm3evFkbNmwosy87O1uSFBER4bE9IiJC+/bts2r8/f1Vq1atMjWlr8/OzlZ4eHiZ44eHh1s15SksLFRhYaG1np+ff45XBQAAcG4qa0wFAABwKarwjc6vvfbaCzrxgQMH9Mgjj2j+/PmqUaPGaescDofHujGmzLZTnVpTXv3ZjpOWlmbdGN3lcikqKuqM5wQAADhflTGmAgAAuFRVKJQaM2aMXnjhBRljKnziTZs2KScnRy1btpSvr698fX21Zs0avfjii/L19bVmSJ06myknJ8fa53a7VVRUpNzc3DPWHDp0qMz5f/jhhzKzsH5r/PjxysvLs5YDBw5U+FoBAADKUxljKgAAgEtVhX6+9+mnn+rjjz/WBx98oCZNmsjPz89j/+LFi896jA4dOuiLL77w2PbAAw/ouuuu02OPPaZrrrlGbrdbK1asUIsWLSRJRUVFWrNmjZ577jlJUsuWLeXn56cVK1aod+/ekqSsrCxt375dU6ZMkSTFx8crLy9P69ev18033yxJ+uyzz5SXl6c2bdqctj+n0ymn03mO7wgAAMD5q4wxFQAAwKWqQqHUVVddpZ49e17QiYOCghQbG+uxLTAwUKGhodb25ORkpaamKiYmRjExMUpNTVXNmjXVt29fSZLL5dLAgQM1ZswYhYaGKiQkRGPHjlXTpk2tG6c3btxYXbt21eDBg/XKK69IkoYMGaLExESevAcAAKpUZYypAAAALlUVCqXmzJlT2X2Ua9y4cSooKNCwYcOUm5uruLg4LV++XEFBQVbNtGnT5Ovrq969e6ugoEAdOnRQenq6fHx8rJoFCxZo1KhR1lP6evTooZkzZ9pyDQAAAKdj15gKAACgOqpQKCVJJ06c0OrVq7Vnzx717dtXQUFB+v777xUcHKwrr7yyQsdcvXq1x7rD4VBKSopSUlJO+5oaNWpoxowZmjFjxmlrQkJCNH/+/Ar1BAAAcDFdjDEVAADApaBCodS+ffvUtWtX7d+/X4WFherUqZOCgoI0ZcoU/fLLL3r55Zcru08AAIDLDmMqAADgzSr09L1HHnlErVq1Um5urgICAqztPXv21EcffVRpzQEAAFzOGFMBAABvVuGn7/3nP/+Rv7+/x/Z69erpu+++q5TGAAAALneMqQAAgDer0EypkydPqqSkpMz2gwcPetyEHAAAAKfHmAoAAHizCoVSnTp10vTp0611h8OhY8eOaeLEibrzzjsrqzcAAIDLGmMqAADgzSr0871p06apffv2uv766/XLL7+ob9++2r17t8LCwvTmm29Wdo8AAACXJcZUAADAm1VoplRkZKS2bNmisWPHaujQoWrRooWeffZZff755woPD6/sHgEAAC5LlTWm+uSTT9S9e3dFRkbK4XBo6dKlHvuNMUpJSVFkZKQCAgLUrl077dixw6OmsLBQI0eOVFhYmAIDA9WjRw8dPHiwMi4TAACgXBWaKSVJAQEBevDBB/Xggw9WZj8AAABepTLGVMePH1fz5s31wAMP6O677y6zf8qUKZo6darS09PVsGFDTZ48WZ06ddKuXbuse1clJydr2bJlWrRokUJDQzVmzBglJiZq06ZN8vHxqXBvAAAAp1OhUOqNN9444/5+/fpVqBkAAABvUlljqoSEBCUkJJS7zxij6dOna8KECerVq5ckae7cuYqIiNDChQs1dOhQ5eXlafbs2Zo3b546duwoSZo/f76ioqK0cuVKdenS5TyuCgAA4NxUKJR65JFHPNaLi4v1888/y9/fXzVr1iSUAgAAOAd2jKn27t2r7Oxsde7c2drmdDrVtm1brV27VkOHDtWmTZtUXFzsURMZGanY2FitXbuWUAoAAFwUFQqlcnNzy2zbvXu3Hn74Yf3xj3+84KYAAAC8gR1jquzsbElSRESEx/aIiAjt27fPqvH391etWrXK1JS+vjyFhYUqLCy01vPz8yulZwAA4B0qdKPz8sTExOjZZ58t840fAAAAzt3FGlM5HA6PdWNMmW2nOltNWlqaXC6XtURFRVVKrwAAwDtUWiglST4+Pvr+++8r85AAAABepzLHVG63W5LKzHjKycmxZk+53W4VFRWVmbn125ryjB8/Xnl5edZy4MCBSukZAAB4hwr9fO+dd97xWDfGKCsrSzNnztQtt9xSKY0BAABc7uwYU0VHR8vtdmvFihVq0aKFJKmoqEhr1qzRc889J0lq2bKl/Pz8tGLFCvXu3VuSlJWVpe3bt2vKlCmnPbbT6ZTT6ayUPgEAgPepUCh11113eaw7HA7Vrl1bd9xxh/7yl79URl8AAACXvcoaUx07dkxff/21tb53715t2bJFISEhqlu3rpKTk5WamqqYmBjFxMQoNTVVNWvWVN++fSVJLpdLAwcO1JgxYxQaGqqQkBCNHTtWTZs2tZ7GBwAAUNkqFEqdPHmysvsAAADwOpU1ptq4caPat29vrY8ePVqS1L9/f6Wnp2vcuHEqKCjQsGHDlJubq7i4OC1fvlxBQUHWa6ZNmyZfX1/17t1bBQUF6tChg9LT0+Xj41MpPQIAAJyqQqEUAAAAqo927drJGHPa/Q6HQykpKUpJSTltTY0aNTRjxgzNmDHjInQIAABQVoVCqdJv387F1KlTK3IKAACAyx5jKgAA4M0qFEp9/vnn2rx5s06cOKFGjRpJkr766iv5+PjoxhtvtOrO9phhAAAAb8aYCgAAeLMKhVLdu3dXUFCQ5s6dq1q1akmScnNz9cADD+i2227TmDFjKrVJAACAyxFjKgAA4M2uqMiL/vKXvygtLc0aPElSrVq1NHnyZJ6+BwAAcI4YUwEAAG9WoVAqPz9fhw4dKrM9JydHR48eveCmAAAAvAFjKgAA4M0qFEr17NlTDzzwgN5++20dPHhQBw8e1Ntvv62BAweqV69eld0jAADAZYkxFQAA8GYVuqfUyy+/rLFjx+oPf/iDiouLfz2Qr68GDhyo559/vlIbBAAAuFwxpgIAAN6sQqFUzZo19dJLL+n555/Xnj17ZIzRtddeq8DAwMruDwAA4LLFmAoAAHizCv18r1RWVpaysrLUsGFDBQYGyhhTWX0BAAB4DcZUAADAG1UolDp8+LA6dOighg0b6s4771RWVpYkadCgQTy6GAAA4BwxpgIAAN6sQqHUo48+Kj8/P+3fv181a9a0tvfp00cZGRmV1hwAAMDljDEVAADwZhW6p9Ty5cv14Ycf6uqrr/bYHhMTo3379lVKYwAAAJc7xlQAAMCbVWim1PHjxz2+zSv1448/yul0XnBTAAAA3oAxFQAA8GYVCqVuv/12vfHGG9a6w+HQyZMn9fzzz6t9+/aV1hwAAMDljDEVAADwZhX6+d7zzz+vdu3aaePGjSoqKtK4ceO0Y8cO/fTTT/rPf/5T2T0CAABclhhTAQAAb1ahmVLXX3+9tm3bpptvvlmdOnXS8ePH1atXL33++edq0KBBZfcIAABwWWJMBQAAvNl5z5QqLi5W586d9corr2jSpEkXoycAAIDLHmMqAADg7c57ppSfn5+2b98uh8NxMfoBAADwCoypAACAt6vQz/f69eun2bNnV3YvAAAAXoUxFQAA8GYVutF5UVGR/va3v2nFihVq1aqVAgMDPfZPnTq1UpoDAAC4nDGmAgAA3uy8QqlvvvlG9evX1/bt23XjjTdKkr766iuPGqagAwAAnBljKgAAgPMMpWJiYpSVlaWPP/5YktSnTx+9+OKLioiIuCjNAQAAXI4YUwEAAJznPaWMMR7rH3zwgY4fP16pDQEAAFzuGFMBAABU8EbnpU4dUAEAAOD8MaYCAADe6LxCKYfDUeb+BtzvAAAA4PwwpgIAADjPe0oZYzRgwAA5nU5J0i+//KKHHnqozJNiFi9eXHkdAgAAXGYYUwEAAJxnKNW/f3+P9T/84Q+V2gwAAIA3YEwFAABwnqHUnDlzLlYfAAAAXoMxFQAAwAXe6BwAAAAAAACoCEIpAAAAAAAA2I5QCgAAAAAAALYjlAIAAAAAAIDtCKUAAAAAAABgO0IpAAAAAAAA2I5QCgAAAAAAALYjlAIAAAAAAIDtCKUAAAAAAABgO0IpAAAAAAAA2I5QCgAAAAAAALar0lBq1qxZatasmYKDgxUcHKz4+Hh98MEH1n5jjFJSUhQZGamAgAC1a9dOO3bs8DhGYWGhRo4cqbCwMAUGBqpHjx46ePCgR01ubq6SkpLkcrnkcrmUlJSkI0eO2HGJAAAAAAAAKEeVhlJXX321nn32WW3cuFEbN27UHXfcod/97ndW8DRlyhRNnTpVM2fO1IYNG+R2u9WpUycdPXrUOkZycrKWLFmiRYsW6dNPP9WxY8eUmJiokpISq6Zv377asmWLMjIylJGRoS1btigpKcn26wUAAAAAAMCvfKvy5N27d/dYf+aZZzRr1ixlZmbq+uuv1/Tp0zVhwgT16tVLkjR37lxFRERo4cKFGjp0qPLy8jR79mzNmzdPHTt2lCTNnz9fUVFRWrlypbp06aKdO3cqIyNDmZmZiouLkyS99tprio+P165du9SoUSN7LxoAAAAAAADV555SJSUlWrRokY4fP674+Hjt3btX2dnZ6ty5s1XjdDrVtm1brV27VpK0adMmFRcXe9RERkYqNjbWqlm3bp1cLpcVSElS69at5XK5rJryFBYWKj8/32MBAAAAAABA5ajyUOqLL77QlVdeKafTqYceekhLlizR9ddfr+zsbElSRESER31ERIS1Lzs7W/7+/qpVq9YZa8LDw8ucNzw83KopT1pamnUPKpfLpaioqAu6TgAAAAAAAPxPlYdSjRo10pYtW5SZmamHH35Y/fv315dffmntdzgcHvXGmDLbTnVqTXn1ZzvO+PHjlZeXZy0HDhw410sCAAAAAADAWVR5KOXv769rr71WrVq1Ulpampo3b64XXnhBbrdbksrMZsrJybFmT7ndbhUVFSk3N/eMNYcOHSpz3h9++KHMLKzfcjqd1lMBSxcAAAAAAABUjioPpU5ljFFhYaGio6Pldru1YsUKa19RUZHWrFmjNm3aSJJatmwpPz8/j5qsrCxt377dqomPj1deXp7Wr19v1Xz22WfKy8uzagAAAAAAAGCvKn363hNPPKGEhARFRUXp6NGjWrRokVavXq2MjAw5HA4lJycrNTVVMTExiomJUWpqqmrWrKm+fftKklwulwYOHKgxY8YoNDRUISEhGjt2rJo2bWo9ja9x48bq2rWrBg8erFdeeUWSNGTIECUmJvLkPQAAAAAAgCpSpaHUoUOHlJSUpKysLLlcLjVr1kwZGRnq1KmTJGncuHEqKCjQsGHDlJubq7i4OC1fvlxBQUHWMaZNmyZfX1/17t1bBQUF6tChg9LT0+Xj42PVLFiwQKNGjbKe0tejRw/NnDnT3osFAAAAAACApUpDqdmzZ59xv8PhUEpKilJSUk5bU6NGDc2YMUMzZsw4bU1ISIjmz59f0TYBAAAAAABQyardPaUAAAAAAABw+SOUAgAAAAAAgO0IpQAAAC5z9evXl8PhKLMMHz5ckjRgwIAy+1q3bl3FXQMAgMtdld5TCgAAABffhg0bVFJSYq1v375dnTp10j333GNt69q1q+bMmWOt+/v729ojAADwPoRSAAAAl7natWt7rD/77LNq0KCB2rZta21zOp1yu912twYAALwYP98DAADwIkVFRZo/f74efPBBORwOa/vq1asVHh6uhg0bavDgwcrJyTnrsQoLC5Wfn++xAAAAnCtCKQAAAC+ydOlSHTlyRAMGDLC2JSQkaMGCBVq1apX+8pe/aMOGDbrjjjtUWFh4xmOlpaXJ5XJZS1RU1EXuHgAAXE74+R4AAIAXmT17thISEhQZGWlt69Onj/XPsbGxatWqlerVq6f33ntPvXr1Ou2xxo8fr9GjR1vr+fn5BFMAAOCcEUoBAAB4iX379mnlypVavHjxGevq1KmjevXqaffu3WesczqdcjqdldkiAADwIvx8DwAAwEvMmTNH4eHh6tat2xnrDh8+rAMHDqhOnTo2dQYAALwRoRQAAIAXOHnypObMmaP+/fvL1/d/k+WPHTumsWPHat26dfr222+1evVqde/eXWFhYerZs2cVdgwAAC53/HwPAADAC6xcuVL79+/Xgw8+6LHdx8dHX3zxhd544w0dOXJEderUUfv27fXWW28pKCioiroFAADegFAKAADAC3Tu3FnGmDLbAwIC9OGHH1ZBRwAAwNvx8z0AAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO2qNJRKS0vTTTfdpKCgIIWHh+uuu+7Srl27PGqMMUpJSVFkZKQCAgLUrl077dixw6OmsLBQI0eOVFhYmAIDA9WjRw8dPHjQoyY3N1dJSUlyuVxyuVxKSkrSkSNHLvYlAgAAAAAAoBxVGkqtWbNGw4cPV2ZmplasWKETJ06oc+fOOn78uFUzZcoUTZ06VTNnztSGDRvkdrvVqVMnHT161KpJTk7WkiVLtGjRIn366ac6duyYEhMTVVJSYtX07dtXW7ZsUUZGhjIyMrRlyxYlJSXZer0AAAAAAAD4lW9VnjwjI8Njfc6cOQoPD9emTZt0++23yxij6dOna8KECerVq5ckae7cuYqIiNDChQs1dOhQ5eXlafbs2Zo3b546duwoSZo/f76ioqK0cuVKdenSRTt37lRGRoYyMzMVFxcnSXrttdcUHx+vXbt2qVGjRvZeOAAAAAAAgJerVveUysvLkySFhIRIkvbu3avs7Gx17tzZqnE6nWrbtq3Wrl0rSdq0aZOKi4s9aiIjIxUbG2vVrFu3Ti6XywqkJKl169ZyuVxWzakKCwuVn5/vsQAAAAAAAKByVJtQyhij0aNH69Zbb1VsbKwkKTs7W5IUERHhURsREWHty87Olr+/v2rVqnXGmvDw8DLnDA8Pt2pOlZaWZt1/yuVyKSoq6sIuEAAAAAAAAJZqE0qNGDFC27Zt05tvvllmn8Ph8Fg3xpTZdqpTa8qrP9Nxxo8fr7y8PGs5cODAuVwGAAAAAAAAzkG1CKVGjhypd955Rx9//LGuvvpqa7vb7ZakMrOZcnJyrNlTbrdbRUVFys3NPWPNoUOHypz3hx9+KDMLq5TT6VRwcLDHAgAAAAAAgMpRpaGUMUYjRozQ4sWLtWrVKkVHR3vsj46Oltvt1ooVK6xtRUVFWrNmjdq0aSNJatmypfz8/DxqsrKytH37dqsmPj5eeXl5Wr9+vVXz2WefKS8vz6oBAAAAAACAfao0lBo+fLjmz5+vhQsXKigoSNnZ2crOzlZBQYGkX39yl5ycrNTUVC1ZskTbt2/XgAEDVLNmTfXt21eS5HK5NHDgQI0ZM0YfffSRPv/8c/3hD39Q06ZNrafxNW7cWF27dtXgwYOVmZmpzMxMDR48WImJiTx5DwAAXPZSUlLkcDg8ltIZ6dKvXxSmpKQoMjJSAQEBateunXbs2FGFHQMAAG/gW5UnnzVrliSpXbt2HtvnzJmjAQMGSJLGjRungoICDRs2TLm5uYqLi9Py5csVFBRk1U+bNk2+vr7q3bu3CgoK1KFDB6Wnp8vHx8eqWbBggUaNGmU9pa9Hjx6aOXPmxb1AAACAaqJJkyZauXKltf7bcdKUKVM0depUpaenq2HDhpo8ebI6deqkXbt2eYy5AAAAKlOVhlLGmLPWOBwOpaSkKCUl5bQ1NWrU0IwZMzRjxozT1oSEhGj+/PkVaRMAAOCS5+vr6zE7qpQxRtOnT9eECRPUq1cvSdLcuXMVERGhhQsXaujQoXa3CgAAvES1uNE5AAAALq7du3crMjJS0dHRuvfee/XNN99Ikvbu3avs7GxrNrn06wNf2rZtq7Vr11ZVuwAAwAtU6UwpAAAAXHxxcXF644031LBhQx06dEiTJ09WmzZttGPHDuspx6c+kTgiIkL79u0743ELCwtVWFhorefn51d+8wAA4LJFKAUAAHCZS0hIsP65adOmio+PV4MGDTR37ly1bt1a0q+3TPgtY0yZbadKS0vTpEmTKr9hAADgFfj5HgAAgJcJDAxU06ZNtXv3bus+U6Uzpkrl5OSUmT11qvHjxysvL89aDhw4cNF6BgAAlx9CKQAAAC9TWFionTt3qk6dOoqOjpbb7daKFSus/UVFRVqzZo3atGlzxuM4nU4FBwd7LAAAAOeKn+8BAABc5saOHavu3burbt26ysnJ0eTJk5Wfn6/+/fvL4XAoOTlZqampiomJUUxMjFJTU1WzZk317du3qlsHAACXMUIpAACAy9zBgwd133336ccff1Tt2rXVunVrZWZmql69epKkcePGqaCgQMOGDVNubq7i4uK0fPlyBQUFVXHnAADgckYoBQAAcJlbtGjRGfc7HA6lpKQoJSXFnoYAAADEPaUAAAAAAABQBQilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiuSkOpTz75RN27d1dkZKQcDoeWLl3qsd8Yo5SUFEVGRiogIEDt2rXTjh07PGoKCws1cuRIhYWFKTAwUD169NDBgwc9anJzc5WUlCSXyyWXy6WkpCQdOXLkIl8dAAAAAAAATqdKQ6njx4+refPmmjlzZrn7p0yZoqlTp2rmzJnasGGD3G63OnXqpKNHj1o1ycnJWrJkiRYtWqRPP/1Ux44dU2JiokpKSqyavn37asuWLcrIyFBGRoa2bNmipKSki359AAAAAAAAKJ9vVZ48ISFBCQkJ5e4zxmj69OmaMGGCevXqJUmaO3euIiIitHDhQg0dOlR5eXmaPXu25s2bp44dO0qS5s+fr6ioKK1cuVJdunTRzp07lZGRoczMTMXFxUmSXnvtNcXHx2vXrl1q1KiRPRcLAAAAAAAAS7W9p9TevXuVnZ2tzp07W9ucTqfatm2rtWvXSpI2bdqk4uJij5rIyEjFxsZaNevWrZPL5bICKUlq3bq1XC6XVQMAAAAAAAB7VelMqTPJzs6WJEVERHhsj4iI0L59+6waf39/1apVq0xN6euzs7MVHh5e5vjh4eFWTXkKCwtVWFhorefn51fsQgAAAAAAAFBGtZ0pVcrhcHisG2PKbDvVqTXl1Z/tOGlpadaN0V0ul6Kios6zcwAAgOohLS1NN910k4KCghQeHq677rpLu3bt8qgZMGCAHA6Hx9K6desq6hgAAHiDahtKud1uSSozmyknJ8eaPeV2u1VUVKTc3Nwz1hw6dKjM8X/44Ycys7B+a/z48crLy7OWAwcOXND1AAAAVJU1a9Zo+PDhyszM1IoVK3TixAl17txZx48f96jr2rWrsrKyrOX999+voo4BAIA3qLahVHR0tNxut1asWGFtKyoq0po1a9SmTRtJUsuWLeXn5+dRk5WVpe3bt1s18fHxysvL0/r1662azz77THl5eVZNeZxOp4KDgz0WAACAS1FGRoYGDBigJk2aqHnz5pozZ47279+vTZs2edQ5nU653W5rCQkJqaKOAQCAN6jSe0odO3ZMX3/9tbW+d+9ebdmyRSEhIapbt66Sk5OVmpqqmJgYxcTEKDU1VTVr1lTfvn0lSS6XSwMHDtSYMWMUGhqqkJAQjR07Vk2bNrWexte4cWN17dpVgwcP1iuvvCJJGjJkiBITE3nyHgAA8Ep5eXmSVCZ0Wr16tcLDw3XVVVepbdu2euaZZ8q9N2cp7sEJAAAuRJWGUhs3blT79u2t9dGjR0uS+vfvr/T0dI0bN04FBQUaNmyYcnNzFRcXp+XLlysoKMh6zbRp0+Tr66vevXuroKBAHTp0UHp6unx8fKyaBQsWaNSoUdZT+nr06KGZM2fadJUAAADVhzFGo0eP1q233qrY2Fhre0JCgu655x7Vq1dPe/fu1ZNPPqk77rhDmzZtktPpLPdYaWlpmjRpkl2tAwCAy0yVhlLt2rWTMea0+x0Oh1JSUpSSknLamho1amjGjBmaMWPGaWtCQkI0f/78C2kVAADgsjBixAht27ZNn376qcf2Pn36WP8cGxurVq1aqV69enrvvffUq1evco81fvx460tF6deZUjwcBgAAnKsqDaUAAABgn5EjR+qdd97RJ598oquvvvqMtXXq1FG9evW0e/fu09Y4nc7TzqICAAA4G0IpAACAy5wxRiNHjtSSJUu0evVqRUdHn/U1hw8f1oEDB1SnTh0bOgQAAN6o2j59DwAAAJVj+PDhmj9/vhYuXKigoCBlZ2crOztbBQUFkn59+MzYsWO1bt06ffvtt1q9erW6d++usLAw9ezZs4q7BwAAlytmSgEAAFzmZs2aJenX+3n+1pw5czRgwAD5+Pjoiy++0BtvvKEjR46oTp06at++vd566y2PB8wAAABUJkIpAACAy9yZHiwjSQEBAfrwww9t6gYAAOBX/HwPAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7rwqlXnrpJUVHR6tGjRpq2bKl/v3vf1d1SwAAANUK4yUAAGAXrwml3nrrLSUnJ2vChAn6/PPPddtttykhIUH79++v6tYAAACqBcZLAADATl4TSk2dOlUDBw7UoEGD1LhxY02fPl1RUVGaNWtWVbcGAABQLTBeAgAAdvKKUKqoqEibNm1S586dPbZ37txZa9euraKuAAAAqg/GSwAAwG6+Vd2AHX788UeVlJQoIiLCY3tERISys7PLfU1hYaEKCwut9by8PElSfn7+RemxuPiiHBaXgYv0kTsvfD5xOnw+UV1dzM9m6VjAGHPxTlIFLonx0s/8gUf5LtZn7nzw+cTp8PlEdXUxP5vnOl7yilCqlMPh8Fg3xpTZViotLU2TJk0qsz0qKuqi9AacjstV1R0Ap8fnE9WVHZ/No0ePynUZ/iFgvIRLkWvQ5fdnEZcPPp+oruz4bJ5tvOQVoVRYWJh8fHzKfMuXk5NT5tvAUuPHj9fo0aOt9ZMnT+qnn35SaGjoaQdmuHD5+fmKiorSgQMHFBwcXNXtAB74fKI64/NpH2OMjh49qsjIyKpupVIxXrq08Gce1RWfTVRnfD7tc67jJa8Ipfz9/dWyZUutWLFCPXv2tLavWLFCv/vd78p9jdPplNPp9Nh21VVXXcw28RvBwcH8RwLVFp9PVGd8Pu1xOc6QYrx0aeLPPKorPpuozvh82uNcxkteEUpJ0ujRo5WUlKRWrVopPj5er776qvbv36+HHnqoqlsDAACoFhgvAQAAO3lNKNWnTx8dPnxYTz/9tLKyshQbG6v3339f9erVq+rWAAAAqgXGSwAAwE5eE0pJ0rBhwzRs2LCqbgNn4HQ6NXHixDI/BQCqAz6fqM74fKKyMF66NPBnHtUVn01UZ3w+qx+HudyeZwwAAAAAAIBq74qqbgAAAAAAAADeh1AKAAAAAAAAtiOUAgAAAAAAgO0IpVCtvPTSS4qOjlaNGjXUsmVL/fvf/67qlgB98skn6t69uyIjI+VwOLR06dKqbgmwpKWl6aabblJQUJDCw8N11113adeuXVXdFoCLiPESqivGTKiuGC9VX4RSqDbeeustJScna8KECfr888912223KSEhQfv376/q1uDljh8/rubNm2vmzJlV3QpQxpo1azR8+HBlZmZqxYoVOnHihDp37qzjx49XdWsALgLGS6jOGDOhumK8VH3x9D1UG3Fxcbrxxhs1a9Ysa1vjxo111113KS0trQo7A/7H4XBoyZIluuuuu6q6FaBcP/zwg8LDw7VmzRrdfvvtVd0OgErGeAmXCsZMqM4YL1UfzJRCtVBUVKRNmzapc+fOHts7d+6stWvXVlFXAHDpycvLkySFhIRUcScAKhvjJQCoHIyXqg9CKVQLP/74o0pKShQREeGxPSIiQtnZ2VXUFQBcWowxGj16tG699VbFxsZWdTsAKhnjJQC4cIyXqhffqm4A+C2Hw+Gxbowpsw0AUL4RI0Zo27Zt+vTTT6u6FQAXEeMlAKg4xkvVC6EUqoWwsDD5+PiU+ZYvJyenzLeBAICyRo4cqXfeeUeffPKJrr766qpuB8BFwHgJAC4M46Xqh5/voVrw9/dXy5YttWLFCo/tK1asUJs2baqoKwCo/owxGjFihBYvXqxVq1YpOjq6qlsCcJEwXgKAimG8VH0xUwrVxujRo5WUlKRWrVopPj5er776qvbv36+HHnqoqluDlzt27Ji+/vpra33v3r3asmWLQkJCVLdu3SrsDJCGDx+uhQsX6l//+peCgoKsGRQul0sBAQFV3B2AysZ4CdUZYyZUV4yXqi+HMcZUdRNAqZdeeklTpkxRVlaWYmNjNW3aNB7RiSq3evVqtW/fvsz2/v37Kz093f6GgN843X1k5syZowEDBtjbDABbMF5CdcWYCdUV46Xqi1AKAAAAAAAAtuOeUgAAAAAAALAdoRQAAAAAAABsRygFAAAAAAAA2xFKAQAAAAAAwHaEUgAAAAAAALAdoRQAAAAAAABsRygFAAAAAAAA2xFKAQAAAAAAwHaEUgBwCofDoaVLl1Z1GwAAANUW4yUAlYFQCoDXyc7O1siRI3XNNdfI6XQqKipK3bt310cffVTVrQEAAFQLjJcA2MG3qhsAADt9++23uuWWW3TVVVdpypQpatasmYqLi/Xhhx9q+PDh+u9//1vVLQIAAFQpxksA7MJMKQBeZdiwYXI4HFq/fr1+//vfq2HDhmrSpIlGjx6tzMzMcl/z2GOPqWHDhqpZs6auueYaPfnkkyouLrb2b926Ve3bt1dQUJCCg4PVsmVLbdy4UZK0b98+de/eXbVq1VJgYKCaNGmi999/35ZrBQAAqAjGSwDswkwpAF7jp59+UkZGhp555hkFBgaW2X/VVVeV+7qgoCClp6crMjJSX3zxhQYPHqygoCCNGzdOknT//ferRYsWmjVrlnx8fLRlyxb5+flJkoYPH66ioiJ98sknCgwM1Jdffqkrr7zyol0jAADAhWC8BMBOhFIAvMbXX38tY4yuu+6683rdn/70J+uf69evrzFjxuitt96yBln79+/XH//4R+u4MTExVv3+/ft19913q2nTppKka6655kIvAwAA4KJhvATATvx8D4DXMMZI+vVpMefj7bff1q233iq3260rr7xSTz75pPbv32/tHz16tAYNGqSOHTvq2Wef1Z49e6x9o0aN0uTJk3XLLbdo4sSJ2rZtW+VcDAAAwEXAeAmAnQilAHiNmJgYORwO7dy585xfk5mZqXvvvVcJCQl699139fnnn2vChAkqKiqyalJSUrRjxw5169ZNq1at0vXXX68lS5ZIkgYNGqRvvvlGSUlJ+uKLL9SqVSvNmDGj0q8NAACgMjBeAmAnhymNwgHACyQkJOiLL77Qrl27ytwn4ciRI7rqqqvkcDi0ZMkS3XXXXfrLX/6il156yePbvEGDBuntt9/WkSNHyj3Hfffdp+PHj+udd94ps2/8+PF67733+AYQAABUW4yXANiFmVIAvMpLL72kkpIS3XzzzfrnP/+p3bt3a+fOnXrxxRcVHx9fpv7aa6/V/v37tWjRIu3Zs0cvvvii9a2eJBUUFGjEiBFavXq19u3bp//85z/asGGDGjduLElKTk7Whx9+qL1792rz5s1atWqVtQ8AAKA6YrwEwC7c6ByAV4mOjtbmzZv1zDPPaMyYMcrKylLt2rXVsmVLzZo1q0z97373Oz366KMaMWKECgsL1a1bNz355JNKSUmRJPn4+Ojw4cPq16+fDh06pLCwMPXq1UuTJk2SJJWUlGj48OE6ePCggoOD1bVrV02bNs3OSwYAADgvjJcA2IWf7wEAAAAAAMB2/HwPAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADYjlAKAAAAAAAAtiOUAgAAAAAAgO0IpQAAAAAAAGA7QikAAAAAAADY7v8D8cPK0IYEoD8AAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"markdown","source":"## (No PCA) Not Filtered - augmented data was used to train the model and the original data (test) was used to evaluate it.","metadata":{}},{"cell_type":"code","source":"if DO_ML:\n    print(\"Building machine learning models...\")\n    ml_models = build_ml_models()\n    print(\"Training and evaluating machine learning models...\")\n    # Example usage with the original test set\n    results = train_and_evaluate_ml_models(\n        models=ml_models,\n        X_augmented=X_aug,\n        y_augmented=y_aug,\n        X_test=X_test,\n        y_test=y_test,\n        apply_pca=False,\n        pca_variance_threshold=0.99,\n        apply_filters_bg_subtraction=False,\n        cv=5,\n        standardize_data_func=standardize_data\n    )\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:26:24.896163Z","iopub.execute_input":"2023-12-20T04:26:24.896923Z","iopub.status.idle":"2023-12-20T05:18:40.353823Z","shell.execute_reply.started":"2023-12-20T04:26:24.896890Z","shell.execute_reply":"2023-12-20T05:18:40.352591Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Building machine learning models...\nTraining and evaluating machine learning models...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\n\nSVM Model Results:\nCV: 5\nAccuracy: 0.7086315789473685\nPrecision: 0.7020319031796243\nRecall: 0.6929810893344347\nF1 Score: 0.695429640973835\nConfusion Matrix: \n[[161.   15.2  16.8]\n [ 29.4  83.8  24.8]\n [ 28.2  24.   91.8]]\n\nTP_TN_FP_FN: \n[{0: (0.3389473684210526, 0.9988963988919667, 0.11789473684210526, 0.06736842105263158), 1: (0.17894736842105263, 0.999202216066482, 0.08842105263157894, 0.11157894736842106), 2: (0.18947368421052632, 0.999180055401662, 0.0863157894736842, 0.11368421052631579)}, {0: (0.3389473684210526, 0.9988875346260387, 0.12210526315789473, 0.06736842105263158), 1: (0.17684210526315788, 0.9992110803324099, 0.08421052631578947, 0.11368421052631579), 2: (0.18947368421052632, 0.999175623268698, 0.08842105263157894, 0.11368421052631579)}, {0: (0.3389473684210526, 0.9988831024930748, 0.12421052631578948, 0.06736842105263158), 1: (0.17473684210526316, 0.9992155124653739, 0.08210526315789474, 0.11578947368421053), 2: (0.1936842105263158, 0.999180055401662, 0.0863157894736842, 0.10947368421052632)}, {0: (0.3368421052631579, 0.9988875346260387, 0.12210526315789473, 0.06947368421052631), 1: (0.17684210526315788, 0.9992243767313019, 0.07789473684210527, 0.11368421052631579), 2: (0.1957894736842105, 0.999171191135734, 0.09052631578947369, 0.10736842105263159)}, {0: (0.3410526315789474, 0.9988919667590027, 0.12, 0.06526315789473684), 1: (0.17473684210526316, 0.999219944598338, 0.08, 0.11578947368421053), 2: (0.19789473684210526, 0.999180055401662, 0.0863157894736842, 0.10526315789473684)}]\n\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\n\nAdaBoost Model Results:\nCV: 5\nAccuracy: 0.599578947368421\nPrecision: 0.5891405927925463\nRecall: 0.5928228746881596\nF1 Score: 0.5883136234765474\nConfusion Matrix: \n[[128.8  21.   43.2]\n [ 22.   92.   24. ]\n [ 40.8  39.2  64. ]]\n\nTP_TN_FP_FN: \n[{0: (0.23157894736842105, 0.9989141274238227, 0.10947368421052632, 0.17473684210526316), 1: (0.19789473684210526, 0.9991401662049861, 0.11789473684210526, 0.09263157894736843), 2: (0.16631578947368422, 0.9989894736842105, 0.17684210526315788, 0.1368421052631579)}, {0: (0.30526315789473685, 0.998803324099723, 0.16210526315789472, 0.10105263157894737), 1: (0.18947368421052632, 0.9991401662049861, 0.11789473684210526, 0.10105263157894737), 2: (0.11368421052631579, 0.9991268698060942, 0.11157894736842106, 0.18947368421052632)}, {0: (0.2463157894736842, 0.9988875346260387, 0.12210526315789473, 0.16), 1: (0.20210526315789473, 0.9991002770083103, 0.1368421052631579, 0.08842105263157894), 2: (0.13052631578947368, 0.9990204986149585, 0.16210526315789472, 0.1726315789473684)}, {0: (0.2673684210526316, 0.9988963988919667, 0.11789473684210526, 0.13894736842105262), 1: (0.20210526315789473, 0.9990914127423823, 0.14105263157894737, 0.08842105263157894), 2: (0.13894736842105262, 0.9990825484764543, 0.13263157894736843, 0.16421052631578947)}, {0: (0.30526315789473685, 0.9988299168975069, 0.14947368421052631, 0.10105263157894737), 1: (0.17684210526315788, 0.9991357340720222, 0.12, 0.11368421052631579), 2: (0.12421052631578948, 0.9991002770083103, 0.12421052631578948, 0.17894736842105263)}]\n\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\n\nXGBoost Model Results:\nCV: 5\nAccuracy: 0.776\nPrecision: 0.768769856602363\nRecall: 0.7681543223782467\nF1 Score: 0.7678378413307436\nConfusion Matrix: \n[[163.   13.   17. ]\n [ 14.  106.4  17.6]\n [ 19.2  25.6  99.2]]\n\nTP_TN_FP_FN: \n[{0: (0.35368421052631577, 0.9989850415512466, 0.07578947368421053, 0.05263157894736842), 1: (0.22736842105263158, 0.999219944598338, 0.08, 0.06315789473684211), 2: (0.2, 0.9992288088642659, 0.06315789473684211, 0.1031578947368421)}, {0: (0.3452631578947368, 0.9989939058171745, 0.07157894736842105, 0.061052631578947365), 1: (0.22105263157894736, 0.9992066481994459, 0.0863157894736842, 0.06947368421052631), 2: (0.2, 0.999202216066482, 0.07578947368421053, 0.1031578947368421)}, {0: (0.33473684210526317, 0.9989983379501386, 0.06947368421052631, 0.07157894736842105), 1: (0.22526315789473683, 0.9992155124653739, 0.08210526315789474, 0.06526315789473684), 2: (0.2168421052631579, 0.9992110803324099, 0.07157894736842105, 0.0863157894736842)}, {0: (0.3410526315789474, 0.9990072022160665, 0.06526315789473684, 0.06526315789473684), 1: (0.2231578947368421, 0.999219944598338, 0.08, 0.06736842105263158), 2: (0.21263157894736842, 0.999197783933518, 0.07789473684210527, 0.09052631578947369)}, {0: (0.3410526315789474, 0.9990027700831026, 0.06736842105263158, 0.06526315789473684), 1: (0.2231578947368421, 0.9992243767313019, 0.07789473684210527, 0.06736842105263158), 2: (0.21473684210526317, 0.999202216066482, 0.07578947368421053, 0.08842105263157894)}]\n\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\n\nGradient Boost Model Results:\nCV: 5\nAccuracy: 0.720842105263158\nPrecision: 0.712095321010092\nRecall: 0.7102570440456226\nF1 Score: 0.708850650257023\nConfusion Matrix: \n[[157.6  15.8  19.6]\n [ 17.  102.2  18.8]\n [ 28.6  32.8  82.6]]\n\nTP_TN_FP_FN: \n[{0: (0.33052631578947367, 0.9989407202216066, 0.0968421052631579, 0.07578947368421053), 1: (0.21052631578947367, 0.9991667590027701, 0.10526315789473684, 0.08), 2: (0.1705263157894737, 0.999180055401662, 0.0863157894736842, 0.13263157894736843)}, {0: (0.33052631578947367, 0.9989451523545706, 0.09473684210526316, 0.07578947368421053), 1: (0.21473684210526317, 0.999180055401662, 0.09894736842105263, 0.07578947368421053), 2: (0.17894736842105263, 0.99918891966759, 0.08210526315789474, 0.12421052631578948)}, {0: (0.33473684210526317, 0.9989318559556787, 0.10105263157894737, 0.07157894736842105), 1: (0.21894736842105264, 0.9991623268698061, 0.10736842105263159, 0.07157894736842105), 2: (0.16631578947368422, 0.9992110803324099, 0.07157894736842105, 0.1368421052631579)}, {0: (0.33263157894736844, 0.9989495844875346, 0.09263157894736843, 0.07368421052631578), 1: (0.2231578947368421, 0.999180055401662, 0.09894736842105263, 0.06736842105263158), 2: (0.17473684210526316, 0.999197783933518, 0.07789473684210527, 0.12842105263157894)}, {0: (0.33052631578947367, 0.9989451523545706, 0.09473684210526316, 0.07578947368421053), 1: (0.20842105263157895, 0.999175623268698, 0.10105263157894737, 0.08210526315789474), 2: (0.17894736842105263, 0.999180055401662, 0.0863157894736842, 0.12421052631578948)}]\n\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\n\nRandom Forest Model Results:\nCV: 5\nAccuracy: 0.7608421052631579\nPrecision: 0.7547535352669901\nRecall: 0.7504837175540037\nF1 Score: 0.7505746211751404\nConfusion Matrix: \n[[164.4  15.2  13.4]\n [ 16.2 104.6  17.2]\n [ 23.4  28.2  92.4]]\n\nTP_TN_FP_FN: \n[{0: (0.3473684210526316, 0.9989806094182826, 0.07789473684210527, 0.05894736842105263), 1: (0.2231578947368421, 0.999180055401662, 0.09894736842105263, 0.06736842105263158), 2: (0.18947368421052632, 0.9992288088642659, 0.06315789473684211, 0.11368421052631579)}, {0: (0.3431578947368421, 0.9989673130193907, 0.08421052631578947, 0.06315789473684211), 1: (0.22105263157894736, 0.9992066481994459, 0.0863157894736842, 0.06947368421052631), 2: (0.1957894736842105, 0.9992155124653739, 0.06947368421052631, 0.10736842105263159)}, {0: (0.3452631578947368, 0.9989717451523547, 0.08210526315789474, 0.061052631578947365), 1: (0.22526315789473683, 0.999197783933518, 0.09052631578947369, 0.06526315789473684), 2: (0.2, 0.9992421052631578, 0.056842105263157895, 0.1031578947368421)}, {0: (0.3494736842105263, 0.9989407202216066, 0.0968421052631579, 0.056842105263157895), 1: (0.21473684210526317, 0.999202216066482, 0.08842105263157894, 0.07578947368421053), 2: (0.18526315789473685, 0.9992243767313019, 0.06526315789473684, 0.11789473684210526)}, {0: (0.3452631578947368, 0.9989850415512466, 0.07578947368421053, 0.061052631578947365), 1: (0.2168421052631579, 0.999193351800554, 0.09263157894736843, 0.07368421052631578), 2: (0.20210526315789473, 0.999219944598338, 0.06736842105263158, 0.10105263157894737)}]\n\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\n\nDecision Tree Model Results:\nCV: 5\nAccuracy: 0.6277894736842106\nPrecision: 0.6195097418202393\nRecall: 0.6199769717904433\nF1 Score: 0.6194494182052315\nConfusion Matrix: \n[[133.8  24.8  34.4]\n [ 26.   82.8  29.2]\n [ 26.8  35.6  81.6]]\n\nTP_TN_FP_FN: \n[{0: (0.28210526315789475, 0.9989008310249308, 0.11578947368421053, 0.12421052631578948), 1: (0.16421052631578947, 0.9991401662049861, 0.11789473684210526, 0.12631578947368421), 2: (0.15789473684210525, 0.9990204986149585, 0.16210526315789472, 0.14526315789473684)}, {0: (0.27789473684210525, 0.9989274238227146, 0.1031578947368421, 0.12842105263157894), 1: (0.1831578947368421, 0.9991180055401662, 0.12842105263157894, 0.10736842105263159), 2: (0.17894736842105263, 0.9990914127423823, 0.12842105263157894, 0.12421052631578948)}, {0: (0.2736842105263158, 0.9989008310249308, 0.11578947368421053, 0.13263157894736843), 1: (0.18526315789473685, 0.9991357340720222, 0.12, 0.10526315789473684), 2: (0.1705263157894737, 0.9990781163434903, 0.13473684210526315, 0.13263157894736843)}, {0: (0.3031578947368421, 0.9989141274238227, 0.10947368421052632, 0.1031578947368421), 1: (0.17684210526315788, 0.9991357340720222, 0.12, 0.11368421052631579), 2: (0.17684210526315788, 0.9991224376731301, 0.11368421052631579, 0.12631578947368421)}, {0: (0.27157894736842103, 0.9989096952908587, 0.11157894736842106, 0.13473684210526315), 1: (0.16210526315789472, 0.9990736842105263, 0.14947368421052631, 0.12842105263157894), 2: (0.17473684210526316, 0.9990869806094183, 0.13052631578947368, 0.12842105263157894)}]\n\nTraining Logistic Regression model on fold...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model on original data...\n\nLogistic Regression Model Results:\nCV: 5\nAccuracy: 0.720421052631579\nPrecision: 0.7059348439572832\nRecall: 0.7041335010387725\nF1 Score: 0.7043349551786435\nConfusion Matrix: \n[[164.8  12.8  15.4]\n [ 19.2  88.   30.8]\n [ 19.8  34.8  89.4]]\n\nTP_TN_FP_FN: \n[{0: (0.3452631578947368, 0.9989717451523547, 0.08210526315789474, 0.061052631578947365), 1: (0.18736842105263157, 0.999171191135734, 0.1031578947368421, 0.1031578947368421), 2: (0.1831578947368421, 0.999153462603878, 0.09894736842105263, 0.12)}, {0: (0.3494736842105263, 0.9989761772853186, 0.08, 0.056842105263157895), 1: (0.19789473684210526, 0.9991623268698061, 0.10736842105263159, 0.09263157894736843), 2: (0.18105263157894738, 0.999184487534626, 0.08421052631578947, 0.12210526315789473)}, {0: (0.3431578947368421, 0.9989806094182826, 0.07789473684210527, 0.06315789473684211), 1: (0.18526315789473685, 0.9991623268698061, 0.10736842105263159, 0.10526315789473684), 2: (0.18736842105263157, 0.999153462603878, 0.09894736842105263, 0.11578947368421053)}, {0: (0.3494736842105263, 0.9989628808864265, 0.0863157894736842, 0.056842105263157895), 1: (0.1705263157894737, 0.999202216066482, 0.08842105263157894, 0.12), 2: (0.1957894736842105, 0.9991313019390582, 0.10947368421052632, 0.10736842105263159)}, {0: (0.3473684210526316, 0.9989673130193907, 0.08421052631578947, 0.05894736842105263), 1: (0.18526315789473685, 0.99918891966759, 0.09473684210526316, 0.10526315789473684), 2: (0.1936842105263158, 0.9991623268698061, 0.09473684210526316, 0.10947368421052632)}]\n\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\n\nk-Nearest Neighbors Model Results:\nCV: 5\nAccuracy: 0.7385263157894737\nPrecision: 0.7411012762623904\nRecall: 0.7207289346115658\nF1 Score: 0.7239715318586886\nConfusion Matrix: \n[[171.6  12.6   8.8]\n [ 28.   94.8  15.2]\n [ 32.6  27.   84.4]]\n\nTP_TN_FP_FN: \n[{0: (0.35578947368421054, 0.9988653739612188, 0.13263157894736843, 0.05052631578947368), 1: (0.1957894736842105, 0.999219944598338, 0.08, 0.09473684210526316), 2: (0.1831578947368421, 0.9992509695290859, 0.05263157894736842, 0.12)}, {0: (0.36210526315789476, 0.9988742382271468, 0.12842105263157894, 0.04421052631578947), 1: (0.1936842105263158, 0.9992110803324099, 0.08421052631578947, 0.0968421052631579), 2: (0.17473684210526316, 0.9992421052631578, 0.056842105263157895, 0.12842105263157894)}, {0: (0.36210526315789476, 0.9988875346260387, 0.12210526315789473, 0.04421052631578947), 1: (0.20421052631578948, 0.999202216066482, 0.08842105263157894, 0.0863157894736842), 2: (0.17684210526315788, 0.9992642659279779, 0.04631578947368421, 0.12631578947368421)}, {0: (0.3642105263157895, 0.9988742382271468, 0.12842105263157894, 0.042105263157894736), 1: (0.20421052631578948, 0.9992155124653739, 0.08210526315789474, 0.0863157894736842), 2: (0.17684210526315788, 0.9992686980609419, 0.04421052631578947, 0.12631578947368421)}, {0: (0.36210526315789476, 0.9988786703601108, 0.12631578947368421, 0.04421052631578947), 1: (0.2, 0.9992155124653739, 0.08210526315789474, 0.09052631578947369), 2: (0.17684210526315788, 0.9992509695290859, 0.05263157894736842, 0.12631578947368421)}]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## (No PCA) Filtered - augmented data was used to train the model and the original data (test) was used to evaluate it.","metadata":{}},{"cell_type":"code","source":"if DO_ML:\n    print(\"Building machine learning models...\")\n    ml_models = build_ml_models()\n    print(\"Training and evaluating machine learning models...\")\n    # Example usage with the original test set\n    results = train_and_evaluate_ml_models(\n        models=ml_models,\n        X_augmented=X_aug,\n        y_augmented=y_aug,\n        X_test=X_test,\n        y_test=y_test,\n        apply_pca=False,\n        pca_variance_threshold=0.95,\n        apply_filters_bg_subtraction=True,\n        cv=5,\n        standardize_data_func=standardize_data\n    )","metadata":{"execution":{"iopub.status.busy":"2023-12-23T08:04:42.700299Z","iopub.execute_input":"2023-12-23T08:04:42.701303Z","iopub.status.idle":"2023-12-23T09:02:46.376778Z","shell.execute_reply.started":"2023-12-23T08:04:42.701266Z","shell.execute_reply":"2023-12-23T09:02:46.375778Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Building machine learning models...\nTraining and evaluating machine learning models...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\n\nSVM Model Results:\nCV: 5\nAccuracy: 0.6854736842105262\nPrecision: 0.6799055050745096\nRecall: 0.668603309887946\nF1 Score: 0.6712968759025284\nConfusion Matrix: \n[[158.4  16.4  18.2]\n [ 35.2  79.4  23.4]\n [ 30.8  25.4  87.8]]\n\nTP_TN_FP_FN: \n[{0: (0.33263157894736844, 0.9988565096952908, 0.1368421052631579, 0.07368421052631578), 1: (0.16842105263157894, 0.99918891966759, 0.09473684210526316, 0.12210526315789473), 2: (0.17894736842105263, 0.999175623268698, 0.08842105263157894, 0.12421052631578948)}, {0: (0.33473684210526317, 0.9988387811634349, 0.14526315789473684, 0.07157894736842105), 1: (0.16631578947368422, 0.9992066481994459, 0.0863157894736842, 0.12421052631578948), 2: (0.18105263157894738, 0.999180055401662, 0.0863157894736842, 0.12210526315789473)}, {0: (0.3368421052631579, 0.9988476454293629, 0.14105263157894737, 0.06947368421052631), 1: (0.16842105263157894, 0.9992110803324099, 0.08421052631578947, 0.12210526315789473), 2: (0.18736842105263157, 0.99918891966759, 0.08210526315789474, 0.11578947368421053)}, {0: (0.33052631578947367, 0.9988565096952908, 0.1368421052631579, 0.07578947368421053), 1: (0.16631578947368422, 0.999202216066482, 0.08842105263157894, 0.12421052631578948), 2: (0.18736842105263157, 0.999171191135734, 0.09052631578947369, 0.11578947368421053)}, {0: (0.33263157894736844, 0.9988609418282548, 0.13473684210526315, 0.07368421052631578), 1: (0.16631578947368422, 0.9992066481994459, 0.0863157894736842, 0.12421052631578948), 2: (0.18947368421052632, 0.999171191135734, 0.09052631578947369, 0.11368421052631579)}]\n\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\n\nAdaBoost Model Results:\nCV: 5\nAccuracy: 0.5835789473684211\nPrecision: 0.5692422459910967\nRecall: 0.57487766263673\nF1 Score: 0.5686846113864203\nConfusion Matrix: \n[[129.4  22.4  41.2]\n [ 24.4  92.   21.6]\n [ 46.2  42.   55.8]]\n\nTP_TN_FP_FN: \n[{0: (0.25473684210526315, 0.9988919667590027, 0.12, 0.15157894736842106), 1: (0.20210526315789473, 0.9990825484764543, 0.14526315789473684, 0.08842105263157894), 2: (0.12631578947368421, 0.9990426592797784, 0.15157894736842106, 0.17684210526315788)}, {0: (0.26105263157894737, 0.9988387811634349, 0.14526315789473684, 0.14526315789473684), 1: (0.1957894736842105, 0.9990736842105263, 0.14947368421052631, 0.09473684210526316), 2: (0.12, 0.9990914127423823, 0.12842105263157894, 0.1831578947368421)}, {0: (0.26105263157894737, 0.9988653739612188, 0.13263157894736843, 0.14526315789473684), 1: (0.2, 0.9991180055401662, 0.12842105263157894, 0.09052631578947369), 2: (0.1368421052631579, 0.9990648199445984, 0.14105263157894737, 0.16631578947368422)}, {0: (0.31157894736842107, 0.9987590027700831, 0.1831578947368421, 0.09473684210526316), 1: (0.18526315789473685, 0.9991268698060942, 0.12421052631578948, 0.10526315789473684), 2: (0.09263157894736843, 0.9991445983379501, 0.1031578947368421, 0.21052631578947367)}, {0: (0.2736842105263158, 0.998803324099723, 0.16210526315789472, 0.13263157894736843), 1: (0.18526315789473685, 0.9991135734072022, 0.13052631578947368, 0.10526315789473684), 2: (0.11157894736842106, 0.9990736842105263, 0.1368421052631579, 0.19157894736842104)}]\n\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\n\nXGBoost Model Results:\nCV: 5\nAccuracy: 0.7536842105263158\nPrecision: 0.7493804537100478\nRecall: 0.7445777327225852\nF1 Score: 0.7435988983143464\nConfusion Matrix: \n[[161.4  17.8  13.8]\n [ 16.2 106.6  15.2]\n [ 22.8  31.2  90. ]]\n\nTP_TN_FP_FN: \n[{0: (0.3431578947368421, 0.9990027700831026, 0.06736842105263158, 0.06315789473684211), 1: (0.24, 0.9991490304709141, 0.11368421052631579, 0.05052631578947368), 2: (0.1831578947368421, 0.9992509695290859, 0.05263157894736842, 0.12)}, {0: (0.3389473684210526, 0.9989628808864265, 0.0863157894736842, 0.06736842105263158), 1: (0.21894736842105264, 0.99918891966759, 0.09473684210526316, 0.07157894736842105), 2: (0.1957894736842105, 0.9992243767313019, 0.06526315789473684, 0.10736842105263159)}, {0: (0.3389473684210526, 0.9989540166204985, 0.09052631578947369, 0.06736842105263158), 1: (0.22105263157894736, 0.9991667590027701, 0.10526315789473684, 0.06947368421052631), 2: (0.18736842105263157, 0.9992421052631578, 0.056842105263157895, 0.11578947368421053)}, {0: (0.3431578947368421, 0.9989673130193907, 0.08421052631578947, 0.06315789473684211), 1: (0.22736842105263158, 0.9991667590027701, 0.10526315789473684, 0.06315789473684211), 2: (0.1831578947368421, 0.9992421052631578, 0.056842105263157895, 0.12)}, {0: (0.33473684210526317, 0.9989717451523547, 0.08210526315789474, 0.07157894736842105), 1: (0.21473684210526317, 0.999184487534626, 0.0968421052631579, 0.07578947368421053), 2: (0.19789473684210526, 0.9992066481994459, 0.07368421052631578, 0.10526315789473684)}]\n\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\n\nGradient Boost Model Results:\nCV: 5\nAccuracy: 0.7069473684210525\nPrecision: 0.7010505614790482\nRecall: 0.6952247753498035\nF1 Score: 0.6947395064645571\nConfusion Matrix: \n[[156.6  17.2  19.2]\n [ 23.2  98.8  16. ]\n [ 30.4  33.2  80.4]]\n\nTP_TN_FP_FN: \n[{0: (0.33052631578947367, 0.9988919667590027, 0.12, 0.07578947368421053), 1: (0.20421052631578948, 0.9991490304709141, 0.11368421052631579, 0.0863157894736842), 2: (0.16210526315789472, 0.9992155124653739, 0.06947368421052631, 0.14105263157894737)}, {0: (0.3368421052631579, 0.9989052631578947, 0.11368421052631579, 0.06947368421052631), 1: (0.21052631578947367, 0.999175623268698, 0.10105263157894737, 0.08), 2: (0.1705263157894737, 0.999219944598338, 0.06736842105263158, 0.13263157894736843)}, {0: (0.32421052631578945, 0.9989141274238227, 0.10947368421052632, 0.08210526315789474), 1: (0.2063157894736842, 0.9991578947368421, 0.10947368421052632, 0.08421052631578947), 2: (0.1726315789473684, 0.999197783933518, 0.07789473684210527, 0.13052631578947368)}, {0: (0.32421052631578945, 0.9989052631578947, 0.11368421052631579, 0.08210526315789474), 1: (0.21052631578947367, 0.999175623268698, 0.10105263157894737, 0.08), 2: (0.16842105263157894, 0.99918891966759, 0.08210526315789474, 0.13473684210526315)}, {0: (0.33263157894736844, 0.9989185595567867, 0.10736842105263159, 0.07368421052631578), 1: (0.20842105263157895, 0.9991667590027701, 0.10526315789473684, 0.08210526315789474), 2: (0.1726315789473684, 0.9992066481994459, 0.07368421052631578, 0.13052631578947368)}]\n\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\n\nRandom Forest Model Results:\nCV: 5\nAccuracy: 0.7427368421052631\nPrecision: 0.737008645581272\nRecall: 0.7317718371671964\nF1 Score: 0.7310256176015925\nConfusion Matrix: \n[[162.4  15.4  15.2]\n [ 17.4 104.8  15.8]\n [ 27.   31.4  85.6]]\n\nTP_TN_FP_FN: \n[{0: (0.3368421052631579, 0.9989584487534625, 0.08842105263157894, 0.06947368421052631), 1: (0.22526315789473683, 0.9991578947368421, 0.10947368421052632, 0.06526315789473684), 2: (0.17894736842105263, 0.9992332409972299, 0.061052631578947365, 0.12421052631578948)}, {0: (0.3431578947368421, 0.9989407202216066, 0.0968421052631579, 0.06315789473684211), 1: (0.2231578947368421, 0.99918891966759, 0.09473684210526316, 0.06736842105263158), 2: (0.17684210526315788, 0.9992243767313019, 0.06526315789473684, 0.12631578947368421)}, {0: (0.3410526315789474, 0.9989362880886427, 0.09894736842105263, 0.06526315789473684), 1: (0.21473684210526317, 0.99918891966759, 0.09473684210526316, 0.07578947368421053), 2: (0.18736842105263157, 0.9992288088642659, 0.06315789473684211, 0.11578947368421053)}, {0: (0.3452631578947368, 0.9989540166204985, 0.09052631578947369, 0.061052631578947365), 1: (0.2231578947368421, 0.999193351800554, 0.09263157894736843, 0.06736842105263158), 2: (0.18105263157894738, 0.999219944598338, 0.06736842105263158, 0.12210526315789473)}, {0: (0.3431578947368421, 0.9989495844875346, 0.09263157894736843, 0.06315789473684211), 1: (0.2168421052631579, 0.999175623268698, 0.10105263157894737, 0.07368421052631578), 2: (0.17684210526315788, 0.9992155124653739, 0.06947368421052631, 0.12631578947368421)}]\n\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\n\nDecision Tree Model Results:\nCV: 5\nAccuracy: 0.6341052631578947\nPrecision: 0.6233910936172513\nRecall: 0.6228348476884183\nF1 Score: 0.6228866110749749\nConfusion Matrix: \n[[140.   23.6  29.4]\n [ 27.6  78.4  32. ]\n [ 28.4  32.8  82.8]]\n\nTP_TN_FP_FN: \n[{0: (0.29473684210526313, 0.9988786703601108, 0.12631578947368421, 0.11157894736842106), 1: (0.16842105263157894, 0.9991268698060942, 0.12421052631578948, 0.12210526315789473), 2: (0.15578947368421053, 0.9990869806094183, 0.13052631578947368, 0.14736842105263157)}, {0: (0.27789473684210525, 0.9988875346260387, 0.12210526315789473, 0.12842105263157894), 1: (0.15578947368421053, 0.9991135734072022, 0.13052631578947368, 0.13473684210526315), 2: (0.16631578947368422, 0.9990515235457064, 0.14736842105263157, 0.1368421052631579)}, {0: (0.29473684210526313, 0.9988653739612188, 0.13263157894736843, 0.11157894736842106), 1: (0.16421052631578947, 0.9991667590027701, 0.10526315789473684, 0.12631578947368421), 2: (0.17894736842105263, 0.9991002770083103, 0.12421052631578948, 0.12421052631578948)}, {0: (0.30105263157894735, 0.9989141274238227, 0.10947368421052632, 0.10526315789473684), 1: (0.16, 0.999153462603878, 0.11157894736842106, 0.13052631578947368), 2: (0.2, 0.9991135734072022, 0.11789473684210526, 0.1031578947368421)}, {0: (0.30526315789473685, 0.9989362880886427, 0.09894736842105263, 0.10105263157894737), 1: (0.17684210526315788, 0.9991313019390582, 0.12210526315789473, 0.11368421052631579), 2: (0.1705263157894737, 0.9990958448753463, 0.12631578947368421, 0.13263157894736843)}]\n\nTraining Logistic Regression model on fold...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Evaluating Logistic Regression model on original data...\n\nLogistic Regression Model Results:\nCV: 5\nAccuracy: 0.6917894736842104\nPrecision: 0.6796489129221504\nRecall: 0.6757860670988628\nF1 Score: 0.6765161456157297\nConfusion Matrix: \n[[158.2  13.8  21. ]\n [ 26.2  80.6  31.2]\n [ 23.2  31.   89.8]]\n\nTP_TN_FP_FN: \n[{0: (0.33052631578947367, 0.9989540166204985, 0.09052631578947369, 0.07578947368421053), 1: (0.17684210526315788, 0.9991667590027701, 0.10526315789473684, 0.11368421052631579), 2: (0.19157894736842104, 0.9991401662049861, 0.10526315789473684, 0.11157894736842106)}, {0: (0.3263157894736842, 0.9989318559556787, 0.10105263157894737, 0.08), 1: (0.16842105263157894, 0.9992066481994459, 0.0863157894736842, 0.12210526315789473), 2: (0.1957894736842105, 0.9991047091412742, 0.12210526315789473, 0.10736842105263159)}, {0: (0.3368421052631579, 0.9989096952908587, 0.11157894736842106, 0.06947368421052631), 1: (0.1705263157894737, 0.999197783933518, 0.09052631578947369, 0.12), 2: (0.18526315789473685, 0.9991401662049861, 0.10526315789473684, 0.11789473684210526)}, {0: (0.32842105263157895, 0.9989451523545706, 0.09473684210526316, 0.07789473684210527), 1: (0.16421052631578947, 0.999193351800554, 0.09263157894736843, 0.12631578947368421), 2: (0.19789473684210526, 0.9991047091412742, 0.12210526315789473, 0.10526315789473684)}, {0: (0.3431578947368421, 0.9988875346260387, 0.12210526315789473, 0.06315789473684211), 1: (0.16842105263157894, 0.999184487534626, 0.0968421052631579, 0.12210526315789473), 2: (0.17473684210526316, 0.9991623268698061, 0.09473684210526316, 0.12842105263157894)}]\n\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\n\nk-Nearest Neighbors Model Results:\nCV: 5\nAccuracy: 0.7402105263157894\nPrecision: 0.7346834134217097\nRecall: 0.7283934277823667\nF1 Score: 0.7289980107920646\nConfusion Matrix: \n[[162.6  15.   15.4]\n [ 21.8 100.   16.2]\n [ 24.   31.   89. ]]\n\nTP_TN_FP_FN: \n[{0: (0.3452631578947368, 0.9989185595567867, 0.10736842105263159, 0.061052631578947365), 1: (0.20842105263157895, 0.999193351800554, 0.09263157894736843, 0.08210526315789474), 2: (0.18736842105263157, 0.9992376731301938, 0.05894736842105263, 0.11578947368421053)}, {0: (0.3368421052631579, 0.9989540166204985, 0.09052631578947369, 0.06947368421052631), 1: (0.20842105263157895, 0.9991667590027701, 0.10526315789473684, 0.08210526315789474), 2: (0.18526315789473685, 0.9992066481994459, 0.07368421052631578, 0.11789473684210526)}, {0: (0.3410526315789474, 0.9989495844875346, 0.09263157894736843, 0.06526315789473684), 1: (0.22105263157894736, 0.999175623268698, 0.10105263157894737, 0.06947368421052631), 2: (0.1831578947368421, 0.9992332409972299, 0.061052631578947365, 0.12)}, {0: (0.3410526315789474, 0.9989407202216066, 0.0968421052631579, 0.06526315789473684), 1: (0.21052631578947367, 0.999175623268698, 0.10105263157894737, 0.08), 2: (0.1831578947368421, 0.999219944598338, 0.06736842105263158, 0.12)}, {0: (0.3473684210526316, 0.9989451523545706, 0.09473684210526316, 0.05894736842105263), 1: (0.20421052631578948, 0.9992110803324099, 0.08421052631578947, 0.0863157894736842), 2: (0.19789473684210526, 0.9992110803324099, 0.07157894736842105, 0.10526315789473684)}]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## (PCA) Not Filtered - augmented data was used to train the model and the original data (test) was used to evaluate it.","metadata":{}},{"cell_type":"code","source":"if DO_ML:\n    print(\"Building machine learning models...\")\n    ml_models = build_ml_models()\n    print(\"Training and evaluating machine learning models...\")\n    # Example usage with the original test set\n    results = train_and_evaluate_ml_models(\n        models=ml_models,\n        X_augmented=X_aug,\n        y_augmented=y_aug,\n        X_test=X_test,\n        y_test=y_test,\n        apply_pca=True,\n        pca_variance_threshold=0.99,\n        apply_filters_bg_subtraction=False,\n        cv=5,\n        standardize_data_func=standardize_data\n    )","metadata":{"execution":{"iopub.status.busy":"2023-12-20T07:22:10.307189Z","iopub.execute_input":"2023-12-20T07:22:10.308040Z","iopub.status.idle":"2023-12-20T07:24:34.694516Z","shell.execute_reply.started":"2023-12-20T07:22:10.308003Z","shell.execute_reply":"2023-12-20T07:24:34.693073Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Building machine learning models...\nTraining and evaluating machine learning models...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\n\nSVM Model Results:\nCV: 5\nAccuracy: 0.5835789473684211\nPrecision: 0.5718525899740142\nRecall: 0.5550131202389593\nF1 Score: 0.5517940837958916\nConfusion Matrix: \n[[158.2  18.2  16.6]\n [ 47.8  62.8  27.4]\n [ 53.6  34.2  56.2]]\n\nTP_TN_FP_FN: \n[{0: (0.33052631578947367, 0.9986925207756233, 0.21473684210526317, 0.07578947368421053), 1: (0.13052631578947368, 0.999153462603878, 0.11157894736842106, 0.16), 2: (0.12, 0.9991667590027701, 0.09263157894736843, 0.1831578947368421)}, {0: (0.3389473684210526, 0.9986925207756233, 0.21473684210526317, 0.06736842105263158), 1: (0.13263157894736843, 0.999153462603878, 0.11157894736842106, 0.15789473684210525), 2: (0.11578947368421053, 0.999180055401662, 0.0863157894736842, 0.18736842105263157)}, {0: (0.33263157894736844, 0.9986969529085873, 0.21263157894736842, 0.07368421052631578), 1: (0.13052631578947368, 0.999153462603878, 0.11157894736842106, 0.16), 2: (0.12210526315789473, 0.999171191135734, 0.09052631578947369, 0.18105263157894738)}, {0: (0.33263157894736844, 0.9987013850415513, 0.21052631578947367, 0.07368421052631578), 1: (0.13473684210526315, 0.9991578947368421, 0.10947368421052632, 0.15578947368421053), 2: (0.11578947368421053, 0.9991578947368421, 0.0968421052631579, 0.18736842105263157)}, {0: (0.33052631578947367, 0.9986925207756233, 0.21473684210526317, 0.07578947368421053), 1: (0.13263157894736843, 0.9991623268698061, 0.10736842105263159, 0.15789473684210525), 2: (0.11789473684210526, 0.9991578947368421, 0.0968421052631579, 0.18526315789473685)}]\n\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\n\nAdaBoost Model Results:\nCV: 5\nAccuracy: 0.5389473684210525\nPrecision: 0.5183979118149562\nRecall: 0.5180344880812328\nF1 Score: 0.5097679950790361\nConfusion Matrix: \n[[139.4  24.8  28.8]\n [ 44.   73.2  20.8]\n [ 49.   51.6  43.4]]\n\nTP_TN_FP_FN: \n[{0: (0.2968421052631579, 0.9987279778393352, 0.19789473684210526, 0.10947368421052632), 1: (0.16421052631578947, 0.9990160664819945, 0.17684210526315788, 0.12631578947368421), 2: (0.07578947368421053, 0.999175623268698, 0.08842105263157894, 0.22736842105263158)}, {0: (0.29894736842105263, 0.9987102493074793, 0.2063157894736842, 0.10736842105263159), 1: (0.1431578947368421, 0.9990603878116344, 0.15578947368421053, 0.14736842105263157), 2: (0.08842105263157894, 0.9991357340720222, 0.10736842105263159, 0.21473684210526317)}, {0: (0.2968421052631579, 0.9987146814404433, 0.20421052631578948, 0.10947368421052632), 1: (0.14526315789473684, 0.9990603878116344, 0.15578947368421053, 0.14526315789473684), 2: (0.0863157894736842, 0.9991268698060942, 0.11157894736842106, 0.2168421052631579)}, {0: (0.28842105263157897, 0.9987412742382272, 0.19157894736842104, 0.11789473684210526), 1: (0.16631578947368422, 0.9990648199445984, 0.15368421052631578, 0.12421052631578948), 2: (0.09894736842105263, 0.9991490304709141, 0.10105263157894737, 0.20421052631578948)}, {0: (0.2863157894736842, 0.9987678670360111, 0.17894736842105263, 0.12), 1: (0.15157894736842106, 0.9990470914127424, 0.16210526315789472, 0.13894736842105262), 2: (0.10736842105263159, 0.9991224376731301, 0.11368421052631579, 0.1957894736842105)}]\n\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\n\nXGBoost Model Results:\nCV: 5\nAccuracy: 0.6741052631578948\nPrecision: 0.6656349241535462\nRecall: 0.6639568888555147\nF1 Score: 0.6630505935620004\nConfusion Matrix: \n[[147.4  22.6  23. ]\n [ 23.6  93.2  21.2]\n [ 29.2  35.2  79.6]]\n\nTP_TN_FP_FN: \n[{0: (0.3094736842105263, 0.9989096952908587, 0.11157894736842106, 0.0968421052631579), 1: (0.1957894736842105, 0.9991357340720222, 0.12, 0.09473684210526316), 2: (0.16631578947368422, 0.9991578947368421, 0.0968421052631579, 0.1368421052631579)}, {0: (0.30526315789473685, 0.9989141274238227, 0.10947368421052632, 0.10105263157894737), 1: (0.19157894736842104, 0.9991135734072022, 0.13052631578947368, 0.09894736842105263), 2: (0.1726315789473684, 0.999171191135734, 0.09052631578947369, 0.13052631578947368)}, {0: (0.3094736842105263, 0.9989141274238227, 0.10947368421052632, 0.0968421052631579), 1: (0.2, 0.9991224376731301, 0.12631578947368421, 0.09052631578947369), 2: (0.16631578947368422, 0.999175623268698, 0.08842105263157894, 0.1368421052631579)}, {0: (0.3178947368421053, 0.9989052631578947, 0.11368421052631579, 0.08842105263157894), 1: (0.19789473684210526, 0.9991313019390582, 0.12210526315789473, 0.09263157894736843), 2: (0.16, 0.999175623268698, 0.08842105263157894, 0.1431578947368421)}, {0: (0.3094736842105263, 0.9989096952908587, 0.11157894736842106, 0.0968421052631579), 1: (0.1957894736842105, 0.9991578947368421, 0.10947368421052632, 0.09473684210526316), 2: (0.1726315789473684, 0.9991490304709141, 0.10105263157894737, 0.13052631578947368)}]\n\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\n\nGradient Boost Model Results:\nCV: 5\nAccuracy: 0.6450526315789474\nPrecision: 0.633832794305845\nRecall: 0.6343600076760698\nF1 Score: 0.6326710645772502\nConfusion Matrix: \n[[143.2  20.   29.8]\n [ 22.6  92.   23.4]\n [ 37.4  35.4  71.2]]\n\nTP_TN_FP_FN: \n[{0: (0.30105263157894735, 0.9988520775623269, 0.13894736842105262, 0.10526315789473684), 1: (0.1957894736842105, 0.9991401662049861, 0.11789473684210526, 0.09473684210526316), 2: (0.1431578947368421, 0.9991445983379501, 0.1031578947368421, 0.16)}, {0: (0.29894736842105263, 0.9988875346260387, 0.12210526315789473, 0.10736842105263159), 1: (0.18736842105263157, 0.9991313019390582, 0.12210526315789473, 0.1031578947368421), 2: (0.15368421052631578, 0.9991180055401662, 0.11578947368421053, 0.14947368421052631)}, {0: (0.30105263157894735, 0.9988698060941829, 0.13052631578947368, 0.10526315789473684), 1: (0.1936842105263158, 0.9991357340720222, 0.12, 0.0968421052631579), 2: (0.14105263157894737, 0.9991224376731301, 0.11368421052631579, 0.16210526315789472)}, {0: (0.3031578947368421, 0.9988831024930748, 0.12421052631578948, 0.1031578947368421), 1: (0.1957894736842105, 0.9991623268698061, 0.10736842105263159, 0.09473684210526316), 2: (0.15789473684210525, 0.9991268698060942, 0.11157894736842106, 0.14526315789473684)}, {0: (0.3031578947368421, 0.9989008310249308, 0.11578947368421053, 0.1031578947368421), 1: (0.1957894736842105, 0.9991445983379501, 0.11578947368421053, 0.09473684210526316), 2: (0.15368421052631578, 0.9991180055401662, 0.11578947368421053, 0.14947368421052631)}]\n\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\n\nRandom Forest Model Results:\nCV: 5\nAccuracy: 0.6812631578947368\nPrecision: 0.6709821406934271\nRecall: 0.6689088925600527\nF1 Score: 0.6678997478623866\nConfusion Matrix: \n[[152.4  19.4  21.2]\n [ 22.4  93.4  22.2]\n [ 30.   36.2  77.8]]\n\nTP_TN_FP_FN: \n[{0: (0.3157894736842105, 0.9989052631578947, 0.11368421052631579, 0.09052631578947369), 1: (0.1936842105263158, 0.9991357340720222, 0.12, 0.0968421052631579), 2: (0.16, 0.9991578947368421, 0.0968421052631579, 0.1431578947368421)}, {0: (0.31157894736842107, 0.9988875346260387, 0.12210526315789473, 0.09473684210526316), 1: (0.1957894736842105, 0.9991401662049861, 0.11789473684210526, 0.09473684210526316), 2: (0.16421052631578947, 0.999175623268698, 0.08842105263157894, 0.13894736842105262)}, {0: (0.33052631578947367, 0.9989274238227146, 0.1031578947368421, 0.07578947368421053), 1: (0.20210526315789473, 0.999153462603878, 0.11157894736842106, 0.08842105263157894), 2: (0.16210526315789472, 0.999171191135734, 0.09052631578947369, 0.14105263157894737)}, {0: (0.32421052631578945, 0.9989052631578947, 0.11368421052631579, 0.08210526315789474), 1: (0.1957894736842105, 0.9991357340720222, 0.12, 0.09473684210526316), 2: (0.15789473684210525, 0.999175623268698, 0.08842105263157894, 0.14526315789473684)}, {0: (0.32210526315789473, 0.9989362880886427, 0.09894736842105263, 0.08421052631578947), 1: (0.1957894736842105, 0.9991445983379501, 0.11578947368421053, 0.09473684210526316), 2: (0.17473684210526316, 0.9991667590027701, 0.09263157894736843, 0.12842105263157894)}]\n\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\n\nDecision Tree Model Results:\nCV: 5\nAccuracy: 0.6227368421052631\nPrecision: 0.6117996408589633\nRecall: 0.6110803442550459\nF1 Score: 0.6109530199293849\nConfusion Matrix: \n[[138.8  21.4  32.8]\n [ 28.8  78.8  30.4]\n [ 29.8  36.   78.2]]\n\nTP_TN_FP_FN: \n[{0: (0.2926315789473684, 0.9988963988919667, 0.11789473684210526, 0.11368421052631579), 1: (0.15789473684210525, 0.9991445983379501, 0.11578947368421053, 0.13263157894736843), 2: (0.18947368421052632, 0.9990958448753463, 0.12631578947368421, 0.11368421052631579)}, {0: (0.3031578947368421, 0.9988520775623269, 0.13894736842105262, 0.1031578947368421), 1: (0.15789473684210525, 0.9990869806094183, 0.1431578947368421, 0.13263157894736843), 2: (0.14105263157894737, 0.9991180055401662, 0.11578947368421053, 0.16210526315789472)}, {0: (0.2905263157894737, 0.9988831024930748, 0.12421052631578948, 0.11578947368421053), 1: (0.16421052631578947, 0.9991490304709141, 0.11368421052631579, 0.12631578947368421), 2: (0.16, 0.9990515235457064, 0.14736842105263157, 0.1431578947368421)}, {0: (0.30105263157894735, 0.9988875346260387, 0.12210526315789473, 0.10526315789473684), 1: (0.17473684210526316, 0.9991578947368421, 0.10947368421052632, 0.11578947368421053), 2: (0.16421052631578947, 0.9990914127423823, 0.12842105263157894, 0.13894736842105262)}, {0: (0.2736842105263158, 0.9989052631578947, 0.11368421052631579, 0.13263157894736843), 1: (0.17473684210526316, 0.9991313019390582, 0.12210526315789473, 0.11578947368421053), 2: (0.16842105263157894, 0.9990515235457064, 0.14736842105263157, 0.13473684210526315)}]\n\nTraining Logistic Regression model on fold...\nEvaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\nEvaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\nEvaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\nEvaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\nEvaluating Logistic Regression model on original data...\n\nLogistic Regression Model Results:\nCV: 5\nAccuracy: 0.38273684210526315\nPrecision: 0.33127933497544587\nRecall: 0.3716767623672332\nF1 Score: 0.32729485526470176\nConfusion Matrix: \n[[97.  72.8 23.2]\n [54.2 78.   5.8]\n [57.2 80.   6.8]]\n\nTP_TN_FP_FN: \n[{0: (0.20421052631578948, 0.9986481994459834, 0.23578947368421052, 0.20210526315789473), 1: (0.16421052631578947, 0.9987146814404433, 0.32, 0.12631578947368421), 2: (0.014736842105263158, 0.9992332409972299, 0.061052631578947365, 0.28842105263157897)}, {0: (0.20421052631578948, 0.9986526315789473, 0.2336842105263158, 0.20210526315789473), 1: (0.16421052631578947, 0.9987146814404433, 0.32, 0.12631578947368421), 2: (0.014736842105263158, 0.9992288088642659, 0.06315789473684211, 0.28842105263157897)}, {0: (0.20842105263157895, 0.9986437673130193, 0.23789473684210527, 0.19789473684210526), 1: (0.16421052631578947, 0.9987058171745152, 0.32421052631578945, 0.12631578947368421), 2: (0.01263157894736842, 0.9992509695290859, 0.05263157894736842, 0.2905263157894737)}, {0: (0.20421052631578948, 0.9986526315789473, 0.2336842105263158, 0.20210526315789473), 1: (0.16421052631578947, 0.9987058171745152, 0.32421052631578945, 0.12631578947368421), 2: (0.014736842105263158, 0.9992376731301938, 0.05894736842105263, 0.28842105263157897)}, {0: (0.2, 0.9986570637119113, 0.23157894736842105, 0.2063157894736842), 1: (0.16421052631578947, 0.9987146814404433, 0.32, 0.12631578947368421), 2: (0.014736842105263158, 0.9992155124653739, 0.06947368421052631, 0.28842105263157897)}]\n\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\n\nk-Nearest Neighbors Model Results:\nCV: 5\nAccuracy: 0.6669473684210526\nPrecision: 0.6633170193655133\nRecall: 0.6548708626400674\nF1 Score: 0.6541500274497283\nConfusion Matrix: \n[[149.4  22.   21.6]\n [ 31.8  92.8  13.4]\n [ 29.6  39.8  74.6]]\n\nTP_TN_FP_FN: \n[{0: (0.3136842105263158, 0.9988432132963989, 0.1431578947368421, 0.09263157894736843), 1: (0.1936842105263158, 0.9991180055401662, 0.12842105263157894, 0.0968421052631579), 2: (0.15157894736842106, 0.9992155124653739, 0.06947368421052631, 0.15157894736842106)}, {0: (0.30736842105263157, 0.9988476454293629, 0.14105263157894737, 0.09894736842105263), 1: (0.18105263157894738, 0.9991047091412742, 0.13473684210526315, 0.10947368421052632), 2: (0.15789473684210525, 0.999197783933518, 0.07789473684210527, 0.14526315789473684)}, {0: (0.32210526315789473, 0.9988963988919667, 0.11789473684210526, 0.08421052631578947), 1: (0.1936842105263158, 0.9991135734072022, 0.13052631578947368, 0.0968421052631579), 2: (0.16, 0.999202216066482, 0.07578947368421053, 0.1431578947368421)}, {0: (0.32, 0.9988963988919667, 0.11789473684210526, 0.0863157894736842), 1: (0.2063157894736842, 0.9991091412742382, 0.13263157894736843, 0.08421052631578947), 2: (0.15578947368421053, 0.999219944598338, 0.06736842105263158, 0.14736842105263157)}, {0: (0.3094736842105263, 0.9988786703601108, 0.12631578947368421, 0.0968421052631579), 1: (0.20210526315789473, 0.9991268698060942, 0.12421052631578948, 0.08842105263157894), 2: (0.16, 0.999197783933518, 0.07789473684210527, 0.1431578947368421)}]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## (PCA) Filtered - augmented data was used to train the model and the original data (test) was used to evaluate it.","metadata":{}},{"cell_type":"code","source":"if DO_ML:\n    print(\"Building machine learning models...\")\n    ml_models = build_ml_models()\n    print(\"Training and evaluating machine learning models...\")\n    # Example usage with the original test set\n    results = train_and_evaluate_ml_models(\n        models=ml_models,\n        X_augmented=X_aug,\n        y_augmented=y_aug,\n        X_test=X_test,\n        y_test=y_test,\n        apply_pca=True,\n        pca_variance_threshold=0.99,\n        apply_filters_bg_subtraction=True,\n        cv=5,\n        standardize_data_func=standardize_data\n    )","metadata":{"execution":{"iopub.status.busy":"2023-12-20T07:26:56.680451Z","iopub.execute_input":"2023-12-20T07:26:56.681222Z","iopub.status.idle":"2023-12-20T07:35:28.740042Z","shell.execute_reply.started":"2023-12-20T07:26:56.681192Z","shell.execute_reply":"2023-12-20T07:35:28.738702Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Building machine learning models...\nTraining and evaluating machine learning models...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\nTraining SVM model on fold...\nEvaluating SVM model on original data...\n\nSVM Model Results:\nCV: 5\nAccuracy: 0.5797894736842106\nPrecision: 0.5693653928760587\nRecall: 0.5507828339716152\nF1 Score: 0.5476030412878241\nConfusion Matrix: \n[[158.   19.2  15.8]\n [ 49.6  61.   27.4]\n [ 54.6  33.   56.4]]\n\nTP_TN_FP_FN: \n[{0: (0.32842105263157895, 0.9986969529085873, 0.21263157894736842, 0.07789473684210527), 1: (0.13052631578947368, 0.9991490304709141, 0.11368421052631579, 0.16), 2: (0.12210526315789473, 0.9991667590027701, 0.09263157894736843, 0.18105263157894738)}, {0: (0.3410526315789474, 0.9986792243767314, 0.22105263157894736, 0.06526315789473684), 1: (0.12842105263157894, 0.9991578947368421, 0.10947368421052632, 0.16210526315789472), 2: (0.11789473684210526, 0.99918891966759, 0.08210526315789474, 0.18526315789473685)}, {0: (0.33052631578947367, 0.9986836565096954, 0.21894736842105264, 0.07578947368421053), 1: (0.12631578947368421, 0.9991578947368421, 0.10947368421052632, 0.16421052631578947), 2: (0.11789473684210526, 0.9991578947368421, 0.0968421052631579, 0.18526315789473685)}, {0: (0.33052631578947367, 0.9986836565096954, 0.21894736842105264, 0.07578947368421053), 1: (0.12421052631578948, 0.9991623268698061, 0.10736842105263159, 0.16631578947368422), 2: (0.12210526315789473, 0.9991578947368421, 0.0968421052631579, 0.18105263157894738)}, {0: (0.33263157894736844, 0.9986703601108032, 0.22526315789473683, 0.07368421052631578), 1: (0.13263157894736843, 0.9991578947368421, 0.10947368421052632, 0.15789473684210525), 2: (0.11368421052631579, 0.999180055401662, 0.0863157894736842, 0.18947368421052632)}]\n\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\nTraining AdaBoost model on fold...\nEvaluating AdaBoost model on original data...\n\nAdaBoost Model Results:\nCV: 5\nAccuracy: 0.5305263157894737\nPrecision: 0.5079847910879668\nRecall: 0.5051724821239352\nF1 Score: 0.49624511838922664\nConfusion Matrix: \n[[144.4  25.8  22.8]\n [ 46.2  66.6  25.2]\n [ 54.8  48.2  41. ]]\n\nTP_TN_FP_FN: \n[{0: (0.30105263157894735, 0.9987102493074793, 0.2063157894736842, 0.10526315789473684), 1: (0.13473684210526315, 0.9990382271468145, 0.16631578947368422, 0.15578947368421053), 2: (0.07789473684210527, 0.9991224376731301, 0.11368421052631579, 0.22526315789473683)}, {0: (0.3094736842105263, 0.9986836565096954, 0.21894736842105264, 0.0968421052631579), 1: (0.14105263157894737, 0.9990559556786703, 0.15789473684210525, 0.14947368421052631), 2: (0.07789473684210527, 0.9991623268698061, 0.09473684210526316, 0.22526315789473683)}, {0: (0.30526315789473685, 0.9987058171745152, 0.20842105263157895, 0.10105263157894737), 1: (0.13894736842105262, 0.9990825484764543, 0.14526315789473684, 0.15157894736842106), 2: (0.08842105263157894, 0.9991224376731301, 0.11368421052631579, 0.21473684210526317)}, {0: (0.2968421052631579, 0.9986836565096954, 0.21894736842105264, 0.10947368421052632), 1: (0.13894736842105262, 0.9990736842105263, 0.14947368421052631, 0.15157894736842106), 2: (0.0968421052631579, 0.999153462603878, 0.09894736842105263, 0.2063157894736842)}, {0: (0.30736842105263157, 0.9987013850415513, 0.21052631578947367, 0.09894736842105263), 1: (0.14736842105263157, 0.9990515235457064, 0.16, 0.1431578947368421), 2: (0.09052631578947369, 0.999184487534626, 0.08421052631578947, 0.21263157894736842)}]\n\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\nTraining XGBoost model on fold...\nEvaluating XGBoost model on original data...\n\nXGBoost Model Results:\nCV: 5\nAccuracy: 0.6378947368421053\nPrecision: 0.6284353863711954\nRecall: 0.6263397662136116\nF1 Score: 0.6269834460842485\nConfusion Matrix: \n[[141.4  17.8  33.8]\n [ 29.   80.   29. ]\n [ 29.4  33.   81.6]]\n\nTP_TN_FP_FN: \n[{0: (0.30105263157894735, 0.9988786703601108, 0.12631578947368421, 0.10526315789473684), 1: (0.16, 0.9991578947368421, 0.10947368421052632, 0.13052631578947368), 2: (0.1726315789473684, 0.9990869806094183, 0.13052631578947368, 0.13052631578947368)}, {0: (0.30105263157894735, 0.9989185595567867, 0.10736842105263159, 0.10526315789473684), 1: (0.18105263157894738, 0.9991578947368421, 0.10947368421052632, 0.10947368421052632), 2: (0.17894736842105263, 0.9991047091412742, 0.12210526315789473, 0.12421052631578948)}, {0: (0.2968421052631579, 0.9988698060941829, 0.13052631578947368, 0.10947368421052632), 1: (0.16842105263157894, 0.999171191135734, 0.1031578947368421, 0.12210526315789473), 2: (0.1705263157894737, 0.9990869806094183, 0.13052631578947368, 0.13263157894736843)}, {0: (0.30105263157894735, 0.9988742382271468, 0.12842105263157894, 0.10526315789473684), 1: (0.1726315789473684, 0.999153462603878, 0.11157894736842106, 0.11789473684210526), 2: (0.16421052631578947, 0.9991047091412742, 0.12210526315789473, 0.13894736842105262)}, {0: (0.28842105263157897, 0.9988875346260387, 0.12210526315789473, 0.11789473684210526), 1: (0.16, 0.999175623268698, 0.10105263157894737, 0.13052631578947368), 2: (0.1726315789473684, 0.9990337950138505, 0.15578947368421053, 0.13052631578947368)}]\n\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\nTraining Gradient Boost model on fold...\nEvaluating Gradient Boost model on original data...\n\nGradient Boost Model Results:\nCV: 5\nAccuracy: 0.6265263157894736\nPrecision: 0.615350804698806\nRecall: 0.6117175832060942\nF1 Score: 0.6126330654844924\nConfusion Matrix: \n[[144.6  17.6  30.8]\n [ 29.   77.6  31.4]\n [ 36.4  32.2  75.4]]\n\nTP_TN_FP_FN: \n[{0: (0.29894736842105263, 0.9988387811634349, 0.14526315789473684, 0.10736842105263159), 1: (0.16, 0.9991623268698061, 0.10736842105263159, 0.13052631578947368), 2: (0.15157894736842106, 0.9990736842105263, 0.1368421052631579, 0.15157894736842106)}, {0: (0.30526315789473685, 0.9988476454293629, 0.14105263157894737, 0.10105263157894737), 1: (0.16631578947368422, 0.999184487534626, 0.0968421052631579, 0.12421052631578948), 2: (0.16, 0.9990869806094183, 0.13052631578947368, 0.1431578947368421)}, {0: (0.31157894736842107, 0.9988432132963989, 0.1431578947368421, 0.09473684210526316), 1: (0.15578947368421053, 0.9991667590027701, 0.10526315789473684, 0.13473684210526315), 2: (0.16421052631578947, 0.9991091412742382, 0.12, 0.13894736842105262)}, {0: (0.30736842105263157, 0.9988653739612188, 0.13263157894736843, 0.09894736842105263), 1: (0.1705263157894737, 0.9991667590027701, 0.10526315789473684, 0.12), 2: (0.15789473684210525, 0.9990958448753463, 0.12631578947368421, 0.14526315789473684)}, {0: (0.29894736842105263, 0.9988786703601108, 0.12631578947368421, 0.10736842105263159), 1: (0.16421052631578947, 0.9991578947368421, 0.10947368421052632, 0.12631578947368421), 2: (0.16, 0.9990648199445984, 0.14105263157894737, 0.1431578947368421)}]\n\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\nTraining Random Forest model on fold...\nEvaluating Random Forest model on original data...\n\nRandom Forest Model Results:\nCV: 5\nAccuracy: 0.6408421052631579\nPrecision: 0.6324377515690458\nRecall: 0.6299701509348952\nF1 Score: 0.6304687730136658\nConfusion Matrix: \n[[140.6  18.4  34. ]\n [ 28.   79.2  30.8]\n [ 28.4  31.   84.6]]\n\nTP_TN_FP_FN: \n[{0: (0.28842105263157897, 0.9988831024930748, 0.12421052631578948, 0.11789473684210526), 1: (0.15157894736842106, 0.999180055401662, 0.09894736842105263, 0.13894736842105262), 2: (0.17684210526315788, 0.9990249307479224, 0.16, 0.12631578947368421)}, {0: (0.2905263157894737, 0.9989052631578947, 0.11368421052631579, 0.11578947368421053), 1: (0.16631578947368422, 0.999184487534626, 0.0968421052631579, 0.12421052631578948), 2: (0.1957894736842105, 0.9990736842105263, 0.1368421052631579, 0.10736842105263159)}, {0: (0.3136842105263158, 0.9988786703601108, 0.12631578947368421, 0.09263157894736843), 1: (0.16631578947368422, 0.999184487534626, 0.0968421052631579, 0.12421052631578948), 2: (0.17894736842105263, 0.9991135734072022, 0.11789473684210526, 0.12421052631578948)}, {0: (0.2968421052631579, 0.9988831024930748, 0.12421052631578948, 0.10947368421052632), 1: (0.17684210526315788, 0.999153462603878, 0.11157894736842106, 0.11368421052631579), 2: (0.16842105263157894, 0.9991047091412742, 0.12210526315789473, 0.13473684210526315)}, {0: (0.2905263157894737, 0.9989229916897506, 0.10526315789473684, 0.11578947368421053), 1: (0.1726315789473684, 0.9991445983379501, 0.11578947368421053, 0.11789473684210526), 2: (0.1705263157894737, 0.9990559556786703, 0.14526315789473684, 0.13263157894736843)}]\n\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\nTraining Decision Tree model on fold...\nEvaluating Decision Tree model on original data...\n\nDecision Tree Model Results:\nCV: 5\nAccuracy: 0.5785263157894738\nPrecision: 0.5690135671934557\nRecall: 0.5664670471327377\nF1 Score: 0.5662185165570968\nConfusion Matrix: \n[[129.6  24.4  39. ]\n [ 33.6  64.8  39.6]\n [ 32.   31.6  80.4]]\n\nTP_TN_FP_FN: \n[{0: (0.2736842105263158, 0.9988476454293629, 0.14105263157894737, 0.13263157894736843), 1: (0.13052631578947368, 0.9991313019390582, 0.12210526315789473, 0.16), 2: (0.16421052631578947, 0.9990072022160665, 0.16842105263157894, 0.13894736842105262)}, {0: (0.27157894736842103, 0.9988698060941829, 0.13052631578947368, 0.13473684210526315), 1: (0.15368421052631578, 0.9991180055401662, 0.12842105263157894, 0.1368421052631579), 2: (0.16421052631578947, 0.9990426592797784, 0.15157894736842106, 0.13894736842105262)}, {0: (0.2694736842105263, 0.998816620498615, 0.15578947368421053, 0.1368421052631579), 1: (0.12210526315789473, 0.999175623268698, 0.10105263157894737, 0.16842105263157894), 2: (0.17894736842105263, 0.9989983379501386, 0.1726315789473684, 0.12421052631578948)}, {0: (0.27789473684210525, 0.9988520775623269, 0.13894736842105262, 0.12842105263157894), 1: (0.13894736842105262, 0.9991357340720222, 0.12, 0.15157894736842106), 2: (0.1726315789473684, 0.9990426592797784, 0.15157894736842106, 0.13052631578947368)}, {0: (0.27157894736842103, 0.9988831024930748, 0.12421052631578948, 0.13473684210526315), 1: (0.1368421052631579, 0.9991401662049861, 0.11789473684210526, 0.15368421052631578), 2: (0.16631578947368422, 0.9989761772853186, 0.1831578947368421, 0.1368421052631579)}]\n\nTraining Logistic Regression model on fold...\nEvaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\nEvaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\nEvaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\nEvaluating Logistic Regression model on original data...\nTraining Logistic Regression model on fold...\nEvaluating Logistic Regression model on original data...\n\nLogistic Regression Model Results:\nCV: 5\nAccuracy: 0.399578947368421\nPrecision: 0.3567710556880145\nRecall: 0.38228058538376175\nF1 Score: 0.34553017845729855\nConfusion Matrix: \n[[109.2  59.8  24. ]\n [ 61.8  70.6   5.6]\n [ 66.   68.   10. ]]\n\nTP_TN_FP_FN: \n[{0: (0.2336842105263158, 0.9985817174515236, 0.2673684210526316, 0.1726315789473684), 1: (0.14947368421052631, 0.9988254847645429, 0.2673684210526316, 0.14105263157894737), 2: (0.021052631578947368, 0.9992332409972299, 0.061052631578947365, 0.28210526315789475)}, {0: (0.2294736842105263, 0.9985817174515236, 0.2673684210526316, 0.17684210526315788), 1: (0.14736842105263157, 0.9988210526315789, 0.2694736842105263, 0.1431578947368421), 2: (0.021052631578947368, 0.9992243767313019, 0.06526315789473684, 0.28210526315789475)}, {0: (0.23157894736842105, 0.9985684210526315, 0.2736842105263158, 0.17473684210526316), 1: (0.14736842105263157, 0.998816620498615, 0.27157894736842103, 0.1431578947368421), 2: (0.021052631578947368, 0.9992465373961218, 0.05473684210526316, 0.28210526315789475)}, {0: (0.2294736842105263, 0.9985728531855955, 0.27157894736842103, 0.17684210526315788), 1: (0.14947368421052631, 0.9988210526315789, 0.2694736842105263, 0.14105263157894737), 2: (0.021052631578947368, 0.9992376731301938, 0.05894736842105263, 0.28210526315789475)}, {0: (0.22526315789473683, 0.9985861495844875, 0.26526315789473687, 0.18105263157894738), 1: (0.14947368421052631, 0.9988254847645429, 0.2673684210526316, 0.14105263157894737), 2: (0.021052631578947368, 0.9992110803324099, 0.07157894736842105, 0.28210526315789475)}]\n\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\nTraining k-Nearest Neighbors model on fold...\nEvaluating k-Nearest Neighbors model on original data...\n\nk-Nearest Neighbors Model Results:\nCV: 5\nAccuracy: 0.6050526315789474\nPrecision: 0.5950655317164528\nRecall: 0.5901150784711271\nF1 Score: 0.5909434992791963\nConfusion Matrix: \n[[140.6  20.4  32. ]\n [ 38.   74.2  25.8]\n [ 37.   34.4  72.6]]\n\nTP_TN_FP_FN: \n[{0: (0.27578947368421053, 0.9987722991689751, 0.17684210526315788, 0.13052631578947368), 1: (0.1431578947368421, 0.9990825484764543, 0.14526315789473684, 0.14736842105263157), 2: (0.13263157894736843, 0.9990958448753463, 0.12631578947368421, 0.1705263157894737)}, {0: (0.29473684210526313, 0.998798891966759, 0.16421052631578947, 0.11157894736842106), 1: (0.15368421052631578, 0.9991490304709141, 0.11368421052631579, 0.1368421052631579), 2: (0.16210526315789472, 0.9991268698060942, 0.11157894736842106, 0.14105263157894737)}, {0: (0.3094736842105263, 0.998807756232687, 0.16, 0.0968421052631579), 1: (0.15789473684210525, 0.9991667590027701, 0.10526315789473684, 0.13263157894736843), 2: (0.15789473684210525, 0.9991313019390582, 0.10947368421052632, 0.14526315789473684)}, {0: (0.3094736842105263, 0.9988387811634349, 0.14526315789473684, 0.0968421052631579), 1: (0.15157894736842106, 0.999184487534626, 0.0968421052631579, 0.13894736842105262), 2: (0.16631578947368422, 0.9990869806094183, 0.13052631578947368, 0.1368421052631579)}, {0: (0.2905263157894737, 0.9988432132963989, 0.1431578947368421, 0.11578947368421053), 1: (0.17473684210526316, 0.9991445983379501, 0.11578947368421053, 0.11578947368421053), 2: (0.14526315789473684, 0.9990869806094183, 0.13052631578947368, 0.15789473684210525)}]\n\n","output_type":"stream"}]}]}