{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6115123,"sourceType":"datasetVersion","datasetId":3504592},{"sourceId":7169671,"sourceType":"datasetVersion","datasetId":4142252},{"sourceId":7169667,"sourceType":"datasetVersion","datasetId":4142249}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/input/chemcancer-v2/src/\n%mkdir /kaggle/working/CV_BLS_fold_data\n%mkdir /kaggle/working/CV_BLS_cm","metadata":{"execution":{"iopub.status.busy":"2023-12-25T15:39:33.974038Z","iopub.execute_input":"2023-12-25T15:39:33.974789Z","iopub.status.idle":"2023-12-25T15:39:36.066834Z","shell.execute_reply.started":"2023-12-25T15:39:33.974736Z","shell.execute_reply":"2023-12-25T15:39:36.065527Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/chemcancer-v2/src\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install rvfln","metadata":{"papermill":{"duration":14.221733,"end_time":"2023-07-11T06:03:26.848751","exception":false,"start_time":"2023-07-11T06:03:12.627018","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-25T15:39:36.072490Z","iopub.execute_input":"2023-12-25T15:39:36.072905Z","iopub.status.idle":"2023-12-25T15:39:51.284847Z","shell.execute_reply.started":"2023-12-25T15:39:36.072868Z","shell.execute_reply":"2023-12-25T15:39:51.283823Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting rvfln\n  Downloading rvfln-0.0.6.tar.gz (3.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: rvfln\n  Building wheel for rvfln (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rvfln: filename=rvfln-0.0.6-py3-none-any.whl size=5083 sha256=18fbb8be8410da71554b141d341e3b21fa481fc22661dd85e36616a66dd1e7a9\n  Stored in directory: /root/.cache/pip/wheels/b3/d7/24/732c199b48ade58f8add6a6273be34bb89a52088c38e4864af\nSuccessfully built rvfln\nInstalling collected packages: rvfln\nSuccessfully installed rvfln-0.0.6\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom tensorflow.keras.optimizers import Adam\nfrom data import *\nfrom machine_learning_models import *\nfrom deep_learning_models import *\nfrom vision_transformer import *\nfrom utils_dl_model import *\nfrom utils_ml_model import print_ml_results\nfrom sklearn.model_selection import train_test_split\nfrom rvfln.bls import BLSClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":8.891479,"end_time":"2023-07-11T06:03:35.746429","exception":false,"start_time":"2023-07-11T06:03:26.85495","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-25T15:39:51.286546Z","iopub.execute_input":"2023-12-25T15:39:51.286994Z","iopub.status.idle":"2023-12-25T15:40:04.867189Z","shell.execute_reply.started":"2023-12-25T15:39:51.286956Z","shell.execute_reply":"2023-12-25T15:40:04.866352Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the seed value.\nSEED = 7\nnp.random.seed(SEED)\n\n# Deep Learning parameters\nDL_EPOCH = 500\nDL_BATCH_SIZE = 32\nDL_CNN_VERSION = 3\nDL_TRANSFORMER_VISION_VERSION = 11\nDL_BLS_VERSION = 1\n\nDO_DL = True\nCV_DL = True\nOPT_DL = False\n\nDO_CNN = False\nDO_TRANSFORMER_VISION = False\nDO_BLS = True\nDO_ML = False\n\n# Percentage of test set out of the dataset.\nTEST_SET = 0.2\n\n# Percentage of validation set out of the training dataset.\nVAL_SET = 0.2","metadata":{"papermill":{"duration":0.016798,"end_time":"2023-07-11T06:03:35.769801","exception":false,"start_time":"2023-07-11T06:03:35.753003","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-25T15:40:04.869668Z","iopub.execute_input":"2023-12-25T15:40:04.870198Z","iopub.status.idle":"2023-12-25T15:40:04.876401Z","shell.execute_reply.started":"2023-12-25T15:40:04.870171Z","shell.execute_reply":"2023-12-25T15:40:04.875423Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Folder path associated with deep learning models\ndl_models_folder = \"/kaggle/working/Deep_Learning_models/\"\ndl_metrics_folder = \"/kaggle/working/Deep_Learning_metrics/\"\ndl_weights_folder = \"/kaggle/working/Deep_Learning_weights/\"\ndl_cv_models_folder = \"/kaggle/working/Deep_Learning_CV/\"\ndl_cv_results_folder = \"/kaggle/working/Deep_Learning_CV_results/\"\n\n# Folder path associated with machine learning models\nml_models_folder = \"/kaggle/working/Machine_Learning_models/\"\nml_models_results_folder = \"/kaggle/working/Machine_Learning_models_results/\"\n\n# Model names (Saved in h5 format)\ncnn_model_name = f\"cnn_v{DL_CNN_VERSION}_{DL_BATCH_SIZE}_{DL_EPOCH}_seed_{SEED}.h5\"\ntransformer_vis_model_name = f\"transformer_vision_v{DL_TRANSFORMER_VISION_VERSION}_{DL_BATCH_SIZE}_{DL_EPOCH}_seed_{SEED}.h5\"\nbls_model_name = f\"bls_v{DL_BLS_VERSION}_{DL_BATCH_SIZE}_{DL_EPOCH}_seed_{SEED}.h5\"\n\n# Metric filenames\ncnn_metrics_filename = f\"metrics_{cnn_model_name}.json\"\ntransformer_vis_metrics_filename = f\"metrics_{transformer_vis_model_name}.json\"\n\n# Weight filenames\ncnn_weights_filename = f\"weights_{cnn_model_name}.json\"\ntransformer_vis_weights_filename = f\"weights_{transformer_vis_model_name}.json\"\n\n# Deep Learning models path\nif DO_CNN:\n    dl_model_path = os.path.join(\n        dl_models_folder, cnn_model_name)\nelif DO_TRANSFORMER_VISION:\n    dl_model_path = os.path.join(\n        dl_models_folder, transformer_vis_model_name)\n\n\n# Deep Learning metrics path\nif DO_CNN:\n    dl_metrics_path = os.path.join(\n        dl_metrics_folder, cnn_metrics_filename)\nelif DO_TRANSFORMER_VISION:\n    dl_metrics_path = os.path.join(\n        dl_metrics_folder, transformer_vis_metrics_filename)\n\n\n# Deep Learning weights path\nif DO_CNN:\n    dl_weights_path = os.path.join(\n        dl_weights_folder, cnn_weights_filename)\n\nelif DO_TRANSFORMER_VISION:\n    dl_weights_path = os.path.join(\n        dl_weights_folder, transformer_vis_weights_filename)","metadata":{"papermill":{"duration":0.017912,"end_time":"2023-07-11T06:03:35.79377","exception":false,"start_time":"2023-07-11T06:03:35.775858","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-25T15:40:04.878115Z","iopub.execute_input":"2023-12-25T15:40:04.878492Z","iopub.status.idle":"2023-12-25T15:40:04.901111Z","shell.execute_reply.started":"2023-12-25T15:40:04.878467Z","shell.execute_reply":"2023-12-25T15:40:04.900372Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def extract_data_from_csv(filename=\"generated_data.csv\"):\n    # Read the CSV file into a DataFrame\n    df_extracted = pd.read_csv(filename)\n    \n    # Split the DataFrame into features and labels\n    X_extracted = df_extracted.drop(columns=[\"labels\"]).values\n    y_extracted = df_extracted[\"labels\"].values\n    \n    return X_extracted, y_extracted","metadata":{"execution":{"iopub.status.busy":"2023-12-25T15:40:04.902021Z","iopub.execute_input":"2023-12-25T15:40:04.902296Z","iopub.status.idle":"2023-12-25T15:40:04.915527Z","shell.execute_reply.started":"2023-12-25T15:40:04.902268Z","shell.execute_reply":"2023-12-25T15:40:04.914811Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# With bksb, slope and roll set to true\ntest_data= \"/kaggle/input/test-gen-cc-10x-v4/test-gen-cc-10x-v4.csv\"\n\n# No bksb, slope and roll set to false\ntrain_data = \"/kaggle/input/gen-cc-10x-v4/gen-cc-10x-v4.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-12-25T15:40:04.916381Z","iopub.execute_input":"2023-12-25T15:40:04.916640Z","iopub.status.idle":"2023-12-25T15:40:04.928697Z","shell.execute_reply.started":"2023-12-25T15:40:04.916618Z","shell.execute_reply":"2023-12-25T15:40:04.927984Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_augmented, y_augmented = extract_data_from_csv(train_data)\nprint(f\"X_augmented shaped: {X_augmented.shape}\")\nprint(f\"y_augmented shaped: {y_augmented.shape}\")\n\nX_original, y_original = extract_data_from_csv(test_data)\nprint(f\"X_original shaped: {X_original.shape}\")\nprint(f\"y_original shaped: {y_original.shape}\")","metadata":{"papermill":{"duration":2.46063,"end_time":"2023-07-11T06:03:38.260324","exception":false,"start_time":"2023-07-11T06:03:35.799694","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-25T15:40:04.929704Z","iopub.execute_input":"2023-12-25T15:40:04.930059Z","iopub.status.idle":"2023-12-25T15:40:06.930895Z","shell.execute_reply.started":"2023-12-25T15:40:04.930026Z","shell.execute_reply":"2023-12-25T15:40:06.929830Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"X_augmented shaped: (18980, 270)\ny_augmented shaped: (18980,)\nX_original shaped: (475, 270)\ny_original shaped: (475,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom rvfln.bls import BLSClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n\ndef perform_bls_cv(X_original, y_original, X_augmented, y_augmented,n_z, n_z_features, n_h, alpha):\n\n    bls = BLSClassifier(n_z=n_z, n_z_features=n_z_features, n_h=n_h, alpha=alpha)\n\n    scores = []\n    # Initialize lists to store precision, recall, and F1 scores\n    accuracies = []\n    precisions = []\n    recalls = []\n    f1_scores = []\n    confusion_matrices_bls = []\n\n\n    fold = 1\n    n_splits=5\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_value)\n    skf_augmented = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_value)\n    \n    for train_index, _ in skf_augmented.split(X_augmented, y_augmented):\n        # We are only interested in the train index for augmented data\n        # Select the augmented data for training\n        print(\"=\" * 40)\n        print(f\"Fold: {fold}\")\n        print(\"Selecting the augmented data\")\n        \n        X_train = X_augmented[train_index]\n        y_train = y_augmented[train_index]\n        \n        # Standardize the data\n        print(\"Standardizing the data\")\n        X_train, X_test = standardize_data(X_train, X_original)\n        y_test = y_original\n        \n        print(f\"X_train shape: {X_train.shape}\")\n        print(f\"X_test shape: {X_test.shape}\")\n        print(f\"y_train shape: {y_train.shape}\")\n        print(f\"y_test shape: {y_test.shape}\")\n        \n        print(\"Saving the data\")\n        fold_data = {\n\n            'X_train': X_train,\n            'X_test': X_test,\n            'y_train': y_train,\n            'y_test': y_test\n        }\n\n        with open(f\"/kaggle/working/CV_BLS_fold_data/fold_{fold}_data.pkl\", 'wb') as f:\n            pickle.dump(fold_data, f)\n        \n        # Fit the bls and compute the accuracy\n        bls.fit(X_train, y_train)\n        score = bls.score(X_test, y_test)\n        y_pred = bls.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        \n        # Calculate precision, recall, and F1 score\n        precision = precision_score(y_test, y_pred, average='macro')\n        recall = recall_score(y_test, y_pred, average='macro')\n        f1 = f1_score(y_test, y_pred, average='macro')\n        cm = confusion_matrix(y_test, y_pred)\n        \n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n        \n        with open(f\"/kaggle/working/CV_BLS_cm/BLS_cm_fold_{fold}.pkl\", 'wb') as cm_file:\n            pickle.dump(cm, cm_file)\n\n        # Append the scores to the lists\n        accuracies.append(accuracy)\n        precisions.append(precision)\n        recalls.append(recall)\n        f1_scores.append(f1)\n        scores.append(score)\n        confusion_matrices_bls.append(cm)\n        \n        \n        \n        print(f\"Fold {fold}, BLS Test Score: {score:.4f}\")\n        fold += 1\n    \n    scores = np.array(scores)\n    accuracies = np.array(accuracies)\n    precisions = np.array(precisions)\n    recalls = np.array(recalls)\n    f1_scores = np.array(f1_scores)\n    \n    # Calculate and print the mean and standard deviation of precision, recall, and F1 score\n    print(f\"Mean BLS Test score over stratified {n_splits}-fold cross-validation: {np.mean(scores):.4f}\")\n    print(f\"Mean accuracies over stratified {n_splits}-fold cross-validation: {np.mean(accuracies):.4f}\")\n    print(f\"Mean precision over stratified {n_splits}-fold cross-validation: {np.mean(precisions):.4f}\")\n    print(f\"Mean recall over stratified {n_splits}-fold cross-validation: {np.mean(recalls):.4f}\")\n    print(f\"Mean F1 score over stratified {n_splits}-fold cross-validation: {np.mean(f1_scores):.4f}\")\n    print(\"*\" * 40)\n    print(f\"Standard deviation of BLS Test score over stratified {n_splits}-fold cross-validation: {np.std(scores):.4f}\")\n    print(f\"Standard deviation of accuracies over stratified {n_splits}-fold cross-validation: {np.std(accuracies):.4f}\")\n    print(f\"Standard deviation of precision over stratified {n_splits}-fold cross-validation: {np.std(precisions):.4f}\")\n    print(f\"Standard deviation of recall over stratified {n_splits}-fold cross-validation: {np.std(recalls):.4f}\")\n    print(f\"Standard deviation of F1 score over stratified {n_splits}-fold cross-validation: {np.std(f1_scores):.4f}\")\n    print(confusion_matrices_bls)\n    \n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2023-12-25T15:40:06.932397Z","iopub.execute_input":"2023-12-25T15:40:06.932782Z","iopub.status.idle":"2023-12-25T15:40:06.951801Z","shell.execute_reply.started":"2023-12-25T15:40:06.932731Z","shell.execute_reply":"2023-12-25T15:40:06.950781Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"n_z=12\nn_z_features=50\nn_h=100\nalpha=0.0001\n\nperform_bls_cv(X_original, y_original, X_augmented, y_augmented,n_z, n_z_features, n_h, alpha)","metadata":{"execution":{"iopub.status.busy":"2023-12-25T15:43:24.245881Z","iopub.execute_input":"2023-12-25T15:43:24.246217Z","iopub.status.idle":"2023-12-25T15:43:28.368312Z","shell.execute_reply.started":"2023-12-25T15:43:24.246191Z","shell.execute_reply":"2023-12-25T15:43:28.366943Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"========================================\nFold: 1\nSelecting the augmented data\nStandardizing the data\nX_train shape: (15184, 270)\nX_test shape: (475, 270)\ny_train shape: (15184,)\ny_test shape: (475,)\nSaving the data\nPrecision: 0.7177\nRecall: 0.6938\nF1 Score: 0.6950\nFold 1, BLS Test Score: 0.7200\n========================================\nFold: 2\nSelecting the augmented data\nStandardizing the data\nX_train shape: (15184, 270)\nX_test shape: (475, 270)\ny_train shape: (15184,)\ny_test shape: (475,)\nSaving the data\nPrecision: 0.7270\nRecall: 0.7007\nF1 Score: 0.7046\nFold 2, BLS Test Score: 0.7242\n========================================\nFold: 3\nSelecting the augmented data\nStandardizing the data\nX_train shape: (15184, 270)\nX_test shape: (475, 270)\ny_train shape: (15184,)\ny_test shape: (475,)\nSaving the data\nPrecision: 0.7430\nRecall: 0.7076\nF1 Score: 0.7122\nFold 3, BLS Test Score: 0.7305\n========================================\nFold: 4\nSelecting the augmented data\nStandardizing the data\nX_train shape: (15184, 270)\nX_test shape: (475, 270)\ny_train shape: (15184,)\ny_test shape: (475,)\nSaving the data\nPrecision: 0.7300\nRecall: 0.6936\nF1 Score: 0.6987\nFold 4, BLS Test Score: 0.7200\n========================================\nFold: 5\nSelecting the augmented data\nStandardizing the data\nX_train shape: (15184, 270)\nX_test shape: (475, 270)\ny_train shape: (15184,)\ny_test shape: (475,)\nSaving the data\nPrecision: 0.7328\nRecall: 0.7067\nF1 Score: 0.7104\nFold 5, BLS Test Score: 0.7305\nMean BLS Test score over stratified 5-fold cross-validation: 0.7251\nMean accuracies over stratified 5-fold cross-validation: 0.7251\nMean precision over stratified 5-fold cross-validation: 0.7301\nMean recall over stratified 5-fold cross-validation: 0.7005\nMean F1 score over stratified 5-fold cross-validation: 0.7042\n****************************************\nStandard deviation of BLS Test score over stratified 5-fold cross-validation: 0.0047\nStandard deviation of accuracies over stratified 5-fold cross-validation: 0.0047\nStandard deviation of precision over stratified 5-fold cross-validation: 0.0082\nStandard deviation of recall over stratified 5-fold cross-validation: 0.0060\nStandard deviation of F1 score over stratified 5-fold cross-validation: 0.0066\n[array([[181,   4,   8],\n       [ 34,  85,  19],\n       [ 33,  35,  76]]), array([[177,   9,   7],\n       [ 35,  84,  19],\n       [ 34,  27,  83]]), array([[178,   6,   9],\n       [ 40,  89,   9],\n       [ 32,  32,  80]]), array([[180,   2,  11],\n       [ 45,  77,  16],\n       [ 33,  26,  85]]), array([[179,   2,  12],\n       [ 35,  86,  17],\n       [ 33,  29,  82]])]\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0.7250526315789474"},"metadata":{}}]},{"cell_type":"markdown","source":"n_z is the number of feature nodes in the enhancement node layer. It should ideally be set considering the dimensionality of your input data. A larger n_z means the model can learn more complex representations, but it may also lead to overfitting if set too high. For your data with 270 features, a reasonable starting point might be around 10-50.\n\nn_z_features is the number of random features generated from each feature node. This parameter directly controls the model's complexity and its computational requirements. A higher number will allow the model to learn more complex representations, but it will also increase the computational cost and may lead to overfitting. A reasonable starting point might be 100-500.\n\nn_h is the number of enhancement nodes. This is another parameter controlling the model's complexity. A higher number will allow the model to learn more complex representations, but it will also increase the computational cost and may lead to overfitting. A reasonable starting point might be 500-2000.\n\nalpha is a regularization parameter. It helps prevent overfitting by adding a penalty to the loss function based on the weights' magnitude. It is typically a small positive value. Common choices are 0.1, 0.01, or 0.001.","metadata":{"papermill":{"duration":0.058055,"end_time":"2023-07-11T06:13:10.091683","exception":false,"start_time":"2023-07-11T06:13:10.033628","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Best parameters:  {'alpha': 0.001, 'n_h': 50, 'n_z': 10, 'n_z_features': 50}\nBest score:  0.7470962366338009","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}}]}