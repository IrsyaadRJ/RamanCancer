{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6115123,"sourceType":"datasetVersion","datasetId":3504592},{"sourceId":7169667,"sourceType":"datasetVersion","datasetId":4142249},{"sourceId":7169671,"sourceType":"datasetVersion","datasetId":4142252}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/input/chemcancer-v2/src/\n%mkdir /kaggle/working/CV_BLS_fold_data\n%mkdir /kaggle/working/CV_BLS_cm","metadata":{"execution":{"iopub.status.busy":"2023-12-25T16:06:11.427528Z","iopub.execute_input":"2023-12-25T16:06:11.428050Z","iopub.status.idle":"2023-12-25T16:06:12.097741Z","shell.execute_reply.started":"2023-12-25T16:06:11.428010Z","shell.execute_reply":"2023-12-25T16:06:12.096561Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/chemcancer-v2/src\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install rvfln","metadata":{"papermill":{"duration":14.221733,"end_time":"2023-07-11T06:03:26.848751","exception":false,"start_time":"2023-07-11T06:03:12.627018","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-25T16:06:12.099966Z","iopub.execute_input":"2023-12-25T16:06:12.100429Z","iopub.status.idle":"2023-12-25T16:06:27.348185Z","shell.execute_reply.started":"2023-12-25T16:06:12.100401Z","shell.execute_reply":"2023-12-25T16:06:27.347062Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting rvfln\n  Downloading rvfln-0.0.6.tar.gz (3.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: rvfln\n  Building wheel for rvfln (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rvfln: filename=rvfln-0.0.6-py3-none-any.whl size=5083 sha256=d24661b217cf8d6e145dc7ede966b1b1953b01994496cd459a0e74956f6b79c2\n  Stored in directory: /root/.cache/pip/wheels/b3/d7/24/732c199b48ade58f8add6a6273be34bb89a52088c38e4864af\nSuccessfully built rvfln\nInstalling collected packages: rvfln\nSuccessfully installed rvfln-0.0.6\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom tensorflow.keras.optimizers import Adam\nfrom data import *\nfrom machine_learning_models import *\nfrom deep_learning_models import *\nfrom vision_transformer import *\nfrom utils_dl_model import *\nfrom utils_ml_model import print_ml_results\nfrom sklearn.model_selection import train_test_split\nfrom rvfln.bls import BLSClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":8.891479,"end_time":"2023-07-11T06:03:35.746429","exception":false,"start_time":"2023-07-11T06:03:26.85495","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-25T16:06:27.350131Z","iopub.execute_input":"2023-12-25T16:06:27.350440Z","iopub.status.idle":"2023-12-25T16:06:43.629845Z","shell.execute_reply.started":"2023-12-25T16:06:27.350412Z","shell.execute_reply":"2023-12-25T16:06:43.628922Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Set the seed value.\nSEED = 7\nnp.random.seed(SEED)\n\n# Deep Learning parameters\nDL_EPOCH = 500\nDL_BATCH_SIZE = 32\nDL_CNN_VERSION = 3\nDL_TRANSFORMER_VISION_VERSION = 11\nDL_BLS_VERSION = 1\n\nDO_DL = True\nCV_DL = True\nOPT_DL = False\n\nDO_CNN = False\nDO_TRANSFORMER_VISION = False\nDO_BLS = True\nDO_ML = False\n\n# Percentage of test set out of the dataset.\nTEST_SET = 0.2\n\n# Percentage of validation set out of the training dataset.\nVAL_SET = 0.2","metadata":{"papermill":{"duration":0.016798,"end_time":"2023-07-11T06:03:35.769801","exception":false,"start_time":"2023-07-11T06:03:35.753003","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-25T16:06:43.631223Z","iopub.execute_input":"2023-12-25T16:06:43.632929Z","iopub.status.idle":"2023-12-25T16:06:43.640881Z","shell.execute_reply.started":"2023-12-25T16:06:43.632851Z","shell.execute_reply":"2023-12-25T16:06:43.638447Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Folder path associated with deep learning models\ndl_models_folder = \"/kaggle/working/Deep_Learning_models/\"\ndl_metrics_folder = \"/kaggle/working/Deep_Learning_metrics/\"\ndl_weights_folder = \"/kaggle/working/Deep_Learning_weights/\"\ndl_cv_models_folder = \"/kaggle/working/Deep_Learning_CV/\"\ndl_cv_results_folder = \"/kaggle/working/Deep_Learning_CV_results/\"\n\n# Folder path associated with machine learning models\nml_models_folder = \"/kaggle/working/Machine_Learning_models/\"\nml_models_results_folder = \"/kaggle/working/Machine_Learning_models_results/\"\n\n# Model names (Saved in h5 format)\ncnn_model_name = f\"cnn_v{DL_CNN_VERSION}_{DL_BATCH_SIZE}_{DL_EPOCH}_seed_{SEED}.h5\"\ntransformer_vis_model_name = f\"transformer_vision_v{DL_TRANSFORMER_VISION_VERSION}_{DL_BATCH_SIZE}_{DL_EPOCH}_seed_{SEED}.h5\"\nbls_model_name = f\"bls_v{DL_BLS_VERSION}_{DL_BATCH_SIZE}_{DL_EPOCH}_seed_{SEED}.h5\"\n\n# Metric filenames\ncnn_metrics_filename = f\"metrics_{cnn_model_name}.json\"\ntransformer_vis_metrics_filename = f\"metrics_{transformer_vis_model_name}.json\"\n\n# Weight filenames\ncnn_weights_filename = f\"weights_{cnn_model_name}.json\"\ntransformer_vis_weights_filename = f\"weights_{transformer_vis_model_name}.json\"\n\n# Deep Learning models path\nif DO_CNN:\n    dl_model_path = os.path.join(\n        dl_models_folder, cnn_model_name)\nelif DO_TRANSFORMER_VISION:\n    dl_model_path = os.path.join(\n        dl_models_folder, transformer_vis_model_name)\n\n\n# Deep Learning metrics path\nif DO_CNN:\n    dl_metrics_path = os.path.join(\n        dl_metrics_folder, cnn_metrics_filename)\nelif DO_TRANSFORMER_VISION:\n    dl_metrics_path = os.path.join(\n        dl_metrics_folder, transformer_vis_metrics_filename)\n\n\n# Deep Learning weights path\nif DO_CNN:\n    dl_weights_path = os.path.join(\n        dl_weights_folder, cnn_weights_filename)\n\nelif DO_TRANSFORMER_VISION:\n    dl_weights_path = os.path.join(\n        dl_weights_folder, transformer_vis_weights_filename)","metadata":{"papermill":{"duration":0.017912,"end_time":"2023-07-11T06:03:35.79377","exception":false,"start_time":"2023-07-11T06:03:35.775858","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-25T16:06:43.644608Z","iopub.execute_input":"2023-12-25T16:06:43.645205Z","iopub.status.idle":"2023-12-25T16:06:43.655133Z","shell.execute_reply.started":"2023-12-25T16:06:43.645162Z","shell.execute_reply":"2023-12-25T16:06:43.654205Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def extract_data_from_csv(filename=\"generated_data.csv\"):\n    # Read the CSV file into a DataFrame\n    df_extracted = pd.read_csv(filename)\n    \n    # Split the DataFrame into features and labels\n    X_extracted = df_extracted.drop(columns=[\"labels\"]).values\n    y_extracted = df_extracted[\"labels\"].values\n    \n    return X_extracted, y_extracted","metadata":{"execution":{"iopub.status.busy":"2023-12-25T16:06:43.656319Z","iopub.execute_input":"2023-12-25T16:06:43.656640Z","iopub.status.idle":"2023-12-25T16:06:43.672520Z","shell.execute_reply.started":"2023-12-25T16:06:43.656616Z","shell.execute_reply":"2023-12-25T16:06:43.671056Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# With bksb, slope and roll set to true\ntest_data= \"/kaggle/input/test-gen-cc-10x-v4/test-gen-cc-10x-v4.csv\"\n\n# No bksb, slope and roll set to false\ntrain_data = \"/kaggle/input/gen-cc-10x-v4/gen-cc-10x-v4.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-12-25T16:06:43.674446Z","iopub.execute_input":"2023-12-25T16:06:43.675058Z","iopub.status.idle":"2023-12-25T16:06:43.687757Z","shell.execute_reply.started":"2023-12-25T16:06:43.675018Z","shell.execute_reply":"2023-12-25T16:06:43.686592Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_augmented, y_augmented = extract_data_from_csv(train_data)\nprint(f\"X_augmented shaped: {X_augmented.shape}\")\nprint(f\"y_augmented shaped: {y_augmented.shape}\")\n\nX_original, y_original = extract_data_from_csv(test_data)\nprint(f\"X_original shaped: {X_original.shape}\")\nprint(f\"y_original shaped: {y_original.shape}\")","metadata":{"papermill":{"duration":2.46063,"end_time":"2023-07-11T06:03:38.260324","exception":false,"start_time":"2023-07-11T06:03:35.799694","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-25T16:06:43.689387Z","iopub.execute_input":"2023-12-25T16:06:43.689919Z","iopub.status.idle":"2023-12-25T16:06:45.804913Z","shell.execute_reply.started":"2023-12-25T16:06:43.689888Z","shell.execute_reply":"2023-12-25T16:06:45.803258Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"X_augmented shaped: (18980, 270)\ny_augmented shaped: (18980,)\nX_original shaped: (475, 270)\ny_original shaped: (475,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Apply median filter and background subtraction to the data\ndef apply_filters_and_background_subtraction(X):\n    # Reshape the input data to a 2D array if necessary\n    if len(X.shape) == 1:\n        X = X.reshape((1, -1))\n    \n    # Apply median filter\n    datamedfilt = scipy.ndimage.median_filter(X, size=(1, 5))\n    \n    # Apply airPLS for background subtraction\n    baseline = np.zeros_like(datamedfilt)\n    cols = baseline.shape[1]\n    for col in range(cols):\n        baseline[:, col] = airPLS(datamedfilt[:, col], lambda_=150)\n    \n    data_bksb = datamedfilt - baseline\n    return datamedfilt","metadata":{"execution":{"iopub.status.busy":"2023-12-25T16:06:45.806490Z","iopub.execute_input":"2023-12-25T16:06:45.806885Z","iopub.status.idle":"2023-12-25T16:06:45.815907Z","shell.execute_reply.started":"2023-12-25T16:06:45.806853Z","shell.execute_reply":"2023-12-25T16:06:45.814596Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom rvfln.bls import BLSClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n\ndef perform_bls_cv(X_original, y_original, X_augmented, y_augmented,n_z, n_z_features, n_h, alpha):\n\n    bls = BLSClassifier(n_z=n_z, n_z_features=n_z_features, n_h=n_h, alpha=alpha)\n\n    scores = []\n    # Initialize lists to store precision, recall, and F1 scores\n    accuracies = []\n    precisions = []\n    recalls = []\n    f1_scores = []\n    confusion_matrices_bls = []\n\n\n    fold = 1\n    n_splits=5\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_value)\n    skf_augmented = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_value)\n    \n    for train_index, _ in skf_augmented.split(X_augmented, y_augmented):\n        # We are only interested in the train index for augmented data\n        # Select the augmented data for training\n        print(\"=\" * 40)\n        print(f\"Fold: {fold}\")\n        print(\"Selecting the augmented data\")\n        \n        X_train = X_augmented[train_index]\n        y_train = y_augmented[train_index]\n        \n        print(\"Apply Filters\")\n        X_train =  apply_filters_and_background_subtraction(X_train)\n        X_test =  apply_filters_and_background_subtraction(X_original)\n        \n        # Standardize the data\n        print(\"Standardizing the data\")\n        X_train, X_test = standardize_data(X_train, X_test)\n        y_test = y_original\n        \n        print(f\"X_train shape: {X_train.shape}\")\n        print(f\"X_test shape: {X_test.shape}\")\n        print(f\"y_train shape: {y_train.shape}\")\n        print(f\"y_test shape: {y_test.shape}\")\n        \n        print(\"Saving the data\")\n        fold_data = {\n\n            'X_train': X_train,\n            'X_test': X_test,\n            'y_train': y_train,\n            'y_test': y_test\n        }\n\n        with open(f\"/kaggle/working/CV_BLS_fold_data/fold_{fold}_data.pkl\", 'wb') as f:\n            pickle.dump(fold_data, f)\n        \n        # Fit the bls and compute the accuracy\n        bls.fit(X_train, y_train)\n        score = bls.score(X_test, y_test)\n        y_pred = bls.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        \n        # Calculate precision, recall, and F1 score\n        precision = precision_score(y_test, y_pred, average='macro')\n        recall = recall_score(y_test, y_pred, average='macro')\n        f1 = f1_score(y_test, y_pred, average='macro')\n        cm = confusion_matrix(y_test, y_pred)\n        \n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n        \n        with open(f\"/kaggle/working/CV_BLS_cm/BLS_cm_fold_{fold}.pkl\", 'wb') as cm_file:\n            pickle.dump(cm, cm_file)\n\n        # Append the scores to the lists\n        accuracies.append(accuracy)\n        precisions.append(precision)\n        recalls.append(recall)\n        f1_scores.append(f1)\n        scores.append(score)\n        confusion_matrices_bls.append(cm)\n        \n        \n        \n        print(f\"Fold {fold}, BLS Test Score: {score:.4f}\")\n        fold += 1\n    \n    scores = np.array(scores)\n    accuracies = np.array(accuracies)\n    precisions = np.array(precisions)\n    recalls = np.array(recalls)\n    f1_scores = np.array(f1_scores)\n    \n    # Calculate and print the mean and standard deviation of precision, recall, and F1 score\n    print(f\"Mean BLS Test score over stratified {n_splits}-fold cross-validation: {np.mean(scores):.4f}\")\n    print(f\"Mean accuracies over stratified {n_splits}-fold cross-validation: {np.mean(accuracies):.4f}\")\n    print(f\"Mean precision over stratified {n_splits}-fold cross-validation: {np.mean(precisions):.4f}\")\n    print(f\"Mean recall over stratified {n_splits}-fold cross-validation: {np.mean(recalls):.4f}\")\n    print(f\"Mean F1 score over stratified {n_splits}-fold cross-validation: {np.mean(f1_scores):.4f}\")\n    print(\"*\" * 40)\n    print(f\"Standard deviation of BLS Test score over stratified {n_splits}-fold cross-validation: {np.std(scores):.4f}\")\n    print(f\"Standard deviation of accuracies over stratified {n_splits}-fold cross-validation: {np.std(accuracies):.4f}\")\n    print(f\"Standard deviation of precision over stratified {n_splits}-fold cross-validation: {np.std(precisions):.4f}\")\n    print(f\"Standard deviation of recall over stratified {n_splits}-fold cross-validation: {np.std(recalls):.4f}\")\n    print(f\"Standard deviation of F1 score over stratified {n_splits}-fold cross-validation: {np.std(f1_scores):.4f}\")\n    print(confusion_matrices_bls)\n    \n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2023-12-25T16:06:45.817650Z","iopub.execute_input":"2023-12-25T16:06:45.818597Z","iopub.status.idle":"2023-12-25T16:06:45.843811Z","shell.execute_reply.started":"2023-12-25T16:06:45.818562Z","shell.execute_reply":"2023-12-25T16:06:45.842340Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"n_z=12\nn_z_features=50\nn_h=100\nalpha=0.0001\n\nperform_bls_cv(X_original, y_original, X_augmented, y_augmented,n_z, n_z_features, n_h, alpha)","metadata":{"execution":{"iopub.status.busy":"2023-12-25T16:11:27.479373Z","iopub.execute_input":"2023-12-25T16:11:27.480136Z","iopub.status.idle":"2023-12-25T16:12:24.259595Z","shell.execute_reply.started":"2023-12-25T16:11:27.480093Z","shell.execute_reply":"2023-12-25T16:12:24.258358Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"========================================\nFold: 1\nSelecting the augmented data\nApply Filters\nStandardizing the data\nX_train shape: (15184, 270)\nX_test shape: (475, 270)\ny_train shape: (15184,)\ny_test shape: (475,)\nSaving the data\nPrecision: 0.7801\nRecall: 0.7425\nF1 Score: 0.7499\nFold 1, BLS Test Score: 0.7642\n========================================\nFold: 2\nSelecting the augmented data\nApply Filters\nStandardizing the data\nX_train shape: (15184, 270)\nX_test shape: (475, 270)\ny_train shape: (15184,)\ny_test shape: (475,)\nSaving the data\nPrecision: 0.7306\nRecall: 0.6816\nF1 Score: 0.6892\nFold 2, BLS Test Score: 0.7074\n========================================\nFold: 3\nSelecting the augmented data\nApply Filters\nStandardizing the data\nX_train shape: (15184, 270)\nX_test shape: (475, 270)\ny_train shape: (15184,)\ny_test shape: (475,)\nSaving the data\nPrecision: 0.7241\nRecall: 0.6841\nF1 Score: 0.6902\nFold 3, BLS Test Score: 0.7074\n========================================\nFold: 4\nSelecting the augmented data\nApply Filters\nStandardizing the data\nX_train shape: (15184, 270)\nX_test shape: (475, 270)\ny_train shape: (15184,)\ny_test shape: (475,)\nSaving the data\nPrecision: 0.7418\nRecall: 0.7122\nF1 Score: 0.7177\nFold 4, BLS Test Score: 0.7347\n========================================\nFold: 5\nSelecting the augmented data\nApply Filters\nStandardizing the data\nX_train shape: (15184, 270)\nX_test shape: (475, 270)\ny_train shape: (15184,)\ny_test shape: (475,)\nSaving the data\nPrecision: 0.7501\nRecall: 0.7034\nF1 Score: 0.7112\nFold 5, BLS Test Score: 0.7284\nMean BLS Test score over stratified 5-fold cross-validation: 0.7284\nMean accuracies over stratified 5-fold cross-validation: 0.7284\nMean precision over stratified 5-fold cross-validation: 0.7453\nMean recall over stratified 5-fold cross-validation: 0.7047\nMean F1 score over stratified 5-fold cross-validation: 0.7116\n****************************************\nStandard deviation of BLS Test score over stratified 5-fold cross-validation: 0.0210\nStandard deviation of accuracies over stratified 5-fold cross-validation: 0.0210\nStandard deviation of precision over stratified 5-fold cross-validation: 0.0196\nStandard deviation of recall over stratified 5-fold cross-validation: 0.0221\nStandard deviation of F1 score over stratified 5-fold cross-validation: 0.0222\n[array([[182,   3,   8],\n       [ 38,  91,   9],\n       [ 30,  24,  90]]), array([[177,   5,  11],\n       [ 46,  78,  14],\n       [ 44,  19,  81]]), array([[174,   5,  14],\n       [ 42,  85,  11],\n       [ 43,  24,  77]]), array([[177,   5,  11],\n       [ 41,  83,  14],\n       [ 29,  26,  89]]), array([[180,   4,   9],\n       [ 43,  82,  13],\n       [ 40,  20,  84]])]\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0.728421052631579"},"metadata":{}}]},{"cell_type":"markdown","source":"n_z is the number of feature nodes in the enhancement node layer. It should ideally be set considering the dimensionality of your input data. A larger n_z means the model can learn more complex representations, but it may also lead to overfitting if set too high. For your data with 270 features, a reasonable starting point might be around 10-50.\n\nn_z_features is the number of random features generated from each feature node. This parameter directly controls the model's complexity and its computational requirements. A higher number will allow the model to learn more complex representations, but it will also increase the computational cost and may lead to overfitting. A reasonable starting point might be 100-500.\n\nn_h is the number of enhancement nodes. This is another parameter controlling the model's complexity. A higher number will allow the model to learn more complex representations, but it will also increase the computational cost and may lead to overfitting. A reasonable starting point might be 500-2000.\n\nalpha is a regularization parameter. It helps prevent overfitting by adding a penalty to the loss function based on the weights' magnitude. It is typically a small positive value. Common choices are 0.1, 0.01, or 0.001.","metadata":{"papermill":{"duration":0.058055,"end_time":"2023-07-11T06:13:10.091683","exception":false,"start_time":"2023-07-11T06:13:10.033628","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Best parameters:  {'alpha': 0.001, 'n_h': 50, 'n_z': 10, 'n_z_features': 50}\nBest score:  0.7470962366338009","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}}]}